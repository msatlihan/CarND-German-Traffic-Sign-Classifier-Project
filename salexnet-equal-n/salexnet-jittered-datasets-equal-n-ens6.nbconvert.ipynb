{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #6 for the ensemble of Scaled AlexNet models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "from functools import reduce\n",
    "import os\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size = 32\n",
    "pixel_depth = 255.0\n",
    "\n",
    "# load augmented datasets\n",
    "\n",
    "training_file = 'traffic-signs-augmented-data-equal-n/train.p'\n",
    "validation_file='traffic-signs-augmented-data-equal-n/valid.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train_aug = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid_aug = pickle.load(f)\n",
    "    \n",
    "X_aug_train, y_aug_train = train_aug['features'], train_aug['labels']\n",
    "X_aug_valid, y_aug_valid = valid_aug['features'], valid_aug['labels']\n",
    "\n",
    "# normalize\n",
    "X_aug_train_norm =  ((X_aug_train.astype(np.float32) - (pixel_depth * 0.5)) \n",
    "                        / (pixel_depth * 0.5))\n",
    "X_aug_valid_norm =  ((X_aug_valid.astype(np.float32) - (pixel_depth * 0.5)) \n",
    "                        / (pixel_depth * 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_file = 'traffic-signs-data/train.p'\n",
    "validation_file='traffic-signs-data/valid.p'\n",
    "testing_file = 'traffic-signs-data/test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "\n",
    "X_train_norm =  (X_train.astype(np.float32) - (pixel_depth * 0.5)) / (pixel_depth * 0.5)\n",
    "X_valid_norm =  (X_valid.astype(np.float32) - (pixel_depth * 0.5)) / (pixel_depth * 0.5)\n",
    "X_test_norm =  (X_test.astype(np.float32) - (pixel_depth * 0.5)) / (pixel_depth * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models import *\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trainer\n",
    "\n",
    "num_labels = 43\n",
    "batch_size = 64\n",
    "\n",
    "# pack datasets into a tuple\n",
    "datasets = ((X_aug_train_norm, y_aug_train), \n",
    "            (X_aug_valid_norm, y_aug_valid), \n",
    "            (X_test_norm, y_test))\n",
    "\n",
    "# trainer instance\n",
    "trainer = Trainer(datasets=datasets, batch_size=batch_size, n_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "salexnet = ScaledAlexNet(num_labels, image_size=32, \n",
    "                         learning_rate=0.1, batch_size=batch_size,\n",
    "                         decay_interval=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at epoch 1 and iter 1349: 0.398197 and the learning rate: 0.100000\n",
      "Minibatch train and validation accuracy: 92.188%, 76.874%\n",
      "Time interval: 1267.3012 seconds, estimated run time for 200 epochs: 70.4056 hours\n",
      "[ 0.71723557  0.43742836  0.64328611  0.74055463  0.74115193  0.52804798\n",
      "  0.69610214  0.69210541  0.67114359  0.8632071   0.87881112  0.77340084\n",
      "  0.88870966  0.87999952  0.94393384  0.95656371  0.61703426  0.95596194\n",
      "  0.70931977  0.7173121   0.63577759  0.59780174  0.9278602   0.72149485\n",
      "  0.49364752  0.71226627  0.76798981  0.73895538  0.80025291  0.766339\n",
      "  0.71205628  0.8509509   0.77259368  0.87277782  0.86049092  0.87899327\n",
      "  0.88860899  0.92274421  0.72088683  0.95643467  0.70696557  0.59216076\n",
      "  0.82260215]\n",
      "Model saved\n",
      "Minibatch loss at epoch 2 and iter 2699: 0.105329 and the learning rate: 0.100000\n",
      "Minibatch train and validation accuracy: 100.000%, 88.499%\n",
      "Time interval: 1259.3277 seconds, estimated run time for 200 epochs: 70.1841 hours\n",
      "[ 0.83561593  0.74814987  0.71186388  0.9104926   0.83502686  0.79198289\n",
      "  0.84149688  0.73204428  0.74519587  0.90729362  0.93727082  0.94555128\n",
      "  0.93748313  0.94126534  0.98263842  0.94510126  0.66644669  0.98386645\n",
      "  0.8279382   0.93448061  0.86318851  0.86841351  0.97999954  0.92877716\n",
      "  0.81997627  0.87881196  0.89675736  0.78853643  0.97406995  0.96875739\n",
      "  0.93200535  0.92400259  0.95599562  0.97465456  0.94413763  0.9399792\n",
      "  0.91999954  0.98239475  0.86954081  0.98768491  0.82639599  0.6962021\n",
      "  0.90282589]\n",
      "Model saved\n",
      "Minibatch loss at epoch 3 and iter 4049: 0.089071 and the learning rate: 0.100000\n",
      "Minibatch train and validation accuracy: 100.000%, 90.638%\n",
      "Time interval: 1272.5967 seconds, estimated run time for 200 epochs: 70.3560 hours\n",
      "[ 0.78808415  0.71930903  0.72837222  0.90913242  0.86855614  0.8500123\n",
      "  0.84329587  0.82825267  0.76280212  0.9383359   0.94196594  0.93002528\n",
      "  0.95093906  0.95371765  0.9806447   0.97199863  0.66027081  0.98781353\n",
      "  0.96209425  0.95419437  0.89549136  0.85307211  0.97735226  0.94252831\n",
      "  0.89923698  0.90704322  0.96682185  0.94035876  0.98590797  0.98209804\n",
      "  0.95391995  0.90939152  0.98795742  0.98256058  0.94644499  0.95893174\n",
      "  0.92925471  0.98805928  0.8736397   0.98857379  0.87802345  0.66914773\n",
      "  0.9513759 ]\n",
      "Model saved\n",
      "Minibatch loss at epoch 4 and iter 5399: 0.059712 and the learning rate: 0.100000\n",
      "Minibatch train and validation accuracy: 100.000%, 92.399%\n",
      "Time interval: 1263.1178 seconds, estimated run time for 200 epochs: 70.3103 hours\n",
      "[ 0.88430083  0.77685416  0.79105711  0.92952424  0.90781468  0.84164393\n",
      "  0.93006784  0.88516372  0.93043643  0.94869065  0.9804014   0.98373735\n",
      "  0.95057189  0.9696964   0.97227579  0.96473378  0.65638292  0.99575484\n",
      "  0.90050387  0.93642926  0.88864279  0.88935453  0.9902128   0.95536983\n",
      "  0.92712396  0.92575705  0.95685852  0.88595724  0.97069818  0.94237077\n",
      "  0.97529912  0.95413256  0.96294457  0.96465945  0.94696558  0.94638765\n",
      "  0.97218037  0.98503691  0.93357694  0.98020256  0.87872064  0.72174978\n",
      "  0.96632016]\n",
      "Model saved\n",
      "Minibatch loss at epoch 5 and iter 6749: 0.026822 and the learning rate: 0.100000\n",
      "Minibatch train and validation accuracy: 100.000%, 92.115%\n",
      "Time interval: 1265.9369 seconds, estimated run time for 200 epochs: 70.3142 hours\n",
      "[ 0.93609869  0.83163351  0.77330154  0.85066277  0.87778968  0.83505619\n",
      "  0.93828303  0.89580345  0.86433214  0.95967287  0.98565269  0.93586987\n",
      "  0.975227    0.9726854   0.99202347  0.97625417  0.69494241  0.99449122\n",
      "  0.97850782  0.96926779  0.90792793  0.8908506   0.96379602  0.97718203\n",
      "  0.77750564  0.88553864  0.89738846  0.97478527  0.95485973  0.95876491\n",
      "  0.94558603  0.92944354  0.90020227  0.98536295  0.98580277  0.97696501\n",
      "  0.95955658  0.98588014  0.93550032  0.99499702  0.84163356  0.70990467\n",
      "  0.95276529]\n",
      "Minibatch loss at epoch 6 and iter 8099: 0.040035 and the learning rate: 0.100000\n",
      "Minibatch train and validation accuracy: 100.000%, 93.968%\n",
      "Time interval: 1260.6664 seconds, estimated run time for 200 epochs: 70.2680 hours\n",
      "[ 0.87275857  0.81387436  0.78170186  0.90855002  0.94904083  0.87294132\n",
      "  0.98512596  0.94837707  0.92827618  0.97113615  0.97968239  0.96468258\n",
      "  0.97353923  0.96604496  0.98539197  0.94911981  0.66932756  0.99245048\n",
      "  0.96923029  0.97247213  0.88512719  0.91872001  0.98835146  0.93352211\n",
      "  0.97934455  0.92211008  0.97861713  0.97650874  0.98491913  0.98760486\n",
      "  0.99251074  0.97703397  0.94106507  0.99193507  0.97455919  0.9657194\n",
      "  0.95867318  0.98703194  0.94224244  0.99346358  0.88307476  0.733347\n",
      "  0.99026656]\n",
      "Model saved\n",
      "Minibatch loss at epoch 7 and iter 9449: 0.008062 and the learning rate: 0.100000\n",
      "Minibatch train and validation accuracy: 100.000%, 94.983%\n",
      "Time interval: 1260.6745 seconds, estimated run time for 200 epochs: 70.2351 hours\n",
      "[ 0.93178475  0.85745937  0.75106204  0.92930186  0.9268288   0.88681459\n",
      "  0.96111476  0.9331131   0.92755026  0.98007524  0.97570503  0.96963763\n",
      "  0.97625017  0.97749639  0.98450726  0.98207664  0.79495603  0.98473608\n",
      "  0.96990579  0.98859078  0.90943658  0.9542647   0.99298197  0.9447614\n",
      "  0.94808555  0.94666958  0.95565736  0.98144805  0.98761719  0.99032927\n",
      "  0.98910302  0.96921897  0.96075082  0.99373233  0.97264236  0.9732933\n",
      "  0.98250753  0.99199152  0.95872319  0.99447465  0.91806674  0.80528748\n",
      "  0.97648162]\n",
      "Model saved\n",
      "Minibatch loss at epoch 8 and iter 10799: 0.005844 and the learning rate: 0.095000\n",
      "Minibatch train and validation accuracy: 100.000%, 94.348%\n",
      "Time interval: 1266.7039 seconds, estimated run time for 200 epochs: 70.2523 hours\n",
      "[ 0.93608791  0.84945607  0.78412014  0.96274751  0.92388904  0.88360524\n",
      "  0.91977823  0.95808053  0.93983042  0.97655612  0.98303342  0.98177296\n",
      "  0.97466046  0.97835886  0.9940294   0.97060925  0.73116887  0.99600148\n",
      "  0.98867875  0.96117628  0.94887799  0.85175902  0.99300301  0.97521424\n",
      "  0.93932188  0.9443202   0.97021854  0.97429568  0.98958808  0.99081618\n",
      "  0.98219538  0.90846318  0.96658546  0.99199957  0.97000682  0.97396433\n",
      "  0.95560306  0.98199952  0.91500759  0.99725026  0.89874983  0.76760674\n",
      "  0.93123621]\n",
      "Minibatch loss at epoch 9 and iter 12149: 0.009467 and the learning rate: 0.095000\n",
      "Minibatch train and validation accuracy: 100.000%, 94.970%\n",
      "Time interval: 1262.0164 seconds, estimated run time for 200 epochs: 70.2367 hours\n",
      "[ 0.91403502  0.82996249  0.78358155  0.96714485  0.95080298  0.8816734\n",
      "  0.93183893  0.94064742  0.94574732  0.97062534  0.98556447  0.97414589\n",
      "  0.97993344  0.97978735  0.9942739   0.97678918  0.67480969  0.99775118\n",
      "  0.98744303  0.98736012  0.93322772  0.92676455  0.99272585  0.98039168\n",
      "  0.96474719  0.93909371  0.97458619  0.9846909   0.98783773  0.98396987\n",
      "  0.9789108   0.96177214  0.98835725  0.99196738  0.98457658  0.97808719\n",
      "  0.97219467  0.98759872  0.95142066  0.99401748  0.93743742  0.74139708\n",
      "  0.98407835]\n",
      "Minibatch loss at epoch 10 and iter 13499: 0.001736 and the learning rate: 0.095000\n",
      "Minibatch train and validation accuracy: 100.000%, 94.844%\n",
      "Time interval: 1265.2369 seconds, estimated run time for 200 epochs: 70.2421 hours\n",
      "[ 0.95852482  0.88087654  0.75974178  0.95119572  0.94429398  0.91350776\n",
      "  0.92982     0.96276551  0.94976211  0.97360367  0.98724633  0.9866662\n",
      "  0.9802227   0.97450233  0.98740381  0.98471349  0.6754266   0.99774677\n",
      "  0.98690796  0.95163167  0.94571978  0.91801524  0.99251825  0.97736835\n",
      "  0.95391774  0.94389564  0.97936821  0.99028593  0.99104428  0.99006408\n",
      "  0.98880827  0.9720915   0.91128796  0.98998451  0.98656666  0.97592729\n",
      "  0.96328449  0.99052787  0.95884824  0.99550182  0.91825491  0.67805588\n",
      "  0.97055888]\n",
      "Minibatch loss at epoch 11 and iter 14849: 0.002156 and the learning rate: 0.095000\n",
      "Minibatch train and validation accuracy: 100.000%, 95.933%\n",
      "Time interval: 1261.7464 seconds, estimated run time for 200 epochs: 70.2289 hours\n",
      "[ 0.93715858  0.87338042  0.78533369  0.91773856  0.9534117   0.90718073\n",
      "  0.97764629  0.96444178  0.9527123   0.98677933  0.9865399   0.94891852\n",
      "  0.97978735  0.97604436  0.99526024  0.98135382  0.93262839  0.99009359\n",
      "  0.98995936  0.98081607  0.94769496  0.91973025  0.99474823  0.97040796\n",
      "  0.96952575  0.94657624  0.97529596  0.98714101  0.98521394  0.99007893\n",
      "  0.97891074  0.94716293  0.95032036  0.99550182  0.98761708  0.98775262\n",
      "  0.97197121  0.99078411  0.96510977  0.99575269  0.86684889  0.87809712\n",
      "  0.992477  ]\n",
      "Model saved\n",
      "Minibatch loss at epoch 12 and iter 16199: 0.000026 and the learning rate: 0.095000\n",
      "Minibatch train and validation accuracy: 100.000%, 95.145%\n",
      "Time interval: 1258.7485 seconds, estimated run time for 200 epochs: 70.2040 hours\n",
      "[ 0.94767541  0.89187044  0.73914361  0.91992587  0.9173274   0.90240943\n",
      "  0.95662653  0.96348882  0.92048377  0.98333287  0.98216009  0.97772288\n",
      "  0.98184526  0.9820112   0.99427104  0.99033886  0.68334389  0.99725014\n",
      "  0.99021775  0.98640257  0.93753231  0.94777411  0.99423939  0.98537749\n",
      "  0.9618355   0.95630032  0.98087853  0.99002945  0.97653908  0.98787987\n",
      "  0.98712188  0.96899557  0.97773379  0.99500698  0.97416365  0.94490767\n",
      "  0.971205    0.98739231  0.95327061  0.99599349  0.90097946  0.78085798\n",
      "  0.9774245 ]\n",
      "Minibatch loss at epoch 13 and iter 17549: 0.009953 and the learning rate: 0.095000\n",
      "Minibatch train and validation accuracy: 100.000%, 95.486%\n",
      "Time interval: 1259.1831 seconds, estimated run time for 200 epochs: 70.1849 hours\n",
      "[ 0.95867717  0.89754266  0.80368942  0.94120377  0.94804507  0.92631531\n",
      "  0.95965374  0.96731663  0.96681476  0.98573172  0.98150879  0.96520013\n",
      "  0.97918737  0.97711045  0.99700099  0.98618597  0.70818579  0.996503\n",
      "  0.98918736  0.96378511  0.94034117  0.90558112  0.99548602  0.95978767\n",
      "  0.9701795   0.94007248  0.97433317  0.98725909  0.98182666  0.98950475\n",
      "  0.98350114  0.94414717  0.98062247  0.9934963   0.97901708  0.97511655\n",
      "  0.97540528  0.98663318  0.95309615  0.994735    0.93212861  0.78189772\n",
      "  0.98557889]\n",
      "Minibatch loss at epoch 14 and iter 18899: 0.000710 and the learning rate: 0.095000\n",
      "Minibatch train and validation accuracy: 100.000%, 95.079%\n",
      "Time interval: 1260.1074 seconds, estimated run time for 200 epochs: 70.1721 hours\n",
      "[ 0.94507033  0.88375551  0.82766461  0.96957844  0.94982731  0.91590583\n",
      "  0.94417661  0.90525788  0.91762811  0.98257965  0.98831666  0.97273564\n",
      "  0.98095191  0.98388672  0.99649429  0.98154926  0.72507125  0.99674219\n",
      "  0.9815824   0.97918147  0.94273072  0.85903406  0.99500203  0.98309249\n",
      "  0.97084349  0.95012814  0.97803247  0.99347013  0.98398566  0.98885256\n",
      "  0.9886077   0.91802466  0.96198219  0.99499196  0.97158897  0.96907169\n",
      "  0.98294991  0.99178857  0.96602386  0.99475604  0.8845036   0.77398676\n",
      "  0.97003508]\n",
      "Minibatch loss at epoch 15 and iter 20249: 0.000168 and the learning rate: 0.090250\n",
      "Minibatch train and validation accuracy: 100.000%, 95.915%\n",
      "Time interval: 1258.7891 seconds, estimated run time for 200 epochs: 70.1561 hours\n",
      "[ 0.93606347  0.86758959  0.80136549  0.97804344  0.90391254  0.88231039\n",
      "  0.96332002  0.94424623  0.95849007  0.98460722  0.98556447  0.96593332\n",
      "  0.98264104  0.98179007  0.99700403  0.98959315  0.85008574  0.9967584\n",
      "  0.98943609  0.9710387   0.93736792  0.91725719  0.99649072  0.97367722\n",
      "  0.97288954  0.95576489  0.97917652  0.98999453  0.99003941  0.99056083\n",
      "  0.98616552  0.96216697  0.98814183  0.99221647  0.97178483  0.96482611\n",
      "  0.98422045  0.98682827  0.96277368  0.99475348  0.94674814  0.85572088\n",
      "  0.98646569]\n",
      "Minibatch loss at epoch 16 and iter 21599: 0.009324 and the learning rate: 0.090250\n",
      "Minibatch train and validation accuracy: 100.000%, 94.089%\n",
      "Time interval: 1258.3558 seconds, estimated run time for 200 epochs: 70.1407 hours\n",
      "[ 0.95069176  0.87139767  0.75254196  0.94445711  0.93768066  0.8866877\n",
      "  0.85796928  0.93345827  0.95881253  0.98071581  0.98448402  0.98736638\n",
      "  0.97459292  0.97907275  0.99106658  0.97750562  0.68913573  0.99574208\n",
      "  0.95447892  0.97198492  0.93644017  0.93263388  0.99799651  0.98611063\n",
      "  0.95010346  0.94362271  0.95776653  0.95643103  0.98300862  0.99230528\n",
      "  0.97842032  0.96832758  0.89712435  0.99045652  0.98601353  0.97438377\n",
      "  0.97819114  0.98970574  0.96652138  0.99699801  0.83319128  0.70549697\n",
      "  0.91283631]\n",
      "Minibatch loss at epoch 17 and iter 22949: 0.005214 and the learning rate: 0.090250\n",
      "Minibatch train and validation accuracy: 100.000%, 95.005%\n",
      "Time interval: 1263.5896 seconds, estimated run time for 200 epochs: 70.1441 hours\n",
      "[ 0.92509925  0.83798832  0.77863002  0.94192588  0.93202412  0.91367745\n",
      "  0.9584828   0.9786588   0.94607556  0.98655331  0.98191673  0.98667282\n",
      "  0.98163474  0.97958112  0.99476916  0.98838025  0.71799761  0.99398446\n",
      "  0.94867378  0.96985853  0.93336791  0.90557098  0.99624676  0.97264236\n",
      "  0.9588896   0.94908404  0.96632457  0.963269    0.97986197  0.98206782\n",
      "  0.99005914  0.95192033  0.97323555  0.99152493  0.99056083  0.9815824\n",
      "  0.96987325  0.98675287  0.96904528  0.99550182  0.87639791  0.77891105\n",
      "  0.98240274]\n",
      "Minibatch loss at epoch 18 and iter 24299: 0.001416 and the learning rate: 0.090250\n",
      "Minibatch train and validation accuracy: 100.000%, 95.622%\n",
      "Time interval: 1254.7940 seconds, estimated run time for 200 epochs: 70.1200 hours\n",
      "[ 0.95725179  0.88991517  0.81688547  0.95459956  0.94185436  0.91174281\n",
      "  0.9868775   0.96702707  0.96245861  0.98544127  0.98828173  0.97617251\n",
      "  0.98584384  0.98387051  0.99699044  0.97990149  0.79214454  0.99525779\n",
      "  0.98671967  0.97345948  0.92163134  0.90620893  0.9944995   0.9677102\n",
      "  0.98349947  0.95501333  0.98135668  0.99196333  0.97558546  0.98302531\n",
      "  0.98107594  0.93935007  0.91303307  0.99201155  0.99250329  0.98159158\n",
      "  0.98324245  0.99175984  0.96757674  0.99600345  0.90473604  0.75660592\n",
      "  0.99096793]\n",
      "Minibatch loss at epoch 19 and iter 25649: 0.002393 and the learning rate: 0.090250\n",
      "Minibatch train and validation accuracy: 100.000%, 94.500%\n",
      "Time interval: 1259.5122 seconds, estimated run time for 200 epochs: 70.1123 hours\n",
      "[ 0.94439018  0.87486523  0.77231288  0.95518768  0.94140768  0.89483517\n",
      "  0.88730776  0.91381246  0.94041979  0.98778313  0.98680556  0.9741711\n",
      "  0.98334968  0.98361433  0.9979955   0.98838598  0.68526381  0.99500948\n",
      "  0.98996443  0.97552568  0.94281971  0.88139236  0.99674219  0.97830331\n",
      "  0.94409567  0.94095993  0.97844893  0.98858517  0.98035318  0.98883605\n",
      "  0.97012341  0.91034436  0.98592895  0.988083    0.99328816  0.977889\n",
      "  0.96608478  0.99174327  0.96301955  0.99725437  0.85768867  0.72501022\n",
      "  0.95307571]\n",
      "Minibatch loss at epoch 20 and iter 26999: 0.000048 and the learning rate: 0.090250\n",
      "Minibatch train and validation accuracy: 100.000%, 95.153%\n",
      "Time interval: 1261.0967 seconds, estimated run time for 200 epochs: 70.1097 hours\n",
      "[ 0.94389719  0.87665266  0.80265009  0.93093747  0.92790371  0.91366339\n",
      "  0.97676647  0.91699195  0.92886138  0.98306721  0.99195528  0.96561694\n",
      "  0.97980773  0.97913998  0.99649429  0.97133088  0.78024948  0.99499196\n",
      "  0.98967981  0.98542082  0.94185394  0.87865615  0.99574852  0.98461491\n",
      "  0.97378421  0.96056938  0.97889203  0.98639578  0.98371935  0.98812419\n",
      "  0.98934275  0.92049378  0.93429929  0.99196333  0.98882496  0.97870189\n",
      "  0.97676647  0.99099952  0.96664912  0.99675035  0.8761375   0.76534736\n",
      "  0.98749954]\n",
      "Minibatch loss at epoch 21 and iter 28349: 0.000133 and the learning rate: 0.090250\n",
      "Minibatch train and validation accuracy: 100.000%, 94.840%\n",
      "Time interval: 1260.4724 seconds, estimated run time for 200 epochs: 70.1058 hours\n",
      "[ 0.9283883   0.85338616  0.80978066  0.95499355  0.85971022  0.89555722\n",
      "  0.93651122  0.94200736  0.92225289  0.97084874  0.9861244   0.98907059\n",
      "  0.96974307  0.97238904  0.99426526  0.94139749  0.83969861  0.99426526\n",
      "  0.97402877  0.97363234  0.95152092  0.93222922  0.99425381  0.97405732\n",
      "  0.93393427  0.95260006  0.93797302  0.98741776  0.9947691   0.99228615\n",
      "  0.97487146  0.95900393  0.97568119  0.98900497  0.98611754  0.95322996\n",
      "  0.97815901  0.98044145  0.9606334   0.99625605  0.88241649  0.84271365\n",
      "  0.91745043]\n",
      "Final Test accuracy: 98.2%\n",
      "INFO:tensorflow:Restoring parameters from saved-salexnet-aug-eq-n-ens6/best-model-session\n",
      "Test accuracy with the best model: 97.882%\n",
      "f1-scores of classes:\n",
      "[ 0.99173504  0.99237657  0.97499949  0.98113161  0.98541778  0.96338445\n",
      "  0.96193725  0.98998839  0.99005485  0.99999952  0.9961856   0.98333287\n",
      "  0.96783799  0.99720621  0.99999952  0.92105216  0.99009848  0.99999952\n",
      "  0.93369371  0.95999956  0.93749952  0.86227494  0.97907901  0.94043839\n",
      "  0.9777773   0.98416001  0.95744628  0.77241337  0.99337697  0.95698875\n",
      "  0.86642551  0.97277623  0.99173504  0.99290735  0.9916662   0.99871582\n",
      "  0.99173504  0.99999952  0.99710512  0.98876357  0.96174812  0.99999952\n",
      "  0.9782604 ]\n",
      "Total run time 459.1698 minutes\n"
     ]
    }
   ],
   "source": [
    "trainer.run(salexnet, 'saved-salexnet-aug-eq-n-ens6', n_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
