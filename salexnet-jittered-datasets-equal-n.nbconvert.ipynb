{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "from functools import reduce\n",
    "import os\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size = 32\n",
    "pixel_depth = 255.0\n",
    "\n",
    "# load augmented datasets\n",
    "\n",
    "training_file = './datasets/traffic-signs-augmented-data-equal-n/train.p'\n",
    "validation_file='./datasets/traffic-signs-augmented-data-equal-n/valid.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train_aug = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid_aug = pickle.load(f)\n",
    "    \n",
    "X_aug_train, y_aug_train = train_aug['features'], train_aug['labels']\n",
    "X_aug_valid, y_aug_valid = valid_aug['features'], valid_aug['labels']\n",
    "\n",
    "# normalize\n",
    "X_aug_train_norm = ((X_aug_train.astype(np.float32)-(pixel_depth*0.5)) / (pixel_depth*0.5))\n",
    "X_aug_valid_norm = ((X_aug_valid.astype(np.float32)-(pixel_depth*0.5)) / (pixel_depth*0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_file = './datasets/traffic-signs-data/train.p'\n",
    "validation_file='./datasets/traffic-signs-data/valid.p'\n",
    "testing_file = './datasets/traffic-signs-data/test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "\n",
    "X_train_norm =  (X_train.astype(np.float32)-(pixel_depth * 0.5)) / (pixel_depth*0.5)\n",
    "X_valid_norm =  (X_valid.astype(np.float32)-(pixel_depth * 0.5)) / (pixel_depth*0.5)\n",
    "X_test_norm =  (X_test.astype(np.float32)-(pixel_depth * 0.5)) / (pixel_depth*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scaledalexnet import *\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trainer\n",
    "\n",
    "num_labels = 43\n",
    "batch_size = 64\n",
    "\n",
    "# pack datasets into a tuple\n",
    "datasets = (\n",
    "    (X_aug_train_norm, y_aug_train), \n",
    "    (X_aug_valid_norm, y_aug_valid), \n",
    "    (X_test_norm, y_test)\n",
    "    )\n",
    "\n",
    "# trainer instance\n",
    "trainer = Trainer(datasets=datasets, batch_size=batch_size, n_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "salexnet = ScaledAlexNet(\n",
    "    num_labels, image_size=32, learning_rate=0.1, \n",
    "    batch_size=batch_size, decay_interval=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at epoch 1 and iter 1349: 0.509541 and the learning rate: 0.100000\n",
      "Minibatch train and validation accuracy: 95.312%, 77.725%\n",
      "Time interval: 1199.4090 seconds, estimated run time for 200 epochs: 66.6338 hours\n",
      "[ 0.72037441  0.54715633  0.61938632  0.76736861  0.75435156  0.652964\n",
      "  0.71947765  0.64768797  0.59927565  0.78631932  0.88200617  0.72378719\n",
      "  0.84915215  0.88295954  0.91680211  0.90565115  0.6590333   0.93262899\n",
      "  0.79688317  0.82913375  0.69207418  0.59911615  0.87463242  0.80150115\n",
      "  0.55741161  0.70710105  0.73076886  0.76391816  0.82282239  0.71893603\n",
      "  0.75126314  0.67077875  0.91140413  0.89752603  0.85763621  0.85833752\n",
      "  0.93462062  0.96003872  0.74545407  0.96141505  0.78867495  0.62279248\n",
      "  0.8068617 ]\n",
      "Model saved\n",
      "Minibatch loss at epoch 2 and iter 2699: 0.060130 and the learning rate: 0.100000\n",
      "Minibatch train and validation accuracy: 100.000%, 89.673%\n",
      "Time interval: 1169.7823 seconds, estimated run time for 200 epochs: 65.8109 hours\n",
      "[ 0.83160222  0.67487639  0.73627961  0.86351657  0.86362344  0.76017022\n",
      "  0.92917526  0.79099506  0.81546521  0.92643142  0.9333005   0.96996725\n",
      "  0.92080981  0.92237854  0.88001716  0.92653483  0.68143278  0.88673449\n",
      "  0.93118989  0.92511803  0.86896122  0.86057645  0.95449024  0.89006877\n",
      "  0.94915205  0.87938547  0.94512886  0.97760767  0.96907675  0.9349913\n",
      "  0.94683379  0.9342742   0.94734299  0.97154319  0.93046081  0.94988847\n",
      "  0.96149081  0.97967333  0.88882869  0.98562372  0.86367261  0.73715442\n",
      "  0.96562064]\n",
      "Model saved\n",
      "Minibatch loss at epoch 3 and iter 4049: 0.021473 and the learning rate: 0.100000\n",
      "Minibatch train and validation accuracy: 100.000%, 91.702%\n",
      "Time interval: 1677.6807 seconds, estimated run time for 200 epochs: 74.9421 hours\n",
      "[ 0.79666889  0.7759155   0.76276851  0.94185168  0.83287746  0.83111411\n",
      "  0.85511565  0.88827288  0.89123821  0.95983583  0.95116407  0.96808726\n",
      "  0.95796579  0.94445837  0.98462254  0.96731985  0.82966352  0.98082554\n",
      "  0.92555189  0.96372002  0.89596665  0.86961246  0.99046618  0.96180063\n",
      "  0.93864977  0.90680861  0.94536656  0.95200789  0.97516102  0.9681493\n",
      "  0.9440223   0.90960014  0.9744364   0.98028404  0.90928054  0.92095369\n",
      "  0.917934    0.98430055  0.86004466  0.98739135  0.88369632  0.73199368\n",
      "  0.97316408]\n",
      "Model saved\n",
      "Minibatch loss at epoch 4 and iter 5399: 0.156360 and the learning rate: 0.100000\n",
      "Minibatch train and validation accuracy: 98.438%, 93.145%\n",
      "Time interval: 1516.0693 seconds, estimated run time for 200 epochs: 77.2631 hours\n",
      "[ 0.87777996  0.79089332  0.7805413   0.96914744  0.87972611  0.85749096\n",
      "  0.90262985  0.90983754  0.8976959   0.96351063  0.97042555  0.93080825\n",
      "  0.96161467  0.95605195  0.98201478  0.96385497  0.87067962  0.99028116\n",
      "  0.97778851  0.95992178  0.90712696  0.84106094  0.98766631  0.92070204\n",
      "  0.93333286  0.92466569  0.96637988  0.98407918  0.97907901  0.98058438\n",
      "  0.95003724  0.88045669  0.95349908  0.98298252  0.96837896  0.96791929\n",
      "  0.94706815  0.99448299  0.92487603  0.99303091  0.81908393  0.82842493\n",
      "  0.98405415]\n",
      "Model saved\n",
      "Minibatch loss at epoch 5 and iter 6749: 0.004838 and the learning rate: 0.100000\n",
      "Minibatch train and validation accuracy: 98.438%, 93.582%\n",
      "Time interval: 1561.3396 seconds, estimated run time for 200 epochs: 79.1587 hours\n",
      "[ 0.91882998  0.79532772  0.78547055  0.92175883  0.94409281  0.89106864\n",
      "  0.9440223   0.92507643  0.88647169  0.95860833  0.97435844  0.97455925\n",
      "  0.96395898  0.95159578  0.99105316  0.93236893  0.81737548  0.99452138\n",
      "  0.92608321  0.95953709  0.92746627  0.88063318  0.99000454  0.96954644\n",
      "  0.93258983  0.94865096  0.90708327  0.96694165  0.99129087  0.98713464\n",
      "  0.97131598  0.94386846  0.92079622  0.98607612  0.95502347  0.97673208\n",
      "  0.9618721   0.99449128  0.9101631   0.99724609  0.87976956  0.75914085\n",
      "  0.97567111]\n",
      "Model saved\n",
      "Minibatch loss at epoch 6 and iter 8099: 0.075004 and the learning rate: 0.100000\n",
      "Minibatch train and validation accuracy: 98.438%, 94.464%\n",
      "Time interval: 817.3194 seconds, estimated run time for 200 epochs: 73.5333 hours\n",
      "[ 0.88476127  0.80693972  0.79999954  0.9477945   0.95559365  0.9016732\n",
      "  0.98056531  0.95927334  0.93219441  0.96485895  0.98207122  0.97116286\n",
      "  0.97174251  0.96958894  0.99524593  0.9758237   0.73971701  0.9962523\n",
      "  0.97018921  0.97075975  0.91100276  0.88239652  0.99526018  0.9439919\n",
      "  0.96491182  0.9399159   0.97902048  0.97523087  0.95992273  0.97209489\n",
      "  0.97598749  0.95032567  0.98255903  0.9741056   0.97578824  0.96905613\n",
      "  0.96633518  0.98829335  0.91278392  0.986884    0.8995738   0.80324411\n",
      "  0.98918194]\n",
      "Model saved\n",
      "Minibatch loss at epoch 7 and iter 9449: 0.007259 and the learning rate: 0.100000\n",
      "Minibatch train and validation accuracy: 100.000%, 93.580%\n",
      "Time interval: 759.0248 seconds, estimated run time for 200 epochs: 69.0526 hours\n",
      "[ 0.85802555  0.78789508  0.80189419  0.96792954  0.87731797  0.91254699\n",
      "  0.91972113  0.9569968   0.90353394  0.97309363  0.97425699  0.9716931\n",
      "  0.96959245  0.95739686  0.99724609  0.97846252  0.77869052  0.99650127\n",
      "  0.98293984  0.92193949  0.92694253  0.87214321  0.99574637  0.97061706\n",
      "  0.92802078  0.94316953  0.97845954  0.96305245  0.9790687   0.98932165\n",
      "  0.96788377  0.94667912  0.95806324  0.98563105  0.98465294  0.96912777\n",
      "  0.91108024  0.9896695   0.93446362  0.99599755  0.77865219  0.7648527\n",
      "  0.96386117]\n",
      "Minibatch loss at epoch 8 and iter 10799: 0.000725 and the learning rate: 0.095000\n",
      "Minibatch train and validation accuracy: 100.000%, 94.540%\n",
      "Time interval: 757.5841 seconds, estimated run time for 200 epochs: 65.6820 hours\n",
      "[ 0.89126843  0.82141811  0.80234456  0.94134229  0.93175173  0.88266337\n",
      "  0.90884244  0.93352145  0.93365568  0.97291833  0.98122609  0.97881722\n",
      "  0.97261614  0.95582485  0.99525309  0.9720394   0.83594155  0.99550182\n",
      "  0.98771578  0.9667713   0.9257381   0.87874573  0.98807108  0.96536314\n",
      "  0.95696944  0.96196151  0.96972626  0.99276578  0.97249889  0.98812425\n",
      "  0.98543519  0.92007387  0.95372087  0.98828179  0.98880267  0.97227681\n",
      "  0.97226232  0.99146533  0.95585561  0.99550623  0.90319157  0.75996071\n",
      "  0.96058047]\n",
      "Model saved\n",
      "Minibatch loss at epoch 9 and iter 12149: 0.019928 and the learning rate: 0.095000\n",
      "Minibatch train and validation accuracy: 98.438%, 93.168%\n",
      "Time interval: 757.8699 seconds, estimated run time for 200 epochs: 63.0622 hours\n",
      "[ 0.93685424  0.82913858  0.7885645   0.95842302  0.93109536  0.88618785\n",
      "  0.71288496  0.96419519  0.93843466  0.97222173  0.98727816  0.91609305\n",
      "  0.97389048  0.97101039  0.99476135  0.982059    0.83241951  0.99824911\n",
      "  0.98875791  0.95413232  0.93336767  0.88768554  0.99180084  0.97500569\n",
      "  0.92258012  0.95373619  0.96649498  0.98600656  0.95714581  0.98715645\n",
      "  0.96374571  0.93701875  0.95032036  0.98756796  0.9758237   0.97896522\n",
      "  0.97212666  0.98993909  0.94646072  0.99750084  0.84701955  0.32425025\n",
      "  0.99144822]\n",
      "Minibatch loss at epoch 10 and iter 13499: 0.014345 and the learning rate: 0.095000\n",
      "Minibatch train and validation accuracy: 100.000%, 93.915%\n",
      "Time interval: 756.8081 seconds, estimated run time for 200 epochs: 60.9605 hours\n",
      "[ 0.9111982   0.85584819  0.80889857  0.96192724  0.94625723  0.93249321\n",
      "  0.88549572  0.96368593  0.91691947  0.98127294  0.98661232  0.98057491\n",
      "  0.9597311   0.94717991  0.99304473  0.93783677  0.79880011  0.99700105\n",
      "  0.96112686  0.94802046  0.93372166  0.90094292  0.98617923  0.97722721\n",
      "  0.9704529   0.95830131  0.96831203  0.97564644  0.98013192  0.98664641\n",
      "  0.9879995   0.96445394  0.88003474  0.98705125  0.96544671  0.95698351\n",
      "  0.92553884  0.9927513   0.92992222  0.99402344  0.86866009  0.65948337\n",
      "  0.92079693]\n",
      "Minibatch loss at epoch 11 and iter 14849: 0.000189 and the learning rate: 0.095000\n",
      "Minibatch train and validation accuracy: 100.000%, 95.593%\n",
      "Time interval: 763.0831 seconds, estimated run time for 200 epochs: 59.2726 hours\n",
      "[ 0.92709047  0.85420102  0.81346214  0.96264112  0.92453706  0.91070527\n",
      "  0.96034557  0.9503988   0.91489828  0.9810375   0.98504442  0.9753353\n",
      "  0.96854979  0.97348624  0.99274051  0.98135382  0.90938729  0.9947691\n",
      "  0.9818899   0.9711628   0.93616974  0.90981174  0.99476659  0.97454858\n",
      "  0.95518452  0.96600306  0.96383142  0.98649955  0.98813593  0.99475086\n",
      "  0.98640251  0.95800734  0.94829172  0.9894467   0.98607612  0.97606671\n",
      "  0.95739537  0.98968506  0.94972885  0.9962486   0.90458065  0.83880556\n",
      "  0.98815185]\n",
      "Model saved\n",
      "Minibatch loss at epoch 12 and iter 16199: 0.048224 and the learning rate: 0.095000\n",
      "Minibatch train and validation accuracy: 100.000%, 93.310%\n",
      "Time interval: 763.2627 seconds, estimated run time for 200 epochs: 57.8668 hours\n",
      "[ 0.94673926  0.86326748  0.77948666  0.89797705  0.94454247  0.88872713\n",
      "  0.98171896  0.92046767  0.87049925  0.97922802  0.98804134  0.98420483\n",
      "  0.97371668  0.96489829  0.99550182  0.95303887  0.71602523  0.9987511\n",
      "  0.80041498  0.97318333  0.91803229  0.88876754  0.99025685  0.97228307\n",
      "  0.9358086   0.95483172  0.94678766  0.70527297  0.97532326  0.97109497\n",
      "  0.98836297  0.93415689  0.97383177  0.98661327  0.97435844  0.96676391\n",
      "  0.97280025  0.99274409  0.93967712  0.99674058  0.87076879  0.78691196\n",
      "  0.98262358]\n",
      "Minibatch loss at epoch 13 and iter 17549: 0.002363 and the learning rate: 0.095000\n",
      "Minibatch train and validation accuracy: 100.000%, 93.797%\n",
      "Time interval: 754.7110 seconds, estimated run time for 200 epochs: 56.6408 hours\n",
      "[ 0.91800958  0.83256644  0.79999959  0.9807117   0.89706612  0.90535927\n",
      "  0.73276776  0.92311215  0.8911767   0.98427707  0.97810525  0.98486686\n",
      "  0.97253257  0.97184461  0.99524122  0.997253    0.90310246  0.99452138\n",
      "  0.98822892  0.96916687  0.92643881  0.86106396  0.99574852  0.9638257\n",
      "  0.93315595  0.9630177   0.98476857  0.99549055  0.96240914  0.99600947\n",
      "  0.97156698  0.92771316  0.9945296   0.97854453  0.98411858  0.97624362\n",
      "  0.94781739  0.99251449  0.94924074  0.99081153  0.8759973   0.51298445\n",
      "  0.96453488]\n",
      "Minibatch loss at epoch 14 and iter 18899: 0.000297 and the learning rate: 0.095000\n",
      "Minibatch train and validation accuracy: 100.000%, 95.192%\n",
      "Time interval: 766.2870 seconds, estimated run time for 200 epochs: 55.6358 hours\n",
      "[ 0.93918872  0.84689981  0.84114677  0.95771223  0.92491251  0.91488791\n",
      "  0.96083128  0.92785376  0.90751815  0.98335809  0.98472273  0.97415847\n",
      "  0.96909225  0.97643733  0.99675202  0.98327547  0.97910243  0.98940945\n",
      "  0.97087812  0.97034472  0.92226285  0.91958177  0.9915418   0.97800791\n",
      "  0.9245581   0.95922977  0.96141666  0.97910255  0.97628891  0.98530465\n",
      "  0.96752256  0.96731007  0.84399366  0.99173504  0.98173583  0.97659475\n",
      "  0.97556162  0.99624288  0.95469618  0.99725026  0.91044331  0.7413789\n",
      "  0.98915464]\n",
      "Minibatch loss at epoch 15 and iter 20249: 0.021239 and the learning rate: 0.090250\n",
      "Minibatch train and validation accuracy: 100.000%, 95.125%\n",
      "Time interval: 766.8971 seconds, estimated run time for 200 epochs: 54.7671 hours\n",
      "[ 0.92207432  0.84415191  0.81421971  0.96337306  0.92467868  0.91964018\n",
      "  0.9856959   0.94346744  0.93587124  0.98372918  0.98876357  0.97987193\n",
      "  0.98094237  0.95694977  0.99700403  0.96899176  0.81011856  0.99825084\n",
      "  0.97342473  0.95940381  0.93111593  0.88731194  0.99427956  0.97442156\n",
      "  0.95989668  0.96574426  0.98356527  0.98229593  0.97821254  0.99058425\n",
      "  0.98909223  0.93551397  0.91685754  0.98879719  0.98061585  0.98456889\n",
      "  0.96610123  0.99599552  0.95125657  0.99750084  0.8803643   0.78627312\n",
      "  0.99327469]\n",
      "Minibatch loss at epoch 16 and iter 21599: 0.007475 and the learning rate: 0.090250\n",
      "Minibatch train and validation accuracy: 100.000%, 95.101%\n",
      "Time interval: 761.7110 seconds, estimated run time for 200 epochs: 53.9890 hours\n",
      "[ 0.93521076  0.84957957  0.77670443  0.95554447  0.96580517  0.91614711\n",
      "  0.96927601  0.94465786  0.92795348  0.97969371  0.98586529  0.95965362\n",
      "  0.98131031  0.96969646  0.99749702  0.97347236  0.91628236  0.99724334\n",
      "  0.94673944  0.97580004  0.92639959  0.90976202  0.99300653  0.98107529\n",
      "  0.97472507  0.95872325  0.97529596  0.96391702  0.97559738  0.9893375\n",
      "  0.99327475  0.95395011  0.85959959  0.98996943  0.97566921  0.97530818\n",
      "  0.96475083  0.99474299  0.94842649  0.99674875  0.87555861  0.77205241\n",
      "  0.98047119]\n",
      "Minibatch loss at epoch 17 and iter 22949: 0.003207 and the learning rate: 0.090250\n",
      "Minibatch train and validation accuracy: 100.000%, 95.653%\n",
      "Time interval: 781.3791 seconds, estimated run time for 200 epochs: 53.3667 hours\n",
      "[ 0.95735246  0.8874132   0.75668979  0.92108864  0.95308596  0.90398628\n",
      "  0.91822118  0.95281392  0.93585235  0.98520142  0.98758644  0.98011249\n",
      "  0.97916621  0.97642541  0.99599349  0.98109454  0.88205653  0.99576539\n",
      "  0.98372924  0.98836869  0.93787324  0.89148074  0.99327475  0.97726095\n",
      "  0.95572871  0.96516341  0.96364915  0.98800552  0.98741001  0.99600756\n",
      "  0.98422045  0.93882364  0.97369653  0.98782557  0.98910302  0.98280543\n",
      "  0.9776901   0.99724472  0.96053255  0.99674058  0.92981088  0.79430801\n",
      "  0.99200755]\n",
      "Model saved\n",
      "Minibatch loss at epoch 18 and iter 24299: 0.000019 and the learning rate: 0.090250\n",
      "Minibatch train and validation accuracy: 100.000%, 95.966%\n",
      "Time interval: 776.8525 seconds, estimated run time for 200 epochs: 52.7996 hours\n",
      "[ 0.94387954  0.87887567  0.83487999  0.95573062  0.94690222  0.91982669\n",
      "  0.90439469  0.95288152  0.92834067  0.98466134  0.98782563  0.972709\n",
      "  0.97974634  0.97626209  0.99500698  0.98400152  0.96153796  0.99700403\n",
      "  0.98700601  0.98206776  0.93853819  0.90327734  0.99749577  0.97606659\n",
      "  0.95956403  0.96681929  0.96884918  0.99649429  0.98396987  0.99329144\n",
      "  0.97867078  0.95073247  0.95165467  0.99274045  0.98601353  0.97881722\n",
      "  0.96148241  0.99447459  0.96504158  0.99750084  0.90388173  0.82246029\n",
      "  0.99220866]\n",
      "Model saved\n",
      "Minibatch loss at epoch 19 and iter 25649: 0.000549 and the learning rate: 0.090250\n",
      "Minibatch train and validation accuracy: 100.000%, 95.349%\n",
      "Time interval: 771.1681 seconds, estimated run time for 200 epochs: 52.2756 hours\n",
      "[ 0.92220604  0.84632593  0.80092418  0.95608312  0.93517131  0.88710368\n",
      "  0.96561694  0.9481082   0.93025565  0.97620791  0.97929972  0.97527486\n",
      "  0.97883016  0.97621411  0.99425954  0.99230146  0.87668109  0.99502194\n",
      "  0.98795736  0.98320943  0.91833073  0.93812531  0.99549729  0.97297251\n",
      "  0.93627143  0.94249821  0.97425699  0.99450505  0.9631409   0.98016518\n",
      "  0.94426024  0.97651124  0.9631409   0.98757404  0.97284025  0.9784382\n",
      "  0.97336876  0.99774784  0.94903922  0.99750078  0.84836584  0.86242723\n",
      "  0.98452908]\n",
      "Minibatch loss at epoch 20 and iter 26999: 0.001571 and the learning rate: 0.090250\n",
      "Minibatch train and validation accuracy: 100.000%, 94.432%\n",
      "Time interval: 758.9452 seconds, estimated run time for 200 epochs: 51.7700 hours\n",
      "[ 0.89724773  0.86901915  0.84641021  0.96405262  0.84862733  0.9350121\n",
      "  0.95945233  0.94159329  0.90054303  0.97554785  0.9904995   0.98683834\n",
      "  0.97497451  0.96576166  0.99650127  0.97559732  0.771595    0.99899852\n",
      "  0.96308845  0.93542302  0.93909782  0.85897744  0.99353504  0.97553694\n",
      "  0.96569461  0.9581725   0.98181772  0.98893315  0.98958284  0.98984349\n",
      "  0.98614502  0.93736655  0.85129905  0.99053735  0.98544234  0.99223596\n",
      "  0.99032456  0.9987492   0.96572685  0.99675196  0.90573066  0.67116636\n",
      "  0.97543454]\n",
      "Minibatch loss at epoch 21 and iter 28349: 0.001313 and the learning rate: 0.090250\n",
      "Minibatch train and validation accuracy: 100.000%, 95.685%\n",
      "Time interval: 756.3132 seconds, estimated run time for 200 epochs: 51.3055 hours\n",
      "[ 0.94328737  0.86965537  0.81680632  0.95145124  0.96733934  0.91855699\n",
      "  0.81976575  0.95754898  0.94384837  0.97878659  0.98150384  0.97075969\n",
      "  0.97949946  0.96932781  0.99522924  0.98399365  0.97702861  0.99750197\n",
      "  0.99168926  0.98881942  0.9434936   0.91151339  0.9977501   0.95087421\n",
      "  0.95731336  0.97142804  0.97575408  0.99498951  0.9825334   0.99451876\n",
      "  0.97266912  0.97605485  0.97532326  0.99103987  0.98661989  0.98497695\n",
      "  0.97892112  0.99673569  0.96376204  0.99725157  0.88410372  0.74121177\n",
      "  0.9799335 ]\n",
      "Minibatch loss at epoch 22 and iter 29699: 0.000195 and the learning rate: 0.090250\n",
      "Minibatch train and validation accuracy: 100.000%, 96.089%\n",
      "Time interval: 763.3999 seconds, estimated run time for 200 epochs: 50.9013 hours\n",
      "[ 0.93481362  0.86201257  0.8468464   0.95861351  0.94298726  0.92284143\n",
      "  0.93183374  0.93540001  0.94448698  0.98254317  0.98216891  0.97224879\n",
      "  0.97945845  0.9743585   0.99524122  0.991813    0.95479441  0.9969995\n",
      "  0.98179048  0.97007978  0.93343842  0.91592532  0.9969995   0.97395533\n",
      "  0.96749175  0.94807845  0.9791559   0.9878599   0.9869228   0.99052787\n",
      "  0.97801876  0.95889026  0.97276211  0.98535573  0.98055577  0.9857102\n",
      "  0.98013192  0.99551076  0.95181298  0.99575269  0.91090584  0.86224043\n",
      "  0.99725294]\n",
      "Model saved\n",
      "Minibatch loss at epoch 23 and iter 31049: 0.000020 and the learning rate: 0.085737\n",
      "Minibatch train and validation accuracy: 100.000%, 95.303%\n",
      "Time interval: 770.0218 seconds, estimated run time for 200 epochs: 50.5481 hours\n",
      "[ 0.93207943  0.87227857  0.83287323  0.9536767   0.97496849  0.9357245\n",
      "  0.91930592  0.98266417  0.96549952  0.98296547  0.99071932  0.98223931\n",
      "  0.98003495  0.97720313  0.99625975  0.9813171   0.79481727  0.99824995\n",
      "  0.98875237  0.9550879   0.9381085   0.83290142  0.99625975  0.96208024\n",
      "  0.96944755  0.96229666  0.97624892  0.9944858   0.9832508   0.98690987\n",
      "  0.9915123   0.90954959  0.96616673  0.989016    0.97989529  0.97700816\n",
      "  0.95775282  0.99649251  0.95882607  0.99600559  0.8798731   0.76635039\n",
      "  0.97200054]\n",
      "Minibatch loss at epoch 24 and iter 32399: 0.000718 and the learning rate: 0.085737\n",
      "Minibatch train and validation accuracy: 100.000%, 95.479%\n",
      "Time interval: 764.2328 seconds, estimated run time for 200 epochs: 50.2110 hours\n",
      "[ 0.93159091  0.86897933  0.8310653   0.96173233  0.95491058  0.91806328\n",
      "  0.90776879  0.9537257   0.93419313  0.9800095   0.99050903  0.97630048\n",
      "  0.97637355  0.98105532  0.98910844  0.98134464  0.87098539  0.9960075\n",
      "  0.9844529   0.97177565  0.93210477  0.91132706  0.99550623  0.97579008\n",
      "  0.94024277  0.96264023  0.96531463  0.99549276  0.97605032  0.9903245\n",
      "  0.9710387   0.97557312  0.97274894  0.98834562  0.9873476   0.97849149\n",
      "  0.98467577  0.99675035  0.9527005   0.99599957  0.83863831  0.8109678\n",
      "  0.96424824]\n",
      "Minibatch loss at epoch 25 and iter 33749: 0.005564 and the learning rate: 0.085737\n",
      "Minibatch train and validation accuracy: 100.000%, 95.361%\n",
      "Time interval: 765.2664 seconds, estimated run time for 200 epochs: 49.9032 hours\n",
      "[ 0.93323851  0.85576618  0.79509586  0.90694457  0.95995998  0.92526108\n",
      "  0.96548325  0.97809809  0.94392473  0.98161906  0.98900497  0.97156698\n",
      "  0.97848874  0.96567577  0.99576116  0.97178942  0.81971031  0.99675035\n",
      "  0.97533256  0.94696921  0.93206406  0.90487564  0.9910754   0.98286521\n",
      "  0.94913429  0.96315074  0.97921771  0.9897418   0.96803832  0.99126047\n",
      "  0.98855674  0.97639704  0.94403726  0.98900497  0.98113161  0.97923827\n",
      "  0.9696818   0.99400556  0.9564091   0.99774897  0.88859576  0.79556429\n",
      "  0.99574637]\n",
      "Minibatch loss at epoch 26 and iter 35099: 0.000145 and the learning rate: 0.085737\n",
      "Minibatch train and validation accuracy: 100.000%, 95.224%\n",
      "Time interval: 757.3007 seconds, estimated run time for 200 epochs: 49.6020 hours\n",
      "[ 0.90913355  0.84590119  0.84131777  0.9550665   0.92609161  0.92644858\n",
      "  0.83668292  0.97795343  0.95385337  0.9716953   0.98208022  0.98059404\n",
      "  0.98066735  0.97293109  0.99501199  0.9842515   0.94481075  0.99799651\n",
      "  0.96671516  0.97626573  0.93269944  0.8858369   0.99302399  0.9677887\n",
      "  0.93986714  0.96667469  0.9675684   0.9773705   0.98618597  0.99500698\n",
      "  0.98952043  0.92685157  0.97990143  0.99195528  0.97919708  0.98315954\n",
      "  0.98593587  0.99497443  0.95526195  0.99625605  0.88981241  0.70467186\n",
      "  0.98999453]\n",
      "Minibatch loss at epoch 27 and iter 36449: 0.000021 and the learning rate: 0.085737\n",
      "Minibatch train and validation accuracy: 100.000%, 94.939%\n",
      "Time interval: 755.9969 seconds, estimated run time for 200 epochs: 49.3204 hours\n",
      "[ 0.93902683  0.86271322  0.76735133  0.92176276  0.95337003  0.89503765\n",
      "  0.96190894  0.95753413  0.9271875   0.95912361  0.98271066  0.98447084\n",
      "  0.96732652  0.96371436  0.99153763  0.96850729  0.82916862  0.99551523\n",
      "  0.97845954  0.97438353  0.92636025  0.85977614  0.99427104  0.9595539\n",
      "  0.96142852  0.96222007  0.98037213  0.99699044  0.98109454  0.9905656\n",
      "  0.98934805  0.92455888  0.9521538   0.98709631  0.97738397  0.9725486\n",
      "  0.97595638  0.99573994  0.94287926  0.99551523  0.88223088  0.79059881\n",
      "  0.99130392]\n",
      "Minibatch loss at epoch 28 and iter 37799: 0.000384 and the learning rate: 0.085737\n",
      "Minibatch train and validation accuracy: 100.000%, 95.826%\n",
      "Time interval: 761.1362 seconds, estimated run time for 200 epochs: 49.0692 hours\n",
      "[ 0.87585104  0.81912863  0.82703274  0.96750689  0.94683868  0.94290644\n",
      "  0.99119449  0.9723779   0.95152557  0.97949052  0.98823482  0.98661995\n",
      "  0.98177171  0.9673298   0.99626166  0.97297251  0.91495073  0.9970085\n",
      "  0.98401552  0.95433855  0.93252456  0.8838352   0.99426818  0.98139375\n",
      "  0.96595478  0.96176499  0.98161906  0.99250704  0.984236    0.98739141\n",
      "  0.98739761  0.93164146  0.96777278  0.98718226  0.95299399  0.96698982\n",
      "  0.98416579  0.99040359  0.94390762  0.99323094  0.89751834  0.89930922\n",
      "  0.99220079]\n",
      "Minibatch loss at epoch 29 and iter 39149: 0.000107 and the learning rate: 0.085737\n",
      "Minibatch train and validation accuracy: 100.000%, 95.849%\n",
      "Time interval: 758.5360 seconds, estimated run time for 200 epochs: 48.8302 hours\n",
      "[ 0.93652648  0.86269313  0.84945005  0.97034472  0.94706404  0.93899679\n",
      "  0.89177054  0.95861351  0.93264997  0.98605525  0.99174327  0.95986485\n",
      "  0.97719163  0.9708339   0.9962523   0.9753353   0.96966535  0.99825084\n",
      "  0.98776484  0.98180872  0.93312222  0.89614511  0.99576116  0.97854447\n",
      "  0.93855882  0.96717119  0.97290593  0.99249578  0.97418362  0.99328476\n",
      "  0.98833984  0.94398046  0.96735144  0.98539191  0.98411864  0.9779644\n",
      "  0.96896166  0.9962486   0.94454622  0.9947691   0.87889957  0.8684631\n",
      "  0.96491182]\n",
      "Minibatch loss at epoch 30 and iter 40499: 0.000024 and the learning rate: 0.081451\n",
      "Minibatch train and validation accuracy: 100.000%, 96.406%\n",
      "Time interval: 759.9394 seconds, estimated run time for 200 epochs: 48.6099 hours\n",
      "[ 0.96034777  0.88708788  0.83669984  0.95752299  0.9671098   0.94088858\n",
      "  0.94599044  0.96499711  0.93835062  0.98946261  0.98833412  0.97652757\n",
      "  0.98074472  0.97174811  0.99401146  0.98789775  0.93532026  0.99750572\n",
      "  0.97677821  0.98544961  0.93680841  0.89960003  0.99550402  0.97971255\n",
      "  0.96248335  0.96813619  0.9750551   0.98660553  0.98861337  0.99426818\n",
      "  0.98984349  0.93696636  0.97228926  0.99129087  0.97430634  0.9711628\n",
      "  0.98592198  0.99425101  0.9637143   0.99426818  0.9261443   0.86486441\n",
      "  0.99451047]\n",
      "Model saved\n",
      "Minibatch loss at epoch 31 and iter 41849: 0.002066 and the learning rate: 0.081451\n",
      "Minibatch train and validation accuracy: 100.000%, 95.787%\n",
      "Time interval: 766.4557 seconds, estimated run time for 200 epochs: 48.4154 hours\n",
      "[ 0.92857099  0.85462022  0.83160919  0.96544963  0.95893729  0.9257251\n",
      "  0.9813171   0.95612514  0.93869495  0.97238618  0.98051739  0.99451602\n",
      "  0.97878742  0.96900356  0.9947691   0.98764163  0.77478534  0.9980005\n",
      "  0.97850209  0.98223931  0.93565351  0.89152676  0.99750328  0.96800923\n",
      "  0.94893903  0.96940774  0.98555005  0.98915464  0.98984343  0.99081612\n",
      "  0.98739761  0.93494159  0.97894174  0.99276948  0.98851675  0.98677266\n",
      "  0.98058444  0.99699956  0.95742416  0.99551523  0.92902851  0.81383735\n",
      "  0.99219686]\n",
      "Minibatch loss at epoch 32 and iter 43199: 0.000002 and the learning rate: 0.081451\n",
      "Minibatch train and validation accuracy: 100.000%, 95.847%\n",
      "Time interval: 758.5892 seconds, estimated run time for 200 epochs: 48.2194 hours\n",
      "[ 0.94983232  0.88527161  0.82057029  0.92885423  0.97433317  0.93496883\n",
      "  0.86543828  0.97600746  0.95211923  0.98729086  0.99052322  0.96969652\n",
      "  0.98172659  0.97193831  0.99452138  0.98472857  0.93730032  0.99849802\n",
      "  0.97987527  0.98762941  0.933999    0.91958272  0.99600953  0.98287374\n",
      "  0.94850188  0.95692027  0.95673144  0.98822296  0.98519927  0.99254054\n",
      "  0.98555726  0.95007151  0.96500069  0.99051374  0.98885256  0.97761333\n",
      "  0.97648162  0.99298197  0.9578262   0.99452138  0.91753852  0.76391929\n",
      "  0.98891634]\n",
      "Minibatch loss at epoch 33 and iter 44549: 0.000032 and the learning rate: 0.081451\n",
      "Minibatch train and validation accuracy: 100.000%, 96.735%\n",
      "Time interval: 754.8316 seconds, estimated run time for 200 epochs: 48.0290 hours\n",
      "[ 0.92023927  0.86463076  0.83010346  0.95165467  0.96909714  0.93130094\n",
      "  0.95846295  0.97640073  0.9486475   0.99120778  0.991768    0.97895205\n",
      "  0.98573166  0.97743934  0.9957633   0.98375136  0.98862153  0.99824727\n",
      "  0.98892754  0.98037243  0.92735898  0.92372161  0.99850023  0.97850215\n",
      "  0.95230603  0.96966588  0.9724133   0.99526489  0.98690337  0.99304128\n",
      "  0.99058425  0.95726442  0.97917128  0.99176395  0.98859078  0.97598368\n",
      "  0.97895205  0.9922086   0.96199226  0.99750078  0.91883641  0.93340331\n",
      "  0.99550849]\n",
      "Model saved\n",
      "Minibatch loss at epoch 34 and iter 45899: 0.000013 and the learning rate: 0.081451\n",
      "Minibatch train and validation accuracy: 100.000%, 95.518%\n",
      "Time interval: 756.3033 seconds, estimated run time for 200 epochs: 47.8521 hours\n",
      "[ 0.94072795  0.86771607  0.80212283  0.95208532  0.96007746  0.91625339\n",
      "  0.95047575  0.94137073  0.92403054  0.98753071  0.99123418  0.97487146\n",
      "  0.98490137  0.97588176  0.99699956  0.98910844  0.81901336  0.99825168\n",
      "  0.98284817  0.98369521  0.93606895  0.89770538  0.9967503   0.97516549\n",
      "  0.96448737  0.96551675  0.97419465  0.99248075  0.98569971  0.99279815\n",
      "  0.99353176  0.94201809  0.93106616  0.98855674  0.9875555   0.97977257\n",
      "  0.97512144  0.99474031  0.96301919  0.99575907  0.90942454  0.75919288\n",
      "  0.99070537]\n",
      "Minibatch loss at epoch 35 and iter 47249: 0.000104 and the learning rate: 0.081451\n",
      "Minibatch train and validation accuracy: 100.000%, 96.047%\n",
      "Time interval: 756.7664 seconds, estimated run time for 200 epochs: 47.6861 hours\n",
      "[ 0.93985087  0.87222767  0.82606149  0.94804227  0.95527422  0.93891579\n",
      "  0.94486648  0.96323133  0.93787837  0.98619777  0.99027139  0.9694615\n",
      "  0.9802826   0.97399956  0.99724609  0.97016686  0.96719146  0.998501\n",
      "  0.97869128  0.98181772  0.9462136   0.90578288  0.99650651  0.98677266\n",
      "  0.93831635  0.97347766  0.96920776  0.98990363  0.96523368  0.9910754\n",
      "  0.99177623  0.95454496  0.91220021  0.98689699  0.98608303  0.97942954\n",
      "  0.97558546  0.99549729  0.96328801  0.99700248  0.92157322  0.82748979\n",
      "  0.98914921]\n",
      "Minibatch loss at epoch 36 and iter 48599: 0.000177 and the learning rate: 0.081451\n",
      "Minibatch train and validation accuracy: 100.000%, 96.215%\n",
      "Time interval: 758.8833 seconds, estimated run time for 200 epochs: 47.5326 hours\n",
      "[ 0.95432639  0.86797547  0.80810374  0.94062161  0.96283227  0.91158992\n",
      "  0.94909561  0.93261534  0.92161232  0.98725277  0.98902148  0.98015141\n",
      "  0.97720313  0.97796643  0.99549276  0.99032933  0.96378636  0.99378526\n",
      "  0.97705358  0.9866398   0.93704045  0.90319037  0.99600953  0.95503682\n",
      "  0.95220631  0.96783948  0.97923833  0.9819563   0.9779731   0.99180079\n",
      "  0.98445553  0.96165001  0.9587723   0.98932689  0.98886365  0.98338652\n",
      "  0.98885262  0.99422783  0.97437155  0.99650651  0.94027126  0.8722555\n",
      "  0.99451876]\n",
      "Minibatch loss at epoch 37 and iter 49949: 0.000110 and the learning rate: 0.081451\n",
      "Minibatch train and validation accuracy: 100.000%, 96.313%\n",
      "Time interval: 758.0265 seconds, estimated run time for 200 epochs: 47.3862 hours\n",
      "[ 0.95050406  0.88563913  0.81699872  0.95413232  0.95918828  0.93536627\n",
      "  0.96620417  0.97307831  0.94397926  0.9848367   0.98949432  0.97625417\n",
      "  0.97886056  0.9744612   0.99699801  0.9869228   0.91700411  0.99626166\n",
      "  0.96660936  0.98351735  0.93434429  0.89802498  0.99550396  0.97018522\n",
      "  0.94554013  0.95638579  0.97490108  0.98943609  0.97990149  0.99352866\n",
      "  0.98542804  0.94317043  0.97323555  0.98725909  0.9890269   0.98224503\n",
      "  0.98110378  0.99649429  0.97186267  0.99476653  0.93637228  0.87371463\n",
      "  0.99304473]\n",
      "Minibatch loss at epoch 38 and iter 51299: 0.000069 and the learning rate: 0.077378\n",
      "Minibatch train and validation accuracy: 100.000%, 95.749%\n",
      "Time interval: 766.7583 seconds, estimated run time for 200 epochs: 47.2601 hours\n",
      "[ 0.93734288  0.87358135  0.80011648  0.93533224  0.93198705  0.91173661\n",
      "  0.98636878  0.92004591  0.92817903  0.98729086  0.99199152  0.97535932\n",
      "  0.97933424  0.97907686  0.99650651  0.98063201  0.91535491  0.99825263\n",
      "  0.98507416  0.97842032  0.93290865  0.90577137  0.99700099  0.98532653\n",
      "  0.95215887  0.96187484  0.98210686  0.99574208  0.97085917  0.98399359\n",
      "  0.97345942  0.94588751  0.9631232   0.98262113  0.97886932  0.95871735\n",
      "  0.97966141  0.99194723  0.9648363   0.99674869  0.85299003  0.88434327\n",
      "  0.99774784]\n",
      "Minibatch loss at epoch 39 and iter 52649: 0.000004 and the learning rate: 0.077378\n",
      "Minibatch train and validation accuracy: 100.000%, 95.268%\n",
      "Time interval: 753.5029 seconds, estimated run time for 200 epochs: 47.1217 hours\n",
      "[ 0.94485509  0.87730956  0.81781095  0.9441548   0.96411729  0.93644947\n",
      "  0.90008956  0.96504474  0.95028144  0.98632127  0.99224758  0.95097524\n",
      "  0.98160696  0.98029262  0.99649602  0.98063201  0.90253842  0.99700695\n",
      "  0.98682535  0.95942324  0.93474191  0.86078012  0.99575907  0.97808373\n",
      "  0.96434933  0.96426702  0.98196149  0.99549502  0.97109497  0.99377596\n",
      "  0.98300022  0.93226671  0.89898717  0.98780131  0.98206776  0.97653693\n",
      "  0.97059488  0.99168932  0.96820468  0.99675196  0.88301629  0.70473486\n",
      "  0.97959131]\n",
      "Minibatch loss at epoch 40 and iter 53999: 0.000357 and the learning rate: 0.077378\n",
      "Minibatch train and validation accuracy: 100.000%, 96.731%\n",
      "Time interval: 757.5115 seconds, estimated run time for 200 epochs: 46.9958 hours\n",
      "[ 0.91869313  0.87307119  0.83773959  0.9378075   0.94973958  0.94313824\n",
      "  0.98317617  0.98293984  0.94856262  0.98699301  0.99199951  0.97990149\n",
      "  0.98316956  0.98160696  0.99675035  0.98887461  0.96261632  0.99700403\n",
      "  0.98681873  0.96850723  0.93845296  0.91435987  0.9960115   0.97977251\n",
      "  0.95456874  0.97331268  0.98042083  0.98758644  0.98205018  0.99799955\n",
      "  0.99201542  0.95964521  0.96941704  0.99324447  0.98623228  0.97929966\n",
      "  0.97725552  0.99447739  0.96415728  0.9964996   0.93532795  0.92739069\n",
      "  0.99500453]\n",
      "Minibatch loss at epoch 41 and iter 55349: 0.000107 and the learning rate: 0.077378\n",
      "Minibatch train and validation accuracy: 100.000%, 95.978%\n",
      "Time interval: 759.3143 seconds, estimated run time for 200 epochs: 46.8784 hours\n",
      "[ 0.87422723  0.84638423  0.84384412  0.96780396  0.94030863  0.95341724\n",
      "  0.97871238  0.98756176  0.96609694  0.9828822   0.99220473  0.98908138\n",
      "  0.98462272  0.97720325  0.99725431  0.98159462  0.84149468  0.99849802\n",
      "  0.98212469  0.95417613  0.92799956  0.89601666  0.99575484  0.95416319\n",
      "  0.97317964  0.9712407   0.98143977  0.99027622  0.98887461  0.99107093\n",
      "  0.99329144  0.97264993  0.95095193  0.99347335  0.98469847  0.98902148\n",
      "  0.9736709   0.99724472  0.96263802  0.99599957  0.90923148  0.82219607\n",
      "  0.99421626]\n",
      "Minibatch loss at epoch 42 and iter 56699: 0.000001 and the learning rate: 0.077378\n",
      "Minibatch train and validation accuracy: 100.000%, 96.613%\n",
      "Time interval: 759.5451 seconds, estimated run time for 200 epochs: 46.7670 hours\n",
      "[ 0.93959343  0.91243249  0.83356839  0.95666701  0.93613952  0.93800098\n",
      "  0.96328455  0.97538114  0.96132553  0.98896086  0.99175984  0.9623729\n",
      "  0.98619777  0.97898155  0.99625605  0.99009365  0.89873374  0.9979955\n",
      "  0.98481411  0.99130386  0.93910712  0.93551695  0.9962486   0.97163761\n",
      "  0.96645981  0.97537392  0.97177863  0.9932512   0.98838598  0.99650824\n",
      "  0.99082977  0.97389108  0.94582397  0.9903053   0.99327475  0.98851103\n",
      "  0.9789108   0.99674875  0.96968108  0.99800056  0.94005471  0.84112096\n",
      "  0.99427104]\n",
      "Minibatch loss at epoch 43 and iter 58049: 0.000004 and the learning rate: 0.077378\n",
      "Minibatch train and validation accuracy: 100.000%, 96.689%\n",
      "Time interval: 756.0323 seconds, estimated run time for 200 epochs: 46.6561 hours\n",
      "[ 0.92469388  0.8969177   0.85119164  0.9638201   0.93483418  0.93777949\n",
      "  0.97010893  0.95212966  0.94992518  0.98925751  0.99175984  0.98447847\n",
      "  0.98698652  0.9839111   0.99675685  0.99304128  0.91032928  0.9969995\n",
      "  0.984761    0.98396993  0.93829066  0.91832417  0.9969995   0.97089708\n",
      "  0.96946323  0.97418976  0.98020732  0.99624294  0.98304206  0.99304128\n",
      "  0.98691636  0.96578646  0.9869163   0.98981321  0.98804736  0.98674613\n",
      "  0.97627735  0.99649954  0.9599995   0.99725157  0.93195832  0.89037442\n",
      "  0.99623924]\n",
      "Minibatch loss at epoch 44 and iter 59399: 0.000198 and the learning rate: 0.077378\n",
      "Minibatch train and validation accuracy: 100.000%, 96.020%\n",
      "Time interval: 758.7655 seconds, estimated run time for 200 epochs: 46.5538 hours\n",
      "[ 0.93102586  0.8950063   0.85132116  0.95729315  0.963471    0.93633837\n",
      "  0.82161897  0.95831269  0.95214188  0.98667961  0.98897189  0.9720394\n",
      "  0.98500699  0.97814995  0.99451596  0.98789179  0.98989344  0.9940294\n",
      "  0.98405534  0.99154603  0.93786162  0.9200837   0.99600554  0.96775728\n",
      "  0.97840941  0.97335654  0.97701955  0.99523163  0.98473608  0.99329484\n",
      "  0.99403536  0.9698599   0.95413238  0.99326468  0.9872781   0.9800635\n",
      "  0.97652769  0.99474031  0.96051234  0.99799854  0.92815095  0.67598271\n",
      "  0.97921902]\n",
      "Minibatch loss at epoch 45 and iter 60749: 0.000067 and the learning rate: 0.073509\n",
      "Minibatch train and validation accuracy: 100.000%, 95.890%\n",
      "Time interval: 768.9903 seconds, estimated run time for 200 epochs: 46.4686 hours\n",
      "[ 0.92128503  0.8733778   0.83841765  0.95873272  0.96362239  0.94079554\n",
      "  0.92622715  0.9647283   0.95560521  0.98430055  0.9914611   0.98910302\n",
      "  0.98669958  0.97603214  0.99700403  0.97676647  0.95726895  0.99775225\n",
      "  0.98025441  0.95413238  0.94077522  0.90999955  0.99550849  0.97726107\n",
      "  0.98126537  0.97280771  0.97728348  0.99649781  0.98135382  0.98546392\n",
      "  0.99229002  0.9701122   0.87521845  0.98661995  0.98923606  0.98115027\n",
      "  0.98104799  0.99625051  0.96625721  0.99551082  0.89698833  0.75796133\n",
      "  0.9558627 ]\n",
      "Minibatch loss at epoch 46 and iter 62099: 0.000134 and the learning rate: 0.073509\n",
      "Minibatch train and validation accuracy: 100.000%, 95.796%\n",
      "Time interval: 761.8402 seconds, estimated run time for 200 epochs: 46.3786 hours\n",
      "[ 0.94295251  0.89392269  0.83403724  0.9631232   0.96303594  0.93226075\n",
      "  0.8762067   0.93891084  0.92612845  0.98390287  0.99051851  0.97844148\n",
      "  0.9827106   0.96902949  0.99750203  0.96944666  0.89550543  0.99725431\n",
      "  0.98341942  0.95735455  0.93758178  0.90417516  0.99600953  0.97875446\n",
      "  0.97606879  0.96916026  0.98404741  0.99273682  0.98375934  0.98862463\n",
      "  0.99057025  0.95110208  0.97390836  0.991243    0.98555005  0.97787565\n",
      "  0.97344655  0.994735    0.96416551  0.99675357  0.93329877  0.75874722\n",
      "  0.98582232]\n",
      "Minibatch loss at epoch 47 and iter 63449: 0.000082 and the learning rate: 0.073509\n",
      "Minibatch train and validation accuracy: 100.000%, 95.901%\n",
      "Time interval: 759.2270 seconds, estimated run time for 200 epochs: 46.2892 hours\n",
      "[ 0.94634569  0.87909073  0.84670287  0.95802307  0.95592839  0.92811036\n",
      "  0.9733296   0.95513701  0.9513123   0.98694074  0.98562169  0.98012221\n",
      "  0.97974443  0.97712201  0.99328482  0.97489589  0.77679342  0.99526489\n",
      "  0.98677266  0.97012341  0.93519443  0.90193945  0.99700248  0.97425789\n",
      "  0.96103853  0.96678543  0.97339857  0.99175161  0.99205512  0.9859497\n",
      "  0.98542082  0.94744372  0.97845197  0.99423075  0.98274112  0.98613125\n",
      "  0.97653908  0.99574     0.95883983  0.99799854  0.91506946  0.80388647\n",
      "  0.998501  ]\n",
      "Minibatch loss at epoch 48 and iter 64799: 0.001342 and the learning rate: 0.073509\n",
      "Minibatch train and validation accuracy: 100.000%, 95.374%\n",
      "Time interval: 758.7918 seconds, estimated run time for 200 epochs: 46.2031 hours\n",
      "[ 0.94429123  0.88337159  0.84538329  0.93700004  0.93792063  0.93193674\n",
      "  0.96833855  0.97514862  0.92576832  0.9842692   0.99223596  0.98738515\n",
      "  0.98314422  0.97453946  0.99799651  0.92059791  0.71451515  0.99874985\n",
      "  0.97800791  0.95602244  0.93993628  0.89334744  0.99725574  0.97643214\n",
      "  0.9642393   0.97009254  0.97029167  0.98866171  0.98715997  0.9910754\n",
      "  0.9942739   0.93301952  0.95965368  0.99248451  0.98701251  0.98294145\n",
      "  0.97917128  0.99724472  0.96574593  0.99700403  0.90429336  0.77221346\n",
      "  0.98989856]\n",
      "Minibatch loss at epoch 49 and iter 66149: 0.000013 and the learning rate: 0.073509\n",
      "Minibatch train and validation accuracy: 100.000%, 96.123%\n",
      "Time interval: 757.2900 seconds, estimated run time for 200 epochs: 46.1188 hours\n",
      "[ 0.94016224  0.88448977  0.85358387  0.96476787  0.95215034  0.93863481\n",
      "  0.90505272  0.97685826  0.96223027  0.98793316  0.99227083  0.97295928\n",
      "  0.98277968  0.98136914  0.99724746  0.983226    0.8797304   0.99824822\n",
      "  0.98505181  0.97414583  0.93730193  0.91734833  0.99875045  0.9764123\n",
      "  0.9729172   0.96879667  0.97869128  0.99347341  0.98642933  0.99477166\n",
      "  0.98910308  0.9635781   0.95235783  0.99096793  0.98824662  0.97857618\n",
      "  0.97772294  0.99522924  0.96063751  0.99700099  0.92414093  0.76666617\n",
      "  0.98373938]\n",
      "Minibatch loss at epoch 50 and iter 67499: 0.000023 and the learning rate: 0.073509\n",
      "Minibatch train and validation accuracy: 100.000%, 96.247%\n",
      "Time interval: 753.0768 seconds, estimated run time for 200 epochs: 46.0331 hours\n",
      "[ 0.95120722  0.88980216  0.86524016  0.9720394   0.95425749  0.93786651\n",
      "  0.92361069  0.96759999  0.9576118   0.98796344  0.98977256  0.97344655\n",
      "  0.98347467  0.98085594  0.99749577  0.99056089  0.86443514  0.99775118\n",
      "  0.98608994  0.97415847  0.93981552  0.91064698  0.99750197  0.9807117\n",
      "  0.9693374   0.97369701  0.98333699  0.99271488  0.9869228   0.99601144\n",
      "  0.99058425  0.94931489  0.94941771  0.99174333  0.98703843  0.97860789\n",
      "  0.98108524  0.994982    0.96259952  0.99675035  0.94380856  0.76104373\n",
      "  0.99699193]\n",
      "Minibatch loss at epoch 51 and iter 68849: 0.000014 and the learning rate: 0.073509\n",
      "Minibatch train and validation accuracy: 100.000%, 95.906%\n",
      "Time interval: 752.9458 seconds, estimated run time for 200 epochs: 45.9507 hours\n",
      "[ 0.93258113  0.88864756  0.86427152  0.9665693   0.96769375  0.939439\n",
      "  0.91253662  0.92325485  0.92916185  0.9895153   0.98949951  0.97680044\n",
      "  0.9844138   0.9531489   0.99526727  0.97298563  0.87306458  0.99675363\n",
      "  0.98425353  0.9798916   0.9346332   0.91025925  0.99625427  0.97427052\n",
      "  0.97424078  0.96222007  0.97844887  0.99399948  0.98544246  0.9910621\n",
      "  0.98789179  0.96769404  0.95689613  0.99276578  0.98958284  0.98388249\n",
      "  0.97390836  0.99674058  0.96761084  0.99526018  0.93229121  0.75210142\n",
      "  0.99548829]\n",
      "Minibatch loss at epoch 52 and iter 70199: 0.000001 and the learning rate: 0.069834\n",
      "Minibatch train and validation accuracy: 100.000%, 96.229%\n",
      "Time interval: 754.8723 seconds, estimated run time for 200 epochs: 45.8736 hours\n",
      "[ 0.94258898  0.89246398  0.82732946  0.93846834  0.96068323  0.93513459\n",
      "  0.93777835  0.96907669  0.96237177  0.98876363  0.99175155  0.97464603\n",
      "  0.98417437  0.97266877  0.99600559  0.98424375  0.86080223  0.99725431\n",
      "  0.99027139  0.98061299  0.93953687  0.93399632  0.99700254  0.97400635\n",
      "  0.97069359  0.96905071  0.97992516  0.9969905   0.98716635  0.99377596\n",
      "  0.98861903  0.96938223  0.95554447  0.9922747   0.9848367   0.98370326\n",
      "  0.97180307  0.9932614   0.94662434  0.99500453  0.95704252  0.78405434\n",
      "  0.99600559]\n",
      "Minibatch loss at epoch 53 and iter 71549: 0.000013 and the learning rate: 0.069834\n",
      "Minibatch train and validation accuracy: 100.000%, 95.745%\n",
      "Time interval: 756.0300 seconds, estimated run time for 200 epochs: 45.8005 hours\n",
      "[ 0.94158548  0.89845783  0.82701111  0.95623004  0.93921286  0.92296731\n",
      "  0.88716078  0.96516144  0.94682986  0.98565269  0.98881388  0.9741711\n",
      "  0.98421401  0.97842044  0.99700403  0.98254192  0.841618    0.99800152\n",
      "  0.98704487  0.97438353  0.93577939  0.91963065  0.99700254  0.97396809\n",
      "  0.95898187  0.96513337  0.97722727  0.99324107  0.98716635  0.99427956\n",
      "  0.98814183  0.96193224  0.97345942  0.98833984  0.98835146  0.98901045\n",
      "  0.97414583  0.99674708  0.95118725  0.99650651  0.93508375  0.7263602\n",
      "  0.99018824]\n",
      "Minibatch loss at epoch 54 and iter 72899: 0.000007 and the learning rate: 0.069834\n",
      "Minibatch train and validation accuracy: 100.000%, 95.906%\n",
      "Time interval: 762.3667 seconds, estimated run time for 200 epochs: 45.7367 hours\n",
      "[ 0.93522322  0.89655125  0.83169937  0.93752891  0.94932383  0.93493444\n",
      "  0.95070875  0.96449363  0.94066226  0.98381025  0.99049956  0.97748363\n",
      "  0.98211998  0.97387731  0.99775237  0.97085917  0.88535517  0.99850023\n",
      "  0.98631459  0.97180307  0.94006258  0.92107314  0.99725568  0.96687722\n",
      "  0.95786977  0.9683094   0.98333704  0.99057025  0.98327547  0.99155867\n",
      "  0.99082524  0.97570598  0.9167999   0.98660004  0.98462248  0.98558593\n",
      "  0.96107596  0.9960115   0.94425499  0.99675357  0.93864214  0.77991843\n",
      "  0.99322402]\n",
      "Minibatch loss at epoch 55 and iter 74249: 0.000052 and the learning rate: 0.069834\n",
      "Minibatch train and validation accuracy: 100.000%, 95.285%\n",
      "Time interval: 764.8268 seconds, estimated run time for 200 epochs: 45.6776 hours\n",
      "[ 0.93363684  0.90300244  0.82791984  0.93489414  0.92427415  0.91394472\n",
      "  0.97022891  0.96934628  0.94117606  0.98129165  0.9880473   0.97653913\n",
      "  0.98317808  0.97106552  0.9977501   0.95854253  0.70443463  0.99924898\n",
      "  0.97408003  0.97180307  0.94210058  0.89967239  0.99601346  0.97106379\n",
      "  0.9415803   0.96553415  0.9589901   0.98348945  0.98863029  0.99131256\n",
      "  0.98836869  0.94550616  0.9507724   0.99125612  0.98622543  0.9826985\n",
      "  0.97894174  0.99725157  0.96162713  0.99750078  0.93690002  0.75257248\n",
      "  0.99375737]\n",
      "Minibatch loss at epoch 56 and iter 75599: 0.000006 and the learning rate: 0.069834\n",
      "Minibatch train and validation accuracy: 100.000%, 96.269%\n",
      "Time interval: 766.1627 seconds, estimated run time for 200 epochs: 45.6221 hours\n",
      "[ 0.94642377  0.9034313   0.85792303  0.97770107  0.94969869  0.94099957\n",
      "  0.92877054  0.97084004  0.95600545  0.98588669  0.99002451  0.97274894\n",
      "  0.98595035  0.97555959  0.99725568  0.97322249  0.83493412  0.99775338\n",
      "  0.98528993  0.97745049  0.93551749  0.92452782  0.99750197  0.97685826\n",
      "  0.9628861   0.96326697  0.98015827  0.99324787  0.99058425  0.98813009\n",
      "  0.98038208  0.96910208  0.98207664  0.99102646  0.98395133  0.97689235\n",
      "  0.98179984  0.99600351  0.9597311   0.99649775  0.94827533  0.78744608\n",
      "  0.99749571]\n",
      "Minibatch loss at epoch 57 and iter 76949: 0.000112 and the learning rate: 0.069834\n",
      "Minibatch train and validation accuracy: 100.000%, 95.821%\n",
      "Time interval: 763.5696 seconds, estimated run time for 200 epochs: 45.5659 hours\n",
      "[ 0.95761412  0.90569955  0.86847776  0.97198492  0.96755117  0.94385833\n",
      "  0.89052677  0.93876541  0.94705093  0.98379701  0.98928976  0.97319639\n",
      "  0.98571736  0.97741646  0.9960075   0.97919172  0.81000549  0.99725431\n",
      "  0.98846501  0.98835725  0.93347424  0.9324671   0.99700105  0.9689557\n",
      "  0.95636314  0.96259952  0.98090702  0.99573994  0.98134464  0.98545682\n",
      "  0.97418362  0.96870363  0.96078855  0.98857379  0.97965282  0.97335571\n",
      "  0.97892112  0.99674714  0.960536    0.99700099  0.9458831   0.69673508\n",
      "  0.99774897]\n",
      "Minibatch loss at epoch 58 and iter 78299: 0.000010 and the learning rate: 0.069834\n",
      "Minibatch train and validation accuracy: 100.000%, 95.753%\n",
      "Time interval: 756.4723 seconds, estimated run time for 200 epochs: 45.5049 hours\n",
      "[ 0.95200741  0.89296103  0.84016925  0.95361024  0.95699143  0.92967772\n",
      "  0.92272049  0.95666778  0.93495482  0.98663926  0.99029082  0.97847307\n",
      "  0.98444504  0.97090304  0.99725014  0.97038788  0.74552828  0.99775225\n",
      "  0.98604834  0.98591506  0.94253433  0.92577767  0.99700254  0.97709876\n",
      "  0.95910931  0.97034174  0.98162812  0.992989    0.98765385  0.98764163\n",
      "  0.9866662   0.96236902  0.97919172  0.99376976  0.97726083  0.97570503\n",
      "  0.97369647  0.99749446  0.96153802  0.99775118  0.94129664  0.73832983\n",
      "  0.99649954]\n",
      "Minibatch loss at epoch 59 and iter 79649: 0.000483 and the learning rate: 0.069834\n",
      "Minibatch train and validation accuracy: 100.000%, 94.916%\n",
      "Time interval: 764.8130 seconds, estimated run time for 200 epochs: 45.4538 hours\n",
      "[ 0.95559281  0.88344461  0.8427918   0.96987319  0.95939285  0.92575753\n",
      "  0.76866776  0.95776653  0.94966567  0.98916006  0.99251074  0.95602244\n",
      "  0.98184484  0.97898155  0.99800056  0.98737258  0.81820828  0.998999\n",
      "  0.98105633  0.98132628  0.93713635  0.93288547  0.99575055  0.98356527\n",
      "  0.96219534  0.96790457  0.96303457  0.98924685  0.98350924  0.99254423\n",
      "  0.99056089  0.96853447  0.97133088  0.99250329  0.97542387  0.98147643\n",
      "  0.97063774  0.99500704  0.95557195  0.99725014  0.8994903   0.48665845\n",
      "  0.99224758]\n",
      "Minibatch loss at epoch 60 and iter 80999: 0.000052 and the learning rate: 0.066342\n",
      "Minibatch train and validation accuracy: 100.000%, 96.448%\n",
      "Time interval: 755.9519 seconds, estimated run time for 200 epochs: 45.3961 hours\n",
      "[ 0.93088806  0.8833822   0.86394697  0.96727222  0.95626771  0.94494003\n",
      "  0.99155444  0.96999222  0.95983785  0.98699301  0.98954654  0.98135382\n",
      "  0.98472273  0.97982806  0.998501    0.98836297  0.79409057  0.99899954\n",
      "  0.98162812  0.96685171  0.93269688  0.92527938  0.99650997  0.9747358\n",
      "  0.96674353  0.96829778  0.98042083  0.98974687  0.98304206  0.99205905\n",
      "  0.99058425  0.97068202  0.98276663  0.99548376  0.98497695  0.98539919\n",
      "  0.9822917   0.99599558  0.96383041  0.99749827  0.93380994  0.83495516\n",
      "  0.99799752]\n",
      "Minibatch loss at epoch 61 and iter 82349: 0.000007 and the learning rate: 0.066342\n",
      "Minibatch train and validation accuracy: 100.000%, 95.922%\n",
      "Time interval: 757.2429 seconds, estimated run time for 200 epochs: 45.3416 hours\n",
      "[ 0.92933971  0.84729302  0.84748507  0.95986491  0.93045288  0.94275045\n",
      "  0.95865333  0.97612554  0.956586    0.98517907  0.98687744  0.98495638\n",
      "  0.98671293  0.97230721  0.99899954  0.98641592  0.78776819  0.9994995\n",
      "  0.98410285  0.96378511  0.94689989  0.89514995  0.996503    0.98119694\n",
      "  0.96966535  0.9708339   0.98109406  0.99349952  0.99034369  0.99501693\n",
      "  0.99082971  0.93686402  0.96641648  0.99096793  0.98031247  0.98535573\n",
      "  0.97919172  0.99575061  0.94933426  0.99625605  0.94930363  0.7903437\n",
      "  0.99373233]\n",
      "Minibatch loss at epoch 62 and iter 83699: 0.000000 and the learning rate: 0.066342\n",
      "Minibatch train and validation accuracy: 100.000%, 96.091%\n",
      "Time interval: 757.0844 seconds, estimated run time for 200 epochs: 45.2887 hours\n",
      "[ 0.93963206  0.89249003  0.84097898  0.93736756  0.95630789  0.94580239\n",
      "  0.88735485  0.95941985  0.95083553  0.98206574  0.98786175  0.9751336\n",
      "  0.98572451  0.97969502  0.9980005   0.97678918  0.94173676  0.99825168\n",
      "  0.9831177   0.976062    0.94145274  0.91948551  0.99749953  0.97472346\n",
      "  0.95568252  0.96309537  0.97081137  0.99003446  0.98398566  0.99057961\n",
      "  0.9898535   0.95475399  0.95733416  0.99374789  0.98749954  0.98344404\n",
      "  0.97558546  0.99524826  0.96709973  0.99675518  0.93901759  0.76275891\n",
      "  0.99824911]\n",
      "Minibatch loss at epoch 63 and iter 85049: 0.000001 and the learning rate: 0.066342\n",
      "Minibatch train and validation accuracy: 100.000%, 96.247%\n",
      "Time interval: 758.8369 seconds, estimated run time for 200 epochs: 45.2390 hours\n",
      "[ 0.93308061  0.8903774   0.82989645  0.9480176   0.95468968  0.94132286\n",
      "  0.92785376  0.92904085  0.9326182   0.98441374  0.9905327   0.93520421\n",
      "  0.9842298   0.97897094  0.99675196  0.97822315  0.9547708   0.99874985\n",
      "  0.98821718  0.98786181  0.93107063  0.935812    0.9984988   0.97077405\n",
      "  0.97112143  0.96076363  0.98039162  0.9952507   0.98569268  0.99131685\n",
      "  0.98667932  0.9714281   0.95689613  0.98832244  0.98360604  0.97935051\n",
      "  0.97796232  0.99549276  0.96309543  0.9947691   0.91570634  0.86190563\n",
      "  0.99501944]\n",
      "Minibatch loss at epoch 64 and iter 86399: 0.000003 and the learning rate: 0.066342\n",
      "Minibatch train and validation accuracy: 100.000%, 96.760%\n",
      "Time interval: 757.2460 seconds, estimated run time for 200 epochs: 45.1895 hours\n",
      "[ 0.92649448  0.88275439  0.8459816   0.95527333  0.95136654  0.94149411\n",
      "  0.94427264  0.97272009  0.95713162  0.98848802  0.98537749  0.9817819\n",
      "  0.98443729  0.98088491  0.99700248  0.99057961  0.96415538  0.99825263\n",
      "  0.98631448  0.98813009  0.93298376  0.93159902  0.99799752  0.97243178\n",
      "  0.97371733  0.97345078  0.98606223  0.99221247  0.98133552  0.9910754\n",
      "  0.98618597  0.96417207  0.98351735  0.99147391  0.98104799  0.98195255\n",
      "  0.97531122  0.99649072  0.94904578  0.99725437  0.92585015  0.89569229\n",
      "  0.99899906]\n",
      "Model saved\n",
      "Minibatch loss at epoch 65 and iter 87749: 0.000001 and the learning rate: 0.066342\n",
      "Minibatch train and validation accuracy: 100.000%, 96.426%\n",
      "Time interval: 763.0557 seconds, estimated run time for 200 epochs: 45.1464 hours\n",
      "[ 0.94891524  0.89043248  0.83597237  0.95054638  0.96301687  0.94635773\n",
      "  0.91008371  0.95668864  0.94936657  0.98872417  0.99226302  0.95463181\n",
      "  0.98266715  0.98066735  0.99699503  0.9866662   0.94486898  0.99899954\n",
      "  0.98660666  0.98667282  0.93281001  0.93528903  0.99700105  0.98028541\n",
      "  0.9648937   0.96741295  0.98261261  0.98920363  0.98642266  0.996503\n",
      "  0.98350108  0.96867305  0.96453518  0.9932512   0.98953611  0.98735386\n",
      "  0.98134464  0.99523884  0.96127164  0.99526727  0.91141129  0.82626051\n",
      "  0.9940055 ]\n",
      "Minibatch loss at epoch 66 and iter 89099: 0.010424 and the learning rate: 0.066342\n",
      "Minibatch train and validation accuracy: 100.000%, 96.446%\n",
      "Time interval: 755.5551 seconds, estimated run time for 200 epochs: 45.0984 hours\n",
      "[ 0.92713583  0.88089353  0.85415477  0.95890367  0.9346323   0.94747323\n",
      "  0.95433855  0.97309262  0.95036119  0.98573166  0.99029565  0.96450084\n",
      "  0.9839353   0.97995943  0.99725157  0.98157656  0.91181225  0.99949926\n",
      "  0.97618413  0.98422825  0.9392029   0.93361163  0.99749947  0.98149472\n",
      "  0.96999186  0.97570807  0.98314279  0.98558736  0.98788577  0.9947691\n",
      "  0.99057025  0.96073633  0.94624627  0.9914825   0.98853385  0.98247302\n",
      "  0.98326725  0.99599349  0.96488035  0.99775237  0.9328599   0.8295421\n",
      "  0.99799955]\n",
      "Minibatch loss at epoch 67 and iter 90449: 0.000000 and the learning rate: 0.063025\n",
      "Minibatch train and validation accuracy: 100.000%, 96.158%\n",
      "Time interval: 753.5509 seconds, estimated run time for 200 epochs: 45.0501 hours\n",
      "[ 0.90467155  0.86853403  0.8280797   0.93912995  0.94259477  0.93981773\n",
      "  0.92954391  0.96805608  0.9508273   0.98580986  0.98950994  0.98371929\n",
      "  0.98378062  0.97046793  0.9967584   0.97559738  0.96180779  0.99874985\n",
      "  0.98927903  0.97603863  0.93364751  0.92340493  0.99625605  0.97375476\n",
      "  0.9636687   0.97616011  0.9880175   0.99549729  0.97319645  0.99403232\n",
      "  0.98765385  0.95851374  0.94112056  0.98904335  0.98931098  0.98824662\n",
      "  0.97249889  0.9942767   0.96259952  0.99452138  0.9038204   0.83606511\n",
      "  0.99572921]\n",
      "Minibatch loss at epoch 68 and iter 91799: 0.000001 and the learning rate: 0.063025\n",
      "Minibatch train and validation accuracy: 100.000%, 96.056%\n",
      "Time interval: 762.7926 seconds, estimated run time for 200 epochs: 45.0108 hours\n",
      "[ 0.89658308  0.86186624  0.85785079  0.96190894  0.94504392  0.95126754\n",
      "  0.91121233  0.98337835  0.95921403  0.98897201  0.99126482  0.98860204\n",
      "  0.98263228  0.98119783  0.99501693  0.97464603  0.94952631  0.99749076\n",
      "  0.98798752  0.98108524  0.929196    0.93883908  0.99725157  0.98343587\n",
      "  0.95686024  0.96759778  0.97872293  0.99425095  0.96591687  0.98642933\n",
      "  0.99352217  0.96657676  0.91320187  0.99222821  0.98905975  0.98100126\n",
      "  0.98495638  0.99699509  0.96617067  0.99675518  0.90266365  0.74140376\n",
      "  0.99497437]\n",
      "Minibatch loss at epoch 69 and iter 93149: 0.000033 and the learning rate: 0.063025\n",
      "Minibatch train and validation accuracy: 100.000%, 95.995%\n",
      "Time interval: 758.6942 seconds, estimated run time for 200 epochs: 44.9693 hours\n",
      "[ 0.90417635  0.89180458  0.83228344  0.95957607  0.92013925  0.94236898\n",
      "  0.90004474  0.97391689  0.94865966  0.98821718  0.99250704  0.98860216\n",
      "  0.98621851  0.97297245  0.99675196  0.9794113   0.92510021  0.99750072\n",
      "  0.98462254  0.97868121  0.94510567  0.92177546  0.9962579   0.98463011\n",
      "  0.95823556  0.97297245  0.98164636  0.98871285  0.98086315  0.99551517\n",
      "  0.99501204  0.9520824   0.93019962  0.99475086  0.99226689  0.9865399\n",
      "  0.98327547  0.99824822  0.96123987  0.99427676  0.93128604  0.73742664\n",
      "  0.99522686]\n",
      "Minibatch loss at epoch 70 and iter 94499: 0.000001 and the learning rate: 0.063025\n",
      "Minibatch train and validation accuracy: 100.000%, 96.097%\n",
      "Time interval: 767.4229 seconds, estimated run time for 200 epochs: 44.9360 hours\n",
      "[ 0.93451017  0.90050101  0.8422243   0.94977337  0.94250071  0.93967587\n",
      "  0.95393425  0.96763152  0.94784999  0.98753071  0.99051845  0.97632366\n",
      "  0.98180854  0.97008067  0.99700552  0.97823381  0.8802458   0.99875045\n",
      "  0.98584503  0.96495003  0.93814921  0.9158172   0.99824995  0.98780131\n",
      "  0.95568252  0.97136962  0.98455364  0.99152076  0.97775555  0.99279094\n",
      "  0.99205512  0.95114273  0.91701013  0.98897201  0.98711544  0.97885889\n",
      "  0.98254198  0.99649948  0.96818835  0.99700403  0.95799947  0.773435\n",
      "  0.99724329]\n",
      "Minibatch loss at epoch 71 and iter 95849: 0.001135 and the learning rate: 0.063025\n",
      "Minibatch train and validation accuracy: 100.000%, 95.958%\n",
      "Time interval: 795.0411 seconds, estimated run time for 200 epochs: 44.9252 hours\n",
      "[ 0.92557204  0.88570625  0.85295725  0.97625417  0.95134825  0.93839985\n",
      "  0.89583755  0.95712858  0.954602    0.98949951  0.99250329  0.9825505\n",
      "  0.9831357   0.97439748  0.997253    0.97508502  0.90764982  0.99700695\n",
      "  0.9681493   0.97463363  0.94157672  0.91352737  0.99875045  0.97882766\n",
      "  0.9720723   0.9628486   0.9899745   0.98639059  0.98545682  0.99452686\n",
      "  0.9923014   0.96350324  0.9276433   0.99350929  0.98739761  0.98607606\n",
      "  0.97440851  0.99526489  0.96334487  0.99750197  0.93387336  0.71581209\n",
      "  0.99092233]\n",
      "Minibatch loss at epoch 72 and iter 97199: 0.000001 and the learning rate: 0.063025\n",
      "Minibatch train and validation accuracy: 100.000%, 96.547%\n",
      "Time interval: 796.7180 seconds, estimated run time for 200 epochs: 44.9160 hours\n",
      "[ 0.93010706  0.89986604  0.85943508  0.97223526  0.94540113  0.9376083\n",
      "  0.91864437  0.93895781  0.943093    0.99024713  0.9910354   0.98642266\n",
      "  0.98491657  0.98236734  0.99725574  0.98764777  0.93683606  0.99899948\n",
      "  0.99028593  0.99152499  0.94265461  0.92717904  0.99749207  0.97601521\n",
      "  0.96148831  0.96958804  0.98504436  0.99599159  0.97943145  0.99378836\n",
      "  0.98496377  0.96262091  0.9798916   0.99055618  0.98802948  0.9820891\n",
      "  0.98349303  0.99774897  0.96125984  0.99750197  0.92484349  0.83813936\n",
      "  0.99422204]\n",
      "Minibatch loss at epoch 73 and iter 98549: 0.000000 and the learning rate: 0.063025\n",
      "Minibatch train and validation accuracy: 100.000%, 96.520%\n",
      "Time interval: 766.4887 seconds, estimated run time for 200 epochs: 44.8840 hours\n",
      "[ 0.92627007  0.88437867  0.86511832  0.97699422  0.94943637  0.94163376\n",
      "  0.91693389  0.9725889   0.94723183  0.98995936  0.99079329  0.98206776\n",
      "  0.98547041  0.9790414   0.99575698  0.98617238  0.93365258  0.99824995\n",
      "  0.98605525  0.98642933  0.94341546  0.93588364  0.99849731  0.98055571\n",
      "  0.96601397  0.97072142  0.98089761  0.99021775  0.97774476  0.9952696\n",
      "  0.99328816  0.96884918  0.9519043   0.99099499  0.98530465  0.98170984\n",
      "  0.98107594  0.99699193  0.96181583  0.99427676  0.94052094  0.8084082\n",
      "  0.99167246]\n",
      "Minibatch loss at epoch 74 and iter 99899: 0.005803 and the learning rate: 0.063025\n",
      "Minibatch train and validation accuracy: 100.000%, 96.262%\n",
      "Time interval: 756.0758 seconds, estimated run time for 200 epochs: 44.8451 hours\n",
      "[ 0.92559117  0.8848384   0.84702504  0.96871161  0.94224292  0.93863648\n",
      "  0.91450793  0.97000688  0.95060438  0.98872417  0.98859078  0.98447847\n",
      "  0.98281914  0.97879726  0.99551743  0.98058444  0.9261741   0.99899954\n",
      "  0.97969246  0.98327547  0.94766945  0.92009389  0.99774897  0.97667515\n",
      "  0.95618105  0.96770889  0.97375476  0.98632866  0.98375934  0.99576324\n",
      "  0.9900887   0.95797861  0.95397043  0.99224371  0.98537749  0.98220414\n",
      "  0.98375934  0.99698752  0.96521467  0.99725294  0.93503141  0.79692423\n",
      "  0.99168932]\n",
      "Minibatch loss at epoch 75 and iter 101249: 0.000005 and the learning rate: 0.059874\n",
      "Minibatch train and validation accuracy: 100.000%, 96.226%\n",
      "Time interval: 754.3106 seconds, estimated run time for 200 epochs: 44.8059 hours\n",
      "[ 0.93893272  0.89452553  0.85847712  0.96628618  0.9552089   0.94256788\n",
      "  0.88933462  0.96628618  0.95386899  0.98748076  0.98857945  0.98111308\n",
      "  0.98178095  0.97899956  0.99675518  0.98959321  0.90260583  0.99924862\n",
      "  0.9877342   0.97822315  0.94461805  0.91313398  0.99799854  0.97526276\n",
      "  0.95950115  0.95971209  0.98381823  0.99548829  0.97990149  0.99576539\n",
      "  0.98617923  0.94941211  0.97016686  0.99450511  0.98459959  0.98221302\n",
      "  0.98061299  0.99724334  0.9615677   0.99625802  0.94348103  0.76531374\n",
      "  0.99674219]\n",
      "Minibatch loss at epoch 76 and iter 102599: 0.000008 and the learning rate: 0.059874\n",
      "Minibatch train and validation accuracy: 100.000%, 96.023%\n",
      "Time interval: 776.2729 seconds, estimated run time for 200 epochs: 44.7838 hours\n",
      "[ 0.92423481  0.88157147  0.84773386  0.95990348  0.95790464  0.94330108\n",
      "  0.95356584  0.96669048  0.94496268  0.98705125  0.9917475   0.9905749\n",
      "  0.98327374  0.97839153  0.9967584   0.9818266   0.84958249  0.9984988\n",
      "  0.98332876  0.96753824  0.94126898  0.88834375  0.99750197  0.98002416\n",
      "  0.95792162  0.96471131  0.98239481  0.99295729  0.98617917  0.99205512\n",
      "  0.99033409  0.93392855  0.95054638  0.99248451  0.98555005  0.97924858\n",
      "  0.98036277  0.99724609  0.96389842  0.99650651  0.93486351  0.79761291\n",
      "  0.9876039 ]\n",
      "Minibatch loss at epoch 77 and iter 103949: 0.000001 and the learning rate: 0.059874\n",
      "Minibatch train and validation accuracy: 100.000%, 96.405%\n",
      "Time interval: 772.0739 seconds, estimated run time for 200 epochs: 44.7592 hours\n",
      "[ 0.93093479  0.88589495  0.86251682  0.97557354  0.95344824  0.94370967\n",
      "  0.89914405  0.95859373  0.95155925  0.98973674  0.99054682  0.97130305\n",
      "  0.98518658  0.98267585  0.99600947  0.98741001  0.9359889   0.9987492\n",
      "  0.98751199  0.98350114  0.93730199  0.92382616  0.99799955  0.97405732\n",
      "  0.96403569  0.9629814   0.97942954  0.99474823  0.98231781  0.99576539\n",
      "  0.98886919  0.95804828  0.9763121   0.99298197  0.9855212   0.98193467\n",
      "  0.97750562  0.99699503  0.96067798  0.99725014  0.92386782  0.81323957\n",
      "  0.9952364 ]\n",
      "Minibatch loss at epoch 78 and iter 105299: 0.000013 and the learning rate: 0.059874\n",
      "Minibatch train and validation accuracy: 100.000%, 96.650%\n",
      "Time interval: 763.6124 seconds, estimated run time for 200 epochs: 44.7293 hours\n",
      "[ 0.93470913  0.89498639  0.85299814  0.96563369  0.95291209  0.94419706\n",
      "  0.93555146  0.97121906  0.95538801  0.98925227  0.99201149  0.9842515\n",
      "  0.98437452  0.97745442  0.99700248  0.98133552  0.94467813  0.99849802\n",
      "  0.98727179  0.984236    0.93604606  0.92392105  0.99874985  0.9750362\n",
      "  0.97297245  0.9632858   0.98454595  0.99624109  0.97726673  0.99180895\n",
      "  0.98984849  0.94658983  0.95579398  0.99398756  0.98721433  0.98539191\n",
      "  0.98764163  0.99674225  0.96647996  0.99675363  0.94303107  0.84090251\n",
      "  0.99724048]\n",
      "Minibatch loss at epoch 79 and iter 106649: 0.000000 and the learning rate: 0.059874\n",
      "Minibatch train and validation accuracy: 100.000%, 96.326%\n",
      "Time interval: 773.5684 seconds, estimated run time for 200 epochs: 44.7071 hours\n",
      "[ 0.95520151  0.90674347  0.8467108   0.94941771  0.9579252   0.9268406\n",
      "  0.87275857  0.95390445  0.94075906  0.99222034  0.99374485  0.98349303\n",
      "  0.98865032  0.97877675  0.99750197  0.98085374  0.97622043  0.99849951\n",
      "  0.98878592  0.98716635  0.93816018  0.91141891  0.99824727  0.98368716\n",
      "  0.96820462  0.96671742  0.98406327  0.99501199  0.98086315  0.99377906\n",
      "  0.99032927  0.9376471   0.9592126   0.99051851  0.98820531  0.98289067\n",
      "  0.98690987  0.9962523   0.95905787  0.9955129   0.93838817  0.76665622\n",
      "  0.9959895 ]\n",
      "Minibatch loss at epoch 80 and iter 107999: 0.002923 and the learning rate: 0.059874\n",
      "Minibatch train and validation accuracy: 100.000%, 96.119%\n",
      "Time interval: 762.2875 seconds, estimated run time for 200 epochs: 44.6776 hours\n",
      "[ 0.94294101  0.89926505  0.83579499  0.95009458  0.94822973  0.9419539\n",
      "  0.97415847  0.97121906  0.9539637   0.98774034  0.98978275  0.97799462\n",
      "  0.9823584   0.97373688  0.99725157  0.97606206  0.82649428  0.998501\n",
      "  0.98341125  0.97869164  0.93769747  0.91505241  0.99750072  0.98272413\n",
      "  0.97363657  0.96623993  0.97872293  0.99148673  0.98593587  0.9967584\n",
      "  0.99304473  0.94933921  0.93323946  0.99147391  0.98402345  0.98247302\n",
      "  0.98519933  0.99599952  0.96373796  0.99775118  0.92829949  0.78618681\n",
      "  0.99523401]\n",
      "Minibatch loss at epoch 81 and iter 109349: 0.000007 and the learning rate: 0.059874\n",
      "Minibatch train and validation accuracy: 100.000%, 96.133%\n",
      "Time interval: 779.5186 seconds, estimated run time for 200 epochs: 44.6607 hours\n",
      "[ 0.95330697  0.89978516  0.79324597  0.93492466  0.95084357  0.88691247\n",
      "  0.94420755  0.95739424  0.93440515  0.98724633  0.98686445  0.98302531\n",
      "  0.98255324  0.97795743  0.99526256  0.98911381  0.87867701  0.99899954\n",
      "  0.98237723  0.98642266  0.93224746  0.95208609  0.99700248  0.97358078\n",
      "  0.94526273  0.96683621  0.97943974  0.98690134  0.97580004  0.99601543\n",
      "  0.97485918  0.97221494  0.97085917  0.99376357  0.98879153  0.98539197\n",
      "  0.98837459  0.99649251  0.96417552  0.99775237  0.9439435   0.82166332\n",
      "  0.99899906]\n",
      "Minibatch loss at epoch 82 and iter 110699: 0.000000 and the learning rate: 0.056880\n",
      "Minibatch train and validation accuracy: 100.000%, 96.368%\n",
      "Time interval: 963.7736 seconds, estimated run time for 200 epochs: 44.7690 hours\n",
      "[ 0.94054794  0.90265912  0.8212108   0.93774909  0.95328414  0.9301759\n",
      "  0.9698292   0.94349426  0.94132733  0.98502195  0.9900344   0.98934281\n",
      "  0.98433506  0.9827193   0.99451321  0.98764777  0.91711766  0.9987492\n",
      "  0.98352426  0.98763549  0.92414111  0.94285667  0.9955129   0.97046572\n",
      "  0.97084349  0.96790451  0.98117834  0.99347675  0.96618313  0.9905749\n",
      "  0.98328364  0.97758019  0.92850459  0.9932512   0.99051845  0.98613131\n",
      "  0.98399359  0.99749577  0.96553439  0.99452138  0.94529605  0.82141894\n",
      "  0.99724197]\n",
      "Minibatch loss at epoch 83 and iter 112049: 0.000009 and the learning rate: 0.056880\n",
      "Minibatch train and validation accuracy: 100.000%, 95.575%\n",
      "Time interval: 944.1035 seconds, estimated run time for 200 epochs: 44.8616 hours\n",
      "[ 0.92846525  0.88263881  0.82329273  0.94311965  0.94199377  0.93016446\n",
      "  0.83528382  0.94098157  0.95047957  0.98851097  0.98809475  0.98108524\n",
      "  0.97982812  0.98301649  0.99476391  0.98984349  0.9309144   0.99800152\n",
      "  0.98456126  0.99082065  0.93851769  0.93094456  0.99824727  0.96672285\n",
      "  0.95877582  0.97116792  0.97440898  0.99423367  0.97748363  0.99328816\n",
      "  0.98715997  0.97172314  0.95165467  0.99200344  0.98532653  0.9790377\n",
      "  0.97894174  0.99749571  0.95807719  0.99700552  0.90831959  0.65205598\n",
      "  0.99298197]\n",
      "Minibatch loss at epoch 84 and iter 113399: 0.000000 and the learning rate: 0.056880\n",
      "Minibatch train and validation accuracy: 100.000%, 96.246%\n",
      "Time interval: 1043.6521 seconds, estimated run time for 200 epochs: 45.0177 hours\n",
      "[ 0.91794032  0.8957997   0.84715128  0.95142806  0.91454923  0.94445765\n",
      "  0.97692633  0.9774062   0.96311122  0.98349947  0.9905327   0.98375934\n",
      "  0.98311865  0.97919232  0.99625605  0.97919172  0.84801334  0.998999\n",
      "  0.98604828  0.97510934  0.93446493  0.91466618  0.99700403  0.9848668\n",
      "  0.9718377   0.96971178  0.97584969  0.99472183  0.98518473  0.99205911\n",
      "  0.99304134  0.94490772  0.95440394  0.992477    0.98574585  0.97934043\n",
      "  0.98715365  0.99724472  0.96425766  0.99725437  0.93857199  0.82333827\n",
      "  0.99219292]\n",
      "Minibatch loss at epoch 85 and iter 114749: 0.000002 and the learning rate: 0.056880\n",
      "Minibatch train and validation accuracy: 100.000%, 96.242%\n",
      "Time interval: 1007.5315 seconds, estimated run time for 200 epochs: 45.1466 hours\n",
      "[ 0.94203562  0.88687497  0.8024869   0.95256209  0.94644552  0.93284976\n",
      "  0.95297164  0.97264242  0.95110404  0.98505181  0.99125171  0.98060352\n",
      "  0.98334134  0.9786374   0.99725157  0.98497862  0.89931363  0.99924862\n",
      "  0.98338658  0.97345948  0.93801063  0.92089313  0.9969995   0.97878593\n",
      "  0.95582074  0.96785575  0.97221494  0.99422783  0.98206776  0.99625796\n",
      "  0.99252945  0.9548195   0.95095193  0.98998451  0.98827004  0.98085964\n",
      "  0.98302531  0.99824995  0.96368742  0.99600947  0.93259507  0.8313663\n",
      "  0.98916006]\n",
      "Minibatch loss at epoch 86 and iter 116099: 0.000039 and the learning rate: 0.056880\n",
      "Minibatch train and validation accuracy: 100.000%, 96.127%\n",
      "Time interval: 670.4771 seconds, estimated run time for 200 epochs: 45.0548 hours\n",
      "[ 0.942092    0.88993418  0.8098011   0.94026291  0.95871735  0.93593401\n",
      "  0.90942228  0.9793303   0.96417707  0.98802948  0.98783165  0.96899176\n",
      "  0.97929245  0.97737515  0.99675357  0.98473608  0.93244636  0.9977501\n",
      "  0.98069263  0.98181772  0.93938547  0.92541176  0.99749953  0.96951914\n",
      "  0.96755874  0.96617067  0.97369021  0.99148673  0.98690987  0.9955197\n",
      "  0.99203926  0.96202487  0.93962842  0.99046612  0.9853484   0.97949052\n",
      "  0.98303366  0.99600351  0.96265721  0.99774897  0.92125535  0.76906091\n",
      "  0.99575269]\n",
      "Minibatch loss at epoch 87 and iter 117449: 0.000008 and the learning rate: 0.056880\n",
      "Minibatch train and validation accuracy: 100.000%, 95.612%\n",
      "Time interval: 668.0662 seconds, estimated run time for 200 epochs: 44.9635 hours\n",
      "[ 0.94149816  0.90279168  0.83590573  0.95440394  0.95116007  0.93900317\n",
      "  0.83260322  0.96233654  0.95751667  0.98972642  0.99079329  0.96223193\n",
      "  0.98356467  0.97984838  0.99625605  0.98473608  0.92801666  0.99775118\n",
      "  0.9818809   0.98813593  0.93797785  0.92394036  0.99749827  0.97521424\n",
      "  0.97367704  0.96803838  0.96919268  0.9937197   0.9893533   0.99576324\n",
      "  0.99304128  0.96929455  0.92371655  0.98903245  0.98403144  0.97812682\n",
      "  0.97131693  0.99476397  0.96343935  0.99700552  0.91583329  0.58040154\n",
      "  0.99474299]\n",
      "Minibatch loss at epoch 88 and iter 118799: 0.000008 and the learning rate: 0.056880\n",
      "Minibatch train and validation accuracy: 100.000%, 96.033%\n",
      "Time interval: 668.8954 seconds, estimated run time for 200 epochs: 44.8749 hours\n",
      "[ 0.93064833  0.90246415  0.84288096  0.95575172  0.93832976  0.94103211\n",
      "  0.96513265  0.97527492  0.96090752  0.9855212   0.98904884  0.97823381\n",
      "  0.98308462  0.97857273  0.99675518  0.9787125   0.79819775  0.99874985\n",
      "  0.97901708  0.97989166  0.94049454  0.91844767  0.99725026  0.97571695\n",
      "  0.97441101  0.97353643  0.97706485  0.99347013  0.98887461  0.99428242\n",
      "  0.99526727  0.95656317  0.9330529   0.99349302  0.98348302  0.98103857\n",
      "  0.97892112  0.996503    0.96343935  0.9977501   0.93916976  0.75780106\n",
      "  0.99472708]\n",
      "Minibatch loss at epoch 89 and iter 120149: 0.000000 and the learning rate: 0.054036\n",
      "Minibatch train and validation accuracy: 100.000%, 96.193%\n",
      "Time interval: 670.3180 seconds, estimated run time for 200 epochs: 44.7891 hours\n",
      "[ 0.94837707  0.90421009  0.82037801  0.95502347  0.95307153  0.93112504\n",
      "  0.95917338  0.96937245  0.95830125  0.98566705  0.99202347  0.97537136\n",
      "  0.98867309  0.978486    0.99775118  0.984236    0.83381712  0.99874985\n",
      "  0.98435509  0.95575172  0.93922609  0.9000535   0.99675685  0.97313237\n",
      "  0.97283399  0.97222877  0.98192573  0.99397844  0.98494893  0.99650997\n",
      "  0.99278742  0.95603818  0.94719344  0.99077487  0.99028111  0.98853385\n",
      "  0.98350114  0.99675196  0.96952724  0.99501944  0.94416451  0.79286003\n",
      "  0.9962486 ]\n",
      "Minibatch loss at epoch 90 and iter 121499: 0.000000 and the learning rate: 0.054036\n",
      "Minibatch train and validation accuracy: 100.000%, 96.297%\n",
      "Time interval: 670.4768 seconds, estimated run time for 200 epochs: 44.7053 hours\n",
      "[ 0.94407445  0.90007901  0.81897503  0.94445711  0.94919282  0.92596954\n",
      "  0.9621591   0.96931279  0.95383799  0.9879815   0.99078411  0.97607368\n",
      "  0.98536044  0.97961187  0.9960115   0.98471355  0.83473665  0.99825174\n",
      "  0.98433959  0.96382004  0.94068193  0.91566217  0.99675518  0.97018522\n",
      "  0.9656415   0.97517681  0.97901708  0.99371654  0.98593587  0.99576539\n",
      "  0.99354148  0.97152632  0.96618313  0.99227464  0.99077487  0.98753685\n",
      "  0.98545676  0.99774897  0.97052801  0.9969995   0.94404835  0.81359798\n",
      "  0.99649954]\n",
      "Minibatch loss at epoch 91 and iter 122849: 0.000000 and the learning rate: 0.054036\n",
      "Minibatch train and validation accuracy: 100.000%, 96.284%\n",
      "Time interval: 668.4576 seconds, estimated run time for 200 epochs: 44.6221 hours\n",
      "[ 0.93677115  0.89888191  0.84392697  0.95756358  0.93446434  0.93830729\n",
      "  0.95456672  0.96724039  0.95943159  0.98795742  0.9915334   0.97487146\n",
      "  0.98639059  0.97856194  0.996503    0.98207664  0.83391553  0.998501\n",
      "  0.98363054  0.96078861  0.93965691  0.92768818  0.99725157  0.97843814\n",
      "  0.97233558  0.9741767   0.98144889  0.99446917  0.98447841  0.99502188\n",
      "  0.99254793  0.97221494  0.95598036  0.99200755  0.98878038  0.98557156\n",
      "  0.98158556  0.99725157  0.97005033  0.99575692  0.94108635  0.7933957\n",
      "  0.99724609]\n",
      "Minibatch loss at epoch 92 and iter 124199: 0.000000 and the learning rate: 0.054036\n",
      "Minibatch train and validation accuracy: 100.000%, 96.234%\n",
      "Time interval: 670.7206 seconds, estimated run time for 200 epochs: 44.5421 hours\n",
      "[ 0.93664789  0.89605492  0.85442811  0.95529473  0.95507193  0.94433445\n",
      "  0.95796251  0.98053664  0.96399552  0.98847073  0.99300307  0.97990149\n",
      "  0.9879027   0.97834802  0.99725157  0.9823091   0.81023151  0.99850029\n",
      "  0.98140293  0.96310544  0.93716955  0.92440444  0.99700254  0.97776628\n",
      "  0.97494841  0.97428095  0.98072124  0.99397546  0.98352551  0.99502444\n",
      "  0.99526727  0.97338545  0.93476689  0.99300307  0.98925215  0.98510379\n",
      "  0.97701663  0.99799854  0.96787304  0.99675518  0.94314677  0.76143283\n",
      "  0.99345702]\n",
      "Minibatch loss at epoch 93 and iter 125549: 0.000001 and the learning rate: 0.054036\n",
      "Minibatch train and validation accuracy: 100.000%, 96.336%\n",
      "Time interval: 670.6240 seconds, estimated run time for 200 epochs: 44.4638 hours\n",
      "[ 0.94238228  0.90026617  0.85436851  0.95593828  0.95043266  0.94369268\n",
      "  0.93211991  0.9674437   0.96202487  0.98945743  0.9915123   0.97227579\n",
      "  0.98714995  0.98014534  0.99725431  0.98375934  0.86628842  0.9980005\n",
      "  0.9872908   0.97438353  0.94034117  0.93076879  0.99724883  0.98291612\n",
      "  0.97493553  0.97537398  0.98143971  0.99625051  0.9842515   0.99526727\n",
      "  0.99181294  0.9714421   0.94899124  0.99103093  0.98516417  0.97999454\n",
      "  0.98060352  0.99724609  0.96966583  0.99750328  0.92299694  0.77165693\n",
      "  0.99472445]\n",
      "Minibatch loss at epoch 94 and iter 126899: 0.005042 and the learning rate: 0.054036\n",
      "Minibatch train and validation accuracy: 100.000%, 96.136%\n",
      "Time interval: 670.8667 seconds, estimated run time for 200 epochs: 44.3873 hours\n",
      "[ 0.93342865  0.8909471   0.83804584  0.95710468  0.95555514  0.93618\n",
      "  0.94622087  0.98124337  0.96036309  0.98748702  0.99224377  0.97919172\n",
      "  0.98611408  0.97891521  0.99700254  0.97798383  0.79807937  0.99874985\n",
      "  0.98682529  0.96918178  0.94062209  0.92352581  0.99800152  0.97735059\n",
      "  0.96938467  0.97715694  0.98607612  0.9952364   0.98764163  0.99651176\n",
      "  0.99378836  0.97085422  0.94629711  0.99177217  0.98873538  0.9843784\n",
      "  0.9834767   0.99675035  0.97071517  0.99725294  0.9278084   0.76174998\n",
      "  0.99068666]\n",
      "Minibatch loss at epoch 95 and iter 128249: 0.000000 and the learning rate: 0.054036\n",
      "Minibatch train and validation accuracy: 100.000%, 96.020%\n",
      "Time interval: 670.0391 seconds, estimated run time for 200 epochs: 44.3119 hours\n",
      "[ 0.93158478  0.89072889  0.85865879  0.96061432  0.94193202  0.94547194\n",
      "  0.96636778  0.97880679  0.95610923  0.9879995   0.9927513   0.98374331\n",
      "  0.98587954  0.97681403  0.99800247  0.97060925  0.77126145  0.99775225\n",
      "  0.98214239  0.95531613  0.94089782  0.91653335  0.99825174  0.98380214\n",
      "  0.95952207  0.97539896  0.97944987  0.99522448  0.98642933  0.99651176\n",
      "  0.99551076  0.96524858  0.93436062  0.99225152  0.98872977  0.98632812\n",
      "  0.98519933  0.998748    0.96821719  0.99551523  0.93573737  0.75108922\n",
      "  0.99422783]\n",
      "Minibatch loss at epoch 96 and iter 129599: 0.000000 and the learning rate: 0.054036\n",
      "Minibatch train and validation accuracy: 100.000%, 96.347%\n",
      "Time interval: 670.9559 seconds, estimated run time for 200 epochs: 44.2386 hours\n",
      "[ 0.94162446  0.89938569  0.85327387  0.95365459  0.96379602  0.94499451\n",
      "  0.89162511  0.97860789  0.95809519  0.99122542  0.98906517  0.9823091\n",
      "  0.98536783  0.97983825  0.99725157  0.98497117  0.89685547  0.99626166\n",
      "  0.98824662  0.99050426  0.93741769  0.92356145  0.99824822  0.95331532\n",
      "  0.96091074  0.9782604   0.97779918  0.99472713  0.98376733  0.99502444\n",
      "  0.99304473  0.97297245  0.97158074  0.99276215  0.99000448  0.98458427\n",
      "  0.97869164  0.998748    0.96307641  0.99625981  0.93836427  0.75473642\n",
      "  0.99799854]\n",
      "Minibatch loss at epoch 97 and iter 130949: 0.000002 and the learning rate: 0.051334\n",
      "Minibatch train and validation accuracy: 100.000%, 96.393%\n",
      "Time interval: 669.5397 seconds, estimated run time for 200 epochs: 44.1660 hours\n",
      "[ 0.93405193  0.89366168  0.86215353  0.96128827  0.93794358  0.94638425\n",
      "  0.956083    0.98005366  0.96101898  0.99027139  0.9915418   0.97655052\n",
      "  0.9853456   0.97886217  0.99750197  0.97847307  0.81914854  0.99800253\n",
      "  0.98385847  0.97319639  0.94204378  0.92895842  0.99749702  0.97991514\n",
      "  0.95821387  0.97558445  0.9748764   0.99522924  0.98838598  0.99576539\n",
      "  0.99576324  0.96507889  0.98135382  0.99251074  0.98671967  0.98319286\n",
      "  0.9736709   0.99774897  0.96941853  0.99725014  0.93084651  0.81082273\n",
      "  0.99824911]\n",
      "Minibatch loss at epoch 98 and iter 132299: 0.000122 and the learning rate: 0.051334\n",
      "Minibatch train and validation accuracy: 100.000%, 96.294%\n",
      "Time interval: 671.5167 seconds, estimated run time for 200 epochs: 44.0960 hours\n",
      "[ 0.93094337  0.88467568  0.85423499  0.94804221  0.95509362  0.94627339\n",
      "  0.97197127  0.98512596  0.96491182  0.988083    0.99226308  0.982059\n",
      "  0.98557281  0.98042113  0.99775338  0.98038208  0.78271407  0.9992497\n",
      "  0.98602748  0.96800727  0.94126892  0.91569412  0.99725294  0.97225583\n",
      "  0.96491182  0.97819424  0.97560924  0.99573356  0.98546392  0.99452138\n",
      "  0.99576539  0.96233243  0.9786917   0.99201149  0.98902154  0.98634851\n",
      "  0.97655058  0.99824911  0.96571088  0.99725437  0.92239541  0.80820966\n",
      "  0.99849802]\n",
      "Minibatch loss at epoch 99 and iter 133649: 0.001398 and the learning rate: 0.051334\n",
      "Minibatch train and validation accuracy: 100.000%, 96.277%\n",
      "Time interval: 671.2628 seconds, estimated run time for 200 epochs: 44.0273 hours\n",
      "[ 0.93288869  0.88629687  0.85832602  0.95233506  0.95664763  0.94824988\n",
      "  0.9815312   0.98271561  0.96149951  0.98881382  0.99152917  0.9818266\n",
      "  0.98433506  0.98141587  0.99725431  0.9825505   0.75350529  0.99874985\n",
      "  0.98675948  0.96428525  0.94253427  0.91531676  0.99725294  0.9741056\n",
      "  0.96483922  0.97697908  0.9777773   0.99522209  0.98715997  0.99601144\n",
      "  0.99378836  0.96398979  0.96944666  0.9932546   0.99077034  0.98733503\n",
      "  0.98133552  0.99824822  0.96704936  0.99799752  0.92895573  0.79496586\n",
      "  0.9984988 ]\n",
      "Minibatch loss at epoch 100 and iter 134999: 0.000000 and the learning rate: 0.051334\n",
      "Minibatch train and validation accuracy: 100.000%, 95.934%\n",
      "Time interval: 671.4035 seconds, estimated run time for 200 epochs: 43.9600 hours\n",
      "[ 0.93111712  0.89039618  0.85319763  0.96963763  0.94176561  0.94747084\n",
      "  0.95126563  0.97498733  0.96081305  0.99000448  0.99225926  0.9758473\n",
      "  0.98434293  0.97729516  0.99825084  0.98206776  0.76405144  0.99900001\n",
      "  0.98552847  0.95415419  0.94148469  0.90719956  0.99700105  0.97966224\n",
      "  0.9676587   0.97500581  0.98042083  0.99573779  0.98789775  0.99625975\n",
      "  0.99205911  0.96634096  0.94225734  0.99005914  0.98433506  0.98263842\n",
      "  0.9817909   0.9984988   0.96480078  0.99725437  0.92406982  0.7485081\n",
      "  0.99041325]\n",
      "Minibatch loss at epoch 101 and iter 136349: 0.000000 and the learning rate: 0.051334\n",
      "Minibatch train and validation accuracy: 100.000%, 96.285%\n",
      "Time interval: 669.9444 seconds, estimated run time for 200 epochs: 43.8932 hours\n",
      "[ 0.93004066  0.89112437  0.85256904  0.96988779  0.94488138  0.94811153\n",
      "  0.97483462  0.97996491  0.96434754  0.99003446  0.99128222  0.97655052\n",
      "  0.98308462  0.9786374   0.99775225  0.98472106  0.7921564   0.99800152\n",
      "  0.98628724  0.96290892  0.94311875  0.91049093  0.99775118  0.9710921\n",
      "  0.96805716  0.97430676  0.97946006  0.99573994  0.99033886  0.99625975\n",
      "  0.99329484  0.97104961  0.96246344  0.99375737  0.98997444  0.98731607\n",
      "  0.97915089  0.99824822  0.96715003  0.99725294  0.91041619  0.8012557\n",
      "  0.99624109]\n",
      "Minibatch loss at epoch 102 and iter 137699: 0.000000 and the learning rate: 0.051334\n",
      "Minibatch train and validation accuracy: 100.000%, 96.244%\n",
      "Time interval: 670.3506 seconds, estimated run time for 200 epochs: 43.8280 hours\n",
      "[ 0.93769652  0.90290713  0.85905623  0.97012341  0.95045638  0.94785529\n",
      "  0.97216749  0.97352892  0.959701    0.99123418  0.99399948  0.97630048\n",
      "  0.98696047  0.98036206  0.99775118  0.98667932  0.7766214   0.99874926\n",
      "  0.98481405  0.96681958  0.94061965  0.91504616  0.99775118  0.97280031\n",
      "  0.96949452  0.97407454  0.97995496  0.99497437  0.98862463  0.99625975\n",
      "  0.99280167  0.97057331  0.94247949  0.99302042  0.98845333  0.98509645\n",
      "  0.98108524  0.99774784  0.96641177  0.99725437  0.92922562  0.76919508\n",
      "  0.99547464]\n",
      "Minibatch loss at epoch 103 and iter 139049: 0.000473 and the learning rate: 0.051334\n",
      "Minibatch train and validation accuracy: 100.000%, 96.277%\n",
      "Time interval: 669.8812 seconds, estimated run time for 200 epochs: 43.7638 hours\n",
      "[ 0.93313688  0.90115619  0.85824764  0.9638375   0.94162452  0.94573218\n",
      "  0.98980814  0.97499955  0.963       0.98709631  0.99299252  0.97917128\n",
      "  0.98616302  0.97731805  0.99824911  0.98132628  0.81586689  0.9992497\n",
      "  0.97943968  0.95483828  0.94222641  0.90300244  0.9977501   0.96802497\n",
      "  0.96943182  0.97640145  0.97947025  0.98918736  0.99255162  0.99775118\n",
      "  0.99501443  0.96487755  0.9451791   0.99300653  0.98976737  0.98485923\n",
      "  0.97038782  0.99700105  0.97051305  0.99700403  0.92267996  0.80532557\n",
      "  0.99849725]\n",
      "Minibatch loss at epoch 104 and iter 140399: 0.000015 and the learning rate: 0.048767\n",
      "Minibatch train and validation accuracy: 100.000%, 95.885%\n",
      "Time interval: 671.2081 seconds, estimated run time for 200 epochs: 43.7016 hours\n",
      "[ 0.91247535  0.87770855  0.86082149  0.97038782  0.93173212  0.94944346\n",
      "  0.98784977  0.96702182  0.95364869  0.98539191  0.99349296  0.98641592\n",
      "  0.98263234  0.97691876  0.99800152  0.97298563  0.79518032  0.9994995\n",
      "  0.98305887  0.94739288  0.94136167  0.89194238  0.99775118  0.96605569\n",
      "  0.95921981  0.97381616  0.97727221  0.99372905  0.99082524  0.9945296\n",
      "  0.99083424  0.9603498   0.94851679  0.99250329  0.99029076  0.98578143\n",
      "  0.97630048  0.99824822  0.96757805  0.99675518  0.88109952  0.80071688\n",
      "  0.992185  ]\n",
      "Minibatch loss at epoch 105 and iter 141749: 0.000001 and the learning rate: 0.048767\n",
      "Minibatch train and validation accuracy: 100.000%, 95.927%\n",
      "Time interval: 670.3854 seconds, estimated run time for 200 epochs: 43.6401 hours\n",
      "[ 0.93409693  0.88819009  0.8558827   0.96705377  0.95926237  0.9485907\n",
      "  0.95813233  0.96745944  0.95672047  0.98533386  0.99125606  0.97677779\n",
      "  0.98062843  0.96877331  0.99775124  0.9758473   0.77352089  0.99849951\n",
      "  0.98725903  0.98036277  0.94012552  0.89275002  0.99724883  0.9536832\n",
      "  0.97104746  0.97450089  0.98405534  0.99524355  0.98667282  0.99452686\n",
      "  0.99181706  0.95164734  0.9587723   0.99276215  0.98798144  0.98534113\n",
      "  0.97227579  0.99675363  0.96435797  0.99750197  0.90469891  0.77192146\n",
      "  0.99648899]\n",
      "Minibatch loss at epoch 106 and iter 143099: 0.000003 and the learning rate: 0.048767\n",
      "Minibatch train and validation accuracy: 100.000%, 96.262%\n",
      "Time interval: 669.7428 seconds, estimated run time for 200 epochs: 43.5794 hours\n",
      "[ 0.95187885  0.90493655  0.86470222  0.96451801  0.96431202  0.94463629\n",
      "  0.95936471  0.95181251  0.9279753   0.99000955  0.99373543  0.9753353\n",
      "  0.98239392  0.97351772  0.99775338  0.98110384  0.84125102  0.99924898\n",
      "  0.98948902  0.98058438  0.93853819  0.92461205  0.99675357  0.98001432\n",
      "  0.95520777  0.97381616  0.98209798  0.99649078  0.98570681  0.99527198\n",
      "  0.99329484  0.95947534  0.93632913  0.9915207   0.98827595  0.98404741\n",
      "  0.97298563  0.99749953  0.96723342  0.99725157  0.93476546  0.78181332\n",
      "  0.99724883]\n",
      "Minibatch loss at epoch 107 and iter 144449: 0.000000 and the learning rate: 0.048767\n",
      "Minibatch train and validation accuracy: 100.000%, 96.543%\n",
      "Time interval: 671.1655 seconds, estimated run time for 200 epochs: 43.5206 hours\n",
      "[ 0.95328891  0.90986621  0.86614549  0.96708566  0.95207781  0.95054901\n",
      "  0.97552574  0.97739512  0.95098233  0.98677266  0.99274772  0.97894174\n",
      "  0.98312724  0.97388202  0.9979955   0.97775555  0.8478381   0.99874985\n",
      "  0.98759258  0.98085374  0.94154775  0.92571992  0.99774671  0.97928947\n",
      "  0.97240627  0.97925049  0.98426133  0.99422783  0.98546392  0.99626356\n",
      "  0.99650824  0.95449024  0.92528284  0.99251074  0.98798752  0.98456126\n",
      "  0.97796232  0.99725157  0.9668532   0.99799955  0.96092927  0.78586936\n",
      "  0.99899954]\n",
      "Minibatch loss at epoch 108 and iter 145799: 0.000000 and the learning rate: 0.048767\n",
      "Minibatch train and validation accuracy: 100.000%, 96.253%\n",
      "Time interval: 670.6185 seconds, estimated run time for 200 epochs: 43.4626 hours\n",
      "[ 0.94893032  0.9110409   0.84484667  0.95823282  0.93671447  0.94507569\n",
      "  0.95285904  0.9677102   0.93200952  0.98727179  0.9920035   0.98034352\n",
      "  0.98207474  0.97597551  0.99774671  0.97485918  0.86379069  0.99850023\n",
      "  0.9861244   0.98085368  0.94568318  0.89381456  0.99824911  0.98610377\n",
      "  0.9561376   0.97840953  0.97799706  0.99295378  0.98813593  0.99626166\n",
      "  0.99329484  0.92718285  0.95625103  0.99052322  0.98696697  0.98140293\n",
      "  0.97893137  0.99700254  0.96780741  0.99800056  0.95098233  0.80695766\n",
      "  0.9960075 ]\n",
      "Minibatch loss at epoch 109 and iter 147149: 0.000062 and the learning rate: 0.048767\n",
      "Minibatch train and validation accuracy: 100.000%, 96.397%\n",
      "Time interval: 669.1386 seconds, estimated run time for 200 epochs: 43.4049 hours\n",
      "[ 0.94970936  0.89125758  0.85274315  0.96194553  0.95745671  0.94765252\n",
      "  0.93788189  0.95888388  0.94259167  0.9875493   0.99225146  0.97630048\n",
      "  0.98183602  0.97769934  0.99799752  0.97943145  0.88379848  0.99825174\n",
      "  0.98903793  0.98084432  0.9435246   0.91332215  0.99849802  0.98293304\n",
      "  0.96105194  0.97767586  0.98039162  0.99497694  0.98570681  0.9942767\n",
      "  0.99304473  0.94443071  0.96362275  0.99076104  0.98650622  0.98286521\n",
      "  0.9758355   0.99700248  0.96498799  0.99775118  0.9431957   0.80971205\n",
      "  0.99700695]\n",
      "Minibatch loss at epoch 110 and iter 148499: 0.000016 and the learning rate: 0.048767\n",
      "Minibatch train and validation accuracy: 100.000%, 96.643%\n",
      "Time interval: 669.2262 seconds, estimated run time for 200 epochs: 43.3483 hours\n",
      "[ 0.93968964  0.89359379  0.85506797  0.96264112  0.96150053  0.94747078\n",
      "  0.9483943   0.97146988  0.95195144  0.98854536  0.99199152  0.9794113\n",
      "  0.98287976  0.97795546  0.99749827  0.98619282  0.89202613  0.99850023\n",
      "  0.98954654  0.98324251  0.94012552  0.925349    0.99849731  0.95882446\n",
      "  0.96237063  0.97817212  0.98453051  0.99623728  0.98135382  0.99601346\n",
      "  0.99353188  0.97385252  0.96618313  0.99201542  0.9879815   0.98580986\n",
      "  0.97822315  0.9969995   0.96597546  0.99775237  0.9481588   0.82899213\n",
      "  0.9967503 ]\n",
      "Minibatch loss at epoch 111 and iter 149849: 0.000000 and the learning rate: 0.048767\n",
      "Minibatch train and validation accuracy: 100.000%, 96.564%\n",
      "Time interval: 669.9148 seconds, estimated run time for 200 epochs: 43.2931 hours\n",
      "[ 0.95318484  0.90123743  0.84621871  0.96013397  0.96428525  0.93688452\n",
      "  0.93543035  0.96371508  0.94414914  0.99052316  0.9917475   0.98037237\n",
      "  0.98317808  0.97888339  0.99775118  0.98327547  0.89782381  0.99899858\n",
      "  0.9868384   0.98470598  0.9410218   0.92996269  0.99824727  0.96576786\n",
      "  0.96072304  0.97773236  0.98160064  0.99396938  0.98351735  0.99477428\n",
      "  0.99131685  0.97194833  0.96360523  0.99177623  0.98899955  0.98556447\n",
      "  0.98084432  0.99750084  0.96727967  0.99725157  0.94430327  0.8129546\n",
      "  0.99700552]\n",
      "Minibatch loss at epoch 112 and iter 151199: 0.000000 and the learning rate: 0.046329\n",
      "Minibatch train and validation accuracy: 100.000%, 96.484%\n",
      "Time interval: 670.3578 seconds, estimated run time for 200 epochs: 43.2390 hours\n",
      "[ 0.93783343  0.89141297  0.85553956  0.98249888  0.94595844  0.93039894\n",
      "  0.94841886  0.94153804  0.93388176  0.98827595  0.99150801  0.97345948\n",
      "  0.98138785  0.97803533  0.99825174  0.98690343  0.90571147  0.99750453\n",
      "  0.98489684  0.9793911   0.9407441   0.93078083  0.99849802  0.9750362\n",
      "  0.96154791  0.97282141  0.97820663  0.99322414  0.98959833  0.99427956\n",
      "  0.98934799  0.97003877  0.97276211  0.9900443   0.98507416  0.98577446\n",
      "  0.98037237  0.99774897  0.96235543  0.99625796  0.92829561  0.84509081\n",
      "  0.99600148]\n",
      "Minibatch loss at epoch 113 and iter 152549: 0.000004 and the learning rate: 0.046329\n",
      "Minibatch train and validation accuracy: 100.000%, 96.384%\n",
      "Time interval: 671.7872 seconds, estimated run time for 200 epochs: 43.1867 hours\n",
      "[ 0.92807263  0.8777169   0.86231446  0.9815675   0.93301839  0.94425213\n",
      "  0.96508193  0.95967108  0.93722731  0.98753691  0.99126041  0.97322249\n",
      "  0.98391908  0.9739697   0.99675035  0.97724444  0.92245513  0.99800247\n",
      "  0.9853847   0.9794113   0.93941736  0.94270104  0.99749953  0.98440933\n",
      "  0.96091068  0.97327513  0.97726107  0.99275494  0.98570681  0.99601346\n",
      "  0.99253678  0.96935469  0.92077339  0.99045658  0.98081189  0.98460722\n",
      "  0.97558546  0.996503    0.95591956  0.99526489  0.93892896  0.81908196\n",
      "  0.99422789]\n",
      "Minibatch loss at epoch 114 and iter 153899: 0.000000 and the learning rate: 0.046329\n",
      "Minibatch train and validation accuracy: 100.000%, 96.037%\n",
      "Time interval: 669.0293 seconds, estimated run time for 200 epochs: 43.1339 hours\n",
      "[ 0.93401212  0.87571341  0.85412568  0.97723335  0.93355429  0.93757486\n",
      "  0.93647015  0.94368148  0.92636895  0.98748076  0.9917475   0.98494893\n",
      "  0.9854266   0.97447515  0.99725157  0.97535938  0.91235662  0.99824995\n",
      "  0.98759252  0.97606206  0.94250411  0.93333292  0.9980005   0.98652649\n",
      "  0.96045446  0.97073001  0.98212469  0.99499702  0.98544955  0.99303436\n",
      "  0.98960352  0.95906949  0.91295362  0.99149954  0.97923398  0.98363048\n",
      "  0.97558546  0.99649251  0.95401078  0.99700552  0.93907303  0.75033766\n",
      "  0.99750328]\n",
      "Minibatch loss at epoch 115 and iter 155249: 0.000000 and the learning rate: 0.046329\n",
      "Minibatch train and validation accuracy: 100.000%, 96.412%\n",
      "Time interval: 670.1315 seconds, estimated run time for 200 epochs: 43.0825 hours\n",
      "[ 0.94499111  0.8938424   0.87422854  0.97964138  0.9590838   0.94705689\n",
      "  0.96811831  0.96317786  0.93818879  0.98752451  0.99075645  0.98062253\n",
      "  0.98647249  0.97569573  0.99774557  0.98350924  0.88111848  0.99825174\n",
      "  0.98537028  0.97442096  0.93644905  0.92979181  0.99750072  0.98318446\n",
      "  0.95779002  0.97312325  0.97917658  0.99224758  0.98352551  0.9967584\n",
      "  0.99526966  0.95945573  0.92739457  0.99098152  0.9827711   0.98611063\n",
      "  0.97534734  0.99574852  0.9540996   0.9980005   0.93960345  0.79452008\n",
      "  0.99775118]\n",
      "Minibatch loss at epoch 116 and iter 156599: 0.000000 and the learning rate: 0.046329\n",
      "Minibatch train and validation accuracy: 100.000%, 96.349%\n",
      "Time interval: 669.9226 seconds, estimated run time for 200 epochs: 43.0320 hours\n",
      "[ 0.94660842  0.89411092  0.86991823  0.97603863  0.96232831  0.94538283\n",
      "  0.95863348  0.96276551  0.93786705  0.98802948  0.99101299  0.98276663\n",
      "  0.9854486   0.97775477  0.99774337  0.98132628  0.88087201  0.99824995\n",
      "  0.98561454  0.97726673  0.93840063  0.92511898  0.99750328  0.98341942\n",
      "  0.95945895  0.97499323  0.97967231  0.99398452  0.98135382  0.99601144\n",
      "  0.99427956  0.95240337  0.925497    0.99251074  0.98173583  0.9875493\n",
      "  0.9779731   0.99700105  0.95321292  0.99825084  0.93829578  0.78177655\n",
      "  0.99699801]\n",
      "Minibatch loss at epoch 117 and iter 157949: 0.000000 and the learning rate: 0.046329\n",
      "Minibatch train and validation accuracy: 100.000%, 96.500%\n",
      "Time interval: 670.4346 seconds, estimated run time for 200 epochs: 42.9825 hours\n",
      "[ 0.94380355  0.89336514  0.87202972  0.97652769  0.9574101   0.94589913\n",
      "  0.92940581  0.9665044   0.93896896  0.98827004  0.99000949  0.97916102\n",
      "  0.98696691  0.97602779  0.99774784  0.98522115  0.93279952  0.99775225\n",
      "  0.9856289   0.98084432  0.93609172  0.93448585  0.99774784  0.98269856\n",
      "  0.95073324  0.97203815  0.97970247  0.99197137  0.98279202  0.99650824\n",
      "  0.99328142  0.96393716  0.93890929  0.99276215  0.98228937  0.98553568\n",
      "  0.9758119   0.99699199  0.95885456  0.99725437  0.94529051  0.79173332\n",
      "  0.99750084]\n",
      "Minibatch loss at epoch 118 and iter 159299: 0.000004 and the learning rate: 0.046329\n",
      "Minibatch train and validation accuracy: 100.000%, 95.936%\n",
      "Time interval: 669.5822 seconds, estimated run time for 200 epochs: 42.9335 hours\n",
      "[ 0.9331708   0.89082235  0.88044888  0.98278356  0.93871689  0.95294952\n",
      "  0.89452374  0.97359365  0.95276749  0.9870255   0.99000949  0.97868127\n",
      "  0.98640436  0.97983825  0.99750078  0.98061299  0.84858906  0.99800247\n",
      "  0.9856146   0.9777447   0.9392581   0.91911912  0.99800056  0.98487431\n",
      "  0.96161777  0.97537392  0.97323787  0.99422789  0.98764777  0.99477428\n",
      "  0.99401742  0.94782144  0.9293347   0.99222034  0.98440933  0.98487431\n",
      "  0.98640919  0.99649781  0.96078384  0.99825084  0.93887722  0.67474276\n",
      "  0.99421626]\n",
      "Minibatch loss at epoch 119 and iter 160649: 0.000000 and the learning rate: 0.044013\n",
      "Minibatch train and validation accuracy: 100.000%, 95.880%\n",
      "Time interval: 671.0097 seconds, estimated run time for 200 epochs: 42.8860 hours\n",
      "[ 0.93790722  0.89217705  0.87039     0.97822315  0.94512296  0.94809639\n",
      "  0.91171044  0.97098225  0.9507944   0.98724633  0.99050903  0.98036277\n",
      "  0.98665947  0.978562    0.99750197  0.98062247  0.83643728  0.99825084\n",
      "  0.98756176  0.97797304  0.93966371  0.91992509  0.99749827  0.98610377\n",
      "  0.96535629  0.9769206   0.97557318  0.99573779  0.98400939  0.99403536\n",
      "  0.99352866  0.94948477  0.90273029  0.99324107  0.98536295  0.98537022\n",
      "  0.98617917  0.99674541  0.96404678  0.99800152  0.9452256   0.66228938\n",
      "  0.98860997]\n",
      "Minibatch loss at epoch 120 and iter 161999: 0.000001 and the learning rate: 0.044013\n",
      "Minibatch train and validation accuracy: 100.000%, 95.707%\n",
      "Time interval: 672.0489 seconds, estimated run time for 200 epochs: 42.8397 hours\n",
      "[ 0.93797451  0.89212012  0.86465704  0.9736709   0.93937165  0.94698036\n",
      "  0.9709397   0.95836288  0.94527823  0.9835816   0.99149102  0.97059494\n",
      "  0.98414254  0.97416371  0.99799955  0.97680044  0.74906087  0.99900001\n",
      "  0.98391432  0.96777278  0.93677509  0.92044801  0.99526727  0.98435509\n",
      "  0.96542776  0.96856582  0.97630751  0.99573141  0.98593587  0.99650824\n",
      "  0.98983842  0.95428252  0.90191609  0.99125165  0.98802352  0.9843474\n",
      "  0.98349303  0.99700248  0.96906114  0.9940235   0.93518943  0.70204794\n",
      "  0.99623543]\n",
      "Minibatch loss at epoch 121 and iter 163349: 0.000000 and the learning rate: 0.044013\n",
      "Minibatch train and validation accuracy: 100.000%, 95.791%\n",
      "Time interval: 670.2671 seconds, estimated run time for 200 epochs: 42.7934 hours\n",
      "[ 0.95014334  0.89374125  0.79251957  0.92400044  0.96753359  0.92863941\n",
      "  0.92168623  0.96280146  0.94302809  0.9877342   0.98953611  0.97062349\n",
      "  0.98488617  0.97412431  0.99749953  0.9818266   0.87020266  0.99900055\n",
      "  0.98512596  0.97676641  0.93666178  0.9193241   0.99625981  0.98099184\n",
      "  0.96033132  0.96904528  0.97946006  0.9942221   0.98109454  0.99428242\n",
      "  0.98838025  0.95502847  0.92653489  0.99027139  0.98778313  0.98456126\n",
      "  0.97844148  0.99775118  0.96587068  0.99551743  0.93840253  0.72755456\n",
      "  0.99575484]\n",
      "Minibatch loss at epoch 122 and iter 164699: 0.000001 and the learning rate: 0.044013\n",
      "Minibatch train and validation accuracy: 100.000%, 96.313%\n",
      "Time interval: 670.8044 seconds, estimated run time for 200 epochs: 42.7481 hours\n",
      "[ 0.94187659  0.89144957  0.83755285  0.94689375  0.96330905  0.94223255\n",
      "  0.95941985  0.96278346  0.94952476  0.98560035  0.98925221  0.97198486\n",
      "  0.98460716  0.97781092  0.99700254  0.98352551  0.89945006  0.99750572\n",
      "  0.98634177  0.97272229  0.93705511  0.92049938  0.99749953  0.9822042\n",
      "  0.96300077  0.97407168  0.98117834  0.99497694  0.98351735  0.99427956\n",
      "  0.98885816  0.95835304  0.93454838  0.99200755  0.9831093   0.98537022\n",
      "  0.97653908  0.99749827  0.96410209  0.99750328  0.93435848  0.80556214\n",
      "  0.99799651]\n",
      "Minibatch loss at epoch 123 and iter 166049: 0.000001 and the learning rate: 0.044013\n",
      "Minibatch train and validation accuracy: 100.000%, 96.293%\n",
      "Time interval: 668.7237 seconds, estimated run time for 200 epochs: 42.7026 hours\n",
      "[ 0.93702602  0.8874132   0.83789903  0.95206255  0.96162254  0.94262844\n",
      "  0.97068834  0.9707312   0.94972301  0.98536295  0.99025196  0.97653908\n",
      "  0.98487091  0.97827137  0.99725294  0.98135382  0.88430399  0.99874985\n",
      "  0.98560035  0.9725123   0.93730199  0.91922104  0.99700099  0.98218656\n",
      "  0.96294332  0.97648501  0.97969246  0.99498951  0.98183554  0.9945296\n",
      "  0.99329144  0.95696282  0.92592549  0.99275863  0.98623919  0.9858731\n",
      "  0.97319639  0.99774671  0.96305752  0.99750197  0.93588716  0.80009913\n",
      "  0.9977411 ]\n",
      "Minibatch loss at epoch 124 and iter 167399: 0.000000 and the learning rate: 0.044013\n",
      "Minibatch train and validation accuracy: 100.000%, 96.777%\n",
      "Time interval: 669.2053 seconds, estimated run time for 200 epochs: 42.6581 hours\n",
      "[ 0.94350368  0.89053756  0.85896325  0.9694615   0.9643116   0.94529486\n",
      "  0.92200518  0.94699264  0.94327092  0.98775876  0.98878592  0.97297251\n",
      "  0.98549229  0.98110306  0.99725157  0.99230146  0.98036164  0.99850172\n",
      "  0.99174333  0.9810946   0.93424833  0.94117606  0.99699801  0.98243833\n",
      "  0.96772486  0.9769907   0.9818899   0.99725294  0.97919172  0.99378526\n",
      "  0.99033409  0.97175092  0.96525049  0.99251074  0.98474568  0.98557884\n",
      "  0.97202575  0.99650127  0.96282959  0.99774897  0.92212111  0.85532457\n",
      "  0.9987492 ]\n",
      "Model saved\n",
      "Minibatch loss at epoch 125 and iter 168749: 0.000000 and the learning rate: 0.044013\n",
      "Minibatch train and validation accuracy: 100.000%, 96.574%\n",
      "Time interval: 672.0569 seconds, estimated run time for 200 epochs: 42.6155 hours\n",
      "[ 0.94448411  0.8860954   0.84734279  0.96406996  0.9595117   0.94228399\n",
      "  0.91230446  0.96044338  0.94936663  0.98726541  0.98978275  0.97655058\n",
      "  0.98573166  0.98136914  0.99725157  0.98813009  0.96669203  0.99850029\n",
      "  0.99099499  0.97821248  0.93618101  0.93621403  0.99700248  0.98367095\n",
      "  0.96642512  0.97675544  0.97995496  0.99674875  0.97943145  0.99378526\n",
      "  0.9910754   0.96585321  0.95529473  0.99301004  0.9839915   0.98607606\n",
      "  0.9736709   0.99649429  0.96288669  0.99775118  0.92167997  0.81759906\n",
      "  0.9977445 ]\n",
      "Minibatch loss at epoch 126 and iter 170099: 0.000000 and the learning rate: 0.041812\n",
      "Minibatch train and validation accuracy: 100.000%, 96.282%\n",
      "Time interval: 670.3183 seconds, estimated run time for 200 epochs: 42.5729 hours\n",
      "[ 0.92419773  0.87269765  0.85127878  0.96753824  0.91829103  0.94140297\n",
      "  0.95459956  0.9815641   0.95337003  0.98604834  0.99026662  0.97822315\n",
      "  0.98822296  0.9797771   0.99675363  0.97870207  0.93814659  0.99825263\n",
      "  0.98608994  0.96500069  0.93786156  0.91896147  0.99750197  0.98237723\n",
      "  0.95812696  0.97727227  0.97396803  0.99376357  0.98399365  0.99626356\n",
      "  0.99427384  0.96013564  0.91890603  0.99221647  0.98524582  0.98414224\n",
      "  0.9736709   0.99699801  0.96625721  0.99625605  0.93192321  0.80556995\n",
      "  0.99749202]\n",
      "Minibatch loss at epoch 127 and iter 171449: 0.000000 and the learning rate: 0.041812\n",
      "Minibatch train and validation accuracy: 100.000%, 96.204%\n",
      "Time interval: 671.3786 seconds, estimated run time for 200 epochs: 42.5313 hours\n",
      "[ 0.92924929  0.87333459  0.84776413  0.96196383  0.94759464  0.94316757\n",
      "  0.93754369  0.97758019  0.95610201  0.98824656  0.99200755  0.9793911\n",
      "  0.98724633  0.98078817  0.99750078  0.9818266   0.92933571  0.9987511\n",
      "  0.98680562  0.96728814  0.9352361   0.92424989  0.99700254  0.98555011\n",
      "  0.96727598  0.97439754  0.98043048  0.99599957  0.97821254  0.99304819\n",
      "  0.99329144  0.96091235  0.9086774   0.99248075  0.98700601  0.98239475\n",
      "  0.97534734  0.99749827  0.96652138  0.99625802  0.91946787  0.76140696\n",
      "  0.99673563]\n",
      "Minibatch loss at epoch 128 and iter 172799: 0.000002 and the learning rate: 0.041812\n",
      "Minibatch train and validation accuracy: 100.000%, 96.422%\n",
      "Time interval: 670.1609 seconds, estimated run time for 200 epochs: 42.4899 hours\n",
      "[ 0.94097763  0.88953137  0.82954818  0.95165467  0.94895715  0.93136281\n",
      "  0.94534171  0.97990525  0.954786    0.98902148  0.99075645  0.97966135\n",
      "  0.98998451  0.98262352  0.9979955   0.98690343  0.92567706  0.99825263\n",
      "  0.9856146   0.97274894  0.93984717  0.9224202   0.99675357  0.98268133\n",
      "  0.96051896  0.97494256  0.9756093   0.99372911  0.98328364  0.99899954\n",
      "  0.99378526  0.95715272  0.93277258  0.99299949  0.98595035  0.98440158\n",
      "  0.97821248  0.99674869  0.96625721  0.99700254  0.94334805  0.80525571\n",
      "  0.99699354]\n",
      "Minibatch loss at epoch 129 and iter 174149: 0.000000 and the learning rate: 0.041812\n",
      "Minibatch train and validation accuracy: 100.000%, 95.601%\n",
      "Time interval: 671.3913 seconds, estimated run time for 200 epochs: 42.4497 hours\n",
      "[ 0.93959355  0.88522828  0.8238681   0.95823282  0.94199711  0.92318553\n",
      "  0.83162898  0.96871901  0.94349092  0.98851097  0.9907611   0.9789108\n",
      "  0.98744929  0.97590613  0.99750084  0.98910844  0.92166847  0.99875051\n",
      "  0.98389047  0.98304206  0.94148469  0.9201597   0.996503    0.98268992\n",
      "  0.95568252  0.97549844  0.97365129  0.99093604  0.98497862  0.99775225\n",
      "  0.99106205  0.94148386  0.94627172  0.99273324  0.98194534  0.97925872\n",
      "  0.97393376  0.9967438   0.96634322  0.9980005   0.9301964   0.63362151\n",
      "  0.99295723]\n",
      "Minibatch loss at epoch 130 and iter 175499: 0.000000 and the learning rate: 0.041812\n",
      "Minibatch train and validation accuracy: 100.000%, 96.431%\n",
      "Time interval: 670.4082 seconds, estimated run time for 200 epochs: 42.4096 hours\n",
      "[ 0.93612915  0.87506461  0.84425485  0.9725123   0.95166695  0.93847966\n",
      "  0.93308324  0.97237796  0.95731205  0.98803544  0.99026173  0.97606206\n",
      "  0.98796946  0.97925055  0.99725014  0.99082065  0.89647537  0.99874985\n",
      "  0.98565012  0.9787125   0.93583262  0.93722498  0.99750328  0.97882766\n",
      "  0.96649438  0.97368377  0.98601353  0.99348974  0.9825505   0.99650651\n",
      "  0.99082971  0.97282565  0.96333766  0.99423659  0.98177224  0.98188984\n",
      "  0.97131693  0.99624676  0.96553439  0.99775237  0.91759193  0.80963087\n",
      "  0.99799752]\n",
      "Minibatch loss at epoch 131 and iter 176849: 0.000000 and the learning rate: 0.041812\n",
      "Minibatch train and validation accuracy: 100.000%, 96.142%\n",
      "Time interval: 669.9053 seconds, estimated run time for 200 epochs: 42.3700 hours\n",
      "[ 0.93909669  0.8795861   0.8411743   0.96015316  0.95841444  0.9376505\n",
      "  0.86865556  0.97027248  0.9520216   0.98780745  0.99024707  0.97964138\n",
      "  0.98819345  0.97929245  0.99725026  0.98740381  0.91851002  0.99900001\n",
      "  0.98953092  0.97989166  0.93810862  0.93242848  0.99724609  0.97311783\n",
      "  0.96466291  0.97726077  0.98282254  0.99574423  0.98159462  0.99502188\n",
      "  0.98984849  0.97486395  0.96265912  0.99450511  0.9872399   0.98263842\n",
      "  0.97178936  0.99724472  0.96429443  0.99625605  0.91915727  0.72958714\n",
      "  0.99523163]\n",
      "Minibatch loss at epoch 132 and iter 178199: 0.000002 and the learning rate: 0.041812\n",
      "Minibatch train and validation accuracy: 100.000%, 96.218%\n",
      "Time interval: 669.7760 seconds, estimated run time for 200 epochs: 42.3309 hours\n",
      "[ 0.93609869  0.87671185  0.84359872  0.9631409   0.95592839  0.93454766\n",
      "  0.91797191  0.97833526  0.96066105  0.98828173  0.98977757  0.97844148\n",
      "  0.98671961  0.9816162   0.99675357  0.98862463  0.85147899  0.998501\n",
      "  0.98952043  0.97962141  0.93854994  0.93012255  0.99774784  0.97428316\n",
      "  0.96936893  0.97491717  0.98332042  0.99623919  0.98328364  0.99576324\n",
      "  0.99058425  0.9724676   0.96315867  0.99425095  0.98775262  0.9834522\n",
      "  0.9777447   0.9967438   0.96505606  0.99775118  0.91657984  0.76122296\n",
      "  0.99799353]\n",
      "Minibatch loss at epoch 133 and iter 179549: 0.000002 and the learning rate: 0.041812\n",
      "Minibatch train and validation accuracy: 100.000%, 95.928%\n",
      "Time interval: 670.8701 seconds, estimated run time for 200 epochs: 42.2929 hours\n",
      "[ 0.94973373  0.89588708  0.83203638  0.9678039   0.95848632  0.92577612\n",
      "  0.86055553  0.93658948  0.92961305  0.98844755  0.98927897  0.96846139\n",
      "  0.98800558  0.98072976  0.99700254  0.99205512  0.91097146  0.9980005\n",
      "  0.9900344   0.98061299  0.93656182  0.93670839  0.99749953  0.98078775\n",
      "  0.96603143  0.96998936  0.98429275  0.99526018  0.982059    0.99626166\n",
      "  0.98813009  0.97836316  0.96173239  0.9843784   0.98550677  0.97856569\n",
      "  0.96819568  0.99549729  0.96088475  0.99032933  0.92443925  0.71567762\n",
      "  0.99522448]\n",
      "Minibatch loss at epoch 134 and iter 180899: 0.000011 and the learning rate: 0.039721\n",
      "Minibatch train and validation accuracy: 100.000%, 95.721%\n",
      "Time interval: 668.8174 seconds, estimated run time for 200 epochs: 42.2545 hours\n",
      "[ 0.93320334  0.87704873  0.83189362  0.95256209  0.94587392  0.93310905\n",
      "  0.96595287  0.97880679  0.95625895  0.98507416  0.98805332  0.98253334\n",
      "  0.98490143  0.98008525  0.99700403  0.98255903  0.76505047  0.99825174\n",
      "  0.98928964  0.96548343  0.93987876  0.87610573  0.99775118  0.96881044\n",
      "  0.96386117  0.9741506   0.98185384  0.99599755  0.98715997  0.99477434\n",
      "  0.99009365  0.94218373  0.94403726  0.99297851  0.98552847  0.98150378\n",
      "  0.97485918  0.99699193  0.96342045  0.99749953  0.91881973  0.7616483\n",
      "  0.99547917]\n",
      "Minibatch loss at epoch 135 and iter 182249: 0.000001 and the learning rate: 0.039721\n",
      "Minibatch train and validation accuracy: 100.000%, 96.075%\n",
      "Time interval: 670.6913 seconds, estimated run time for 200 epochs: 42.2175 hours\n",
      "[ 0.95194131  0.89426243  0.82027334  0.94510132  0.96084142  0.93091035\n",
      "  0.95203787  0.97102457  0.95487726  0.98875237  0.98807108  0.98204136\n",
      "  0.98617697  0.97804648  0.99749953  0.98813593  0.82072371  0.99900055\n",
      "  0.98904335  0.96943182  0.93956864  0.90292794  0.99749577  0.97117686\n",
      "  0.96332598  0.97463167  0.98281395  0.99499702  0.98278362  0.99601144\n",
      "  0.98715371  0.95513701  0.9519043   0.9932546   0.98505932  0.98344404\n",
      "  0.97440851  0.9967438   0.96397281  0.99675685  0.9351514   0.78252697\n",
      "  0.99675196]\n",
      "Minibatch loss at epoch 136 and iter 183599: 0.000074 and the learning rate: 0.039721\n",
      "Minibatch train and validation accuracy: 100.000%, 95.879%\n",
      "Time interval: 670.3911 seconds, estimated run time for 200 epochs: 42.1810 hours\n",
      "[ 0.94316757  0.88318443  0.81820792  0.94423395  0.95134306  0.92599577\n",
      "  0.95457774  0.97546566  0.95460194  0.9877587   0.98831093  0.9822917\n",
      "  0.98519403  0.97907686  0.99700254  0.98619282  0.7921564   0.99924862\n",
      "  0.98928434  0.96897674  0.94133002  0.89059871  0.99774897  0.97448426\n",
      "  0.96464467  0.97670835  0.98602748  0.99574208  0.98277509  0.99576753\n",
      "  0.98764777  0.94673944  0.95185846  0.99425381  0.98399156  0.97980249\n",
      "  0.97345948  0.99624103  0.96583563  0.99725437  0.9315064   0.77018017\n",
      "  0.99649948]\n",
      "Minibatch loss at epoch 137 and iter 184949: 0.000000 and the learning rate: 0.039721\n",
      "Minibatch train and validation accuracy: 100.000%, 95.954%\n",
      "Time interval: 670.6191 seconds, estimated run time for 200 epochs: 42.1450 hours\n",
      "[ 0.94060791  0.8811695   0.83519584  0.95054638  0.94916838  0.93570012\n",
      "  0.95395637  0.97670949  0.95678347  0.98750573  0.98806518  0.982059\n",
      "  0.98568869  0.98032242  0.99725157  0.98789179  0.79154038  0.99924934\n",
      "  0.99051851  0.9699316   0.94034123  0.88913232  0.99774897  0.97452182\n",
      "  0.96548122  0.97572035  0.98453051  0.99599349  0.98351735  0.99502188\n",
      "  0.98862463  0.94291103  0.95575172  0.99399358  0.98601347  0.98050779\n",
      "  0.97510934  0.99674219  0.96661484  0.99700254  0.92766351  0.77270603\n",
      "  0.9969995 ]\n",
      "Minibatch loss at epoch 138 and iter 186299: 0.000014 and the learning rate: 0.039721\n",
      "Minibatch train and validation accuracy: 100.000%, 95.963%\n",
      "Time interval: 669.8505 seconds, estimated run time for 200 epochs: 42.1093 hours\n",
      "[ 0.94233495  0.88058484  0.84213471  0.95829284  0.95380849  0.9399851\n",
      "  0.95185584  0.9674753   0.95064497  0.98824072  0.98880827  0.9815675\n",
      "  0.98618388  0.97881949  0.99725157  0.9859497   0.80548882  0.99899906\n",
      "  0.9897725   0.97298563  0.93660802  0.89335096  0.99725157  0.97739512\n",
      "  0.96759206  0.97345078  0.98477614  0.99649429  0.9818266   0.9940294\n",
      "  0.98739761  0.94543672  0.95004708  0.99399358  0.98649275  0.97854453\n",
      "  0.97178936  0.99624103  0.96581805  0.99725014  0.92812777  0.76618493\n",
      "  0.99774671]\n",
      "Minibatch loss at epoch 139 and iter 187649: 0.000000 and the learning rate: 0.039721\n",
      "Minibatch train and validation accuracy: 100.000%, 95.616%\n",
      "Time interval: 671.8725 seconds, estimated run time for 200 epochs: 42.0749 hours\n",
      "[ 0.94547153  0.87643337  0.82818323  0.9417311   0.96009743  0.94000441\n",
      "  0.965316    0.97028691  0.9482798   0.98673296  0.99177212  0.9793911\n",
      "  0.98595035  0.97302759  0.99749953  0.96548343  0.76624531  0.9994998\n",
      "  0.98830509  0.96825737  0.9354834   0.89363956  0.99724883  0.97932011\n",
      "  0.96741033  0.97338355  0.98456895  0.99649251  0.97847307  0.99206305\n",
      "  0.98715371  0.94301951  0.92521375  0.99399948  0.98599952  0.97859728\n",
      "  0.97226232  0.99674219  0.96689707  0.99725294  0.91629446  0.73459017\n",
      "  0.99774671]\n",
      "Minibatch loss at epoch 140 and iter 188999: 0.000067 and the learning rate: 0.039721\n",
      "Minibatch train and validation accuracy: 100.000%, 96.028%\n",
      "Time interval: 669.2684 seconds, estimated run time for 200 epochs: 42.0399 hours\n",
      "[ 0.94272029  0.8785879   0.83695608  0.95281172  0.96037138  0.94415951\n",
      "  0.9417609   0.97194386  0.95967698  0.9882583   0.99028593  0.97988176\n",
      "  0.98619771  0.97672015  0.99749953  0.97796232  0.81759101  0.99899858\n",
      "  0.99051851  0.9708733   0.93533868  0.90426344  0.99725026  0.97432083\n",
      "  0.96843678  0.97367048  0.98526794  0.99749827  0.97845203  0.99378836\n",
      "  0.98618597  0.95087421  0.95372087  0.99300653  0.98954654  0.98435509\n",
      "  0.97413325  0.99674219  0.96638393  0.99600947  0.93181771  0.76391149\n",
      "  0.99749446]\n",
      "Minibatch loss at epoch 141 and iter 190349: 0.000000 and the learning rate: 0.037735\n",
      "Minibatch train and validation accuracy: 100.000%, 95.971%\n",
      "Time interval: 671.1253 seconds, estimated run time for 200 epochs: 42.0062 hours\n",
      "[ 0.94263226  0.88205886  0.83510131  0.95372093  0.96097511  0.94644123\n",
      "  0.94017452  0.97528702  0.95878595  0.98825246  0.991768    0.97963142\n",
      "  0.98643166  0.97563404  0.99750084  0.97608542  0.81619346  0.9992497\n",
      "  0.98976743  0.97251225  0.93435222  0.908701    0.99750328  0.97384459\n",
      "  0.96924603  0.9741506   0.98505932  0.99724609  0.97751659  0.9932881\n",
      "  0.98764777  0.95375675  0.93739694  0.9940055   0.98880827  0.98363054\n",
      "  0.97298563  0.99648899  0.96581811  0.9960115   0.93576515  0.74138296\n",
      "  0.99724054]\n",
      "Minibatch loss at epoch 142 and iter 191699: 0.000000 and the learning rate: 0.037735\n",
      "Minibatch train and validation accuracy: 100.000%, 96.069%\n",
      "Time interval: 670.2891 seconds, estimated run time for 200 epochs: 41.9726 hours\n",
      "[ 0.94787133  0.88894731  0.82812005  0.94741786  0.96461874  0.93777084\n",
      "  0.93903548  0.96700585  0.94834453  0.98751825  0.99002445  0.9801417\n",
      "  0.98823482  0.97849691  0.99749953  0.98375934  0.82845384  0.99900001\n",
      "  0.98955178  0.97632366  0.93565351  0.91215807  0.99749947  0.97453427\n",
      "  0.96076852  0.97284907  0.98651969  0.99623734  0.9755854   0.99601144\n",
      "  0.98594284  0.95286143  0.96337306  0.99152917  0.9880414   0.98207128\n",
      "  0.96919668  0.99674219  0.96319133  0.9957633   0.93538409  0.77775103\n",
      "  0.99724746]\n",
      "Minibatch loss at epoch 143 and iter 193049: 0.000001 and the learning rate: 0.037735\n",
      "Minibatch train and validation accuracy: 100.000%, 95.951%\n",
      "Time interval: 671.5318 seconds, estimated run time for 200 epochs: 41.9400 hours\n",
      "[ 0.94812286  0.88486707  0.81852561  0.93937922  0.96403897  0.9378472\n",
      "  0.94910347  0.96349967  0.93956     0.98874104  0.99373853  0.982059\n",
      "  0.98670632  0.9736169   0.99749953  0.97085917  0.82708043  0.998999\n",
      "  0.98831081  0.97846252  0.93488574  0.91691107  0.9977501   0.98269856\n",
      "  0.96035194  0.97390383  0.98753071  0.99648899  0.97298563  0.99427956\n",
      "  0.9869228   0.95382351  0.94759256  0.99152076  0.98802346  0.98147643\n",
      "  0.97037351  0.99674219  0.96338272  0.9955129   0.92827612  0.77175421\n",
      "  0.99774784]\n",
      "Minibatch loss at epoch 144 and iter 194399: 0.000003 and the learning rate: 0.037735\n",
      "Minibatch train and validation accuracy: 100.000%, 96.050%\n",
      "Time interval: 669.3004 seconds, estimated run time for 200 epochs: 41.9070 hours\n",
      "[ 0.94984353  0.88678205  0.82069117  0.94247943  0.96137714  0.93805695\n",
      "  0.95622849  0.97075975  0.9467392   0.98802948  0.99272943  0.98303366\n",
      "  0.9876973   0.97596717  0.99774897  0.9741711   0.82546157  0.99899948\n",
      "  0.98805922  0.97655052  0.93875349  0.91216707  0.99750072  0.97907907\n",
      "  0.96161777  0.97517687  0.98260391  0.99547464  0.97798383  0.99527198\n",
      "  0.9869163   0.95039493  0.94849223  0.99350929  0.9865399   0.98196149\n",
      "  0.97273564  0.99649251  0.96315336  0.99650472  0.93503791  0.77861476\n",
      "  0.99799955]\n",
      "Minibatch loss at epoch 145 and iter 195749: 0.000000 and the learning rate: 0.037735\n",
      "Minibatch train and validation accuracy: 100.000%, 96.077%\n",
      "Time interval: 671.0772 seconds, estimated run time for 200 epochs: 41.8751 hours\n",
      "[ 0.94777143  0.88235241  0.83309346  0.95575172  0.96126628  0.94474024\n",
      "  0.94156563  0.97790819  0.95597118  0.9882583   0.992989    0.97772294\n",
      "  0.98821121  0.97593063  0.99774784  0.97085917  0.82943881  0.99900001\n",
      "  0.98707062  0.97537136  0.93794513  0.91283375  0.99700552  0.98101062\n",
      "  0.96537423  0.97446227  0.9809165   0.99522924  0.97965139  0.99626166\n",
      "  0.98960346  0.95057535  0.94829172  0.99399656  0.98680556  0.98341125\n",
      "  0.97320944  0.99624288  0.96443248  0.9965083   0.93142229  0.76272762\n",
      "  0.99749827]\n",
      "Minibatch loss at epoch 146 and iter 197099: 0.000003 and the learning rate: 0.037735\n",
      "Minibatch train and validation accuracy: 100.000%, 96.158%\n",
      "Time interval: 669.4280 seconds, estimated run time for 200 epochs: 41.8430 hours\n",
      "[ 0.94597793  0.88304204  0.83543533  0.95825291  0.9581008   0.9449271\n",
      "  0.96154732  0.97406995  0.95063561  0.9882701   0.99323434  0.97724444\n",
      "  0.98846501  0.97591835  0.9977501   0.97130305  0.8409481   0.99900001\n",
      "  0.98632807  0.97322249  0.93857056  0.91364557  0.99725437  0.98102003\n",
      "  0.96242499  0.97287661  0.98043054  0.99423659  0.98013198  0.99651176\n",
      "  0.99157113  0.95283878  0.94473267  0.99325794  0.98656005  0.98145807\n",
      "  0.97369647  0.99674219  0.96342039  0.99675518  0.92816782  0.787705\n",
      "  0.99824727]\n",
      "Minibatch loss at epoch 147 and iter 198449: 0.000000 and the learning rate: 0.037735\n",
      "Minibatch train and validation accuracy: 100.000%, 96.123%\n",
      "Time interval: 669.7667 seconds, estimated run time for 200 epochs: 41.8115 hours\n",
      "[ 0.94474959  0.8783285   0.82363117  0.95045215  0.95759583  0.9356916\n",
      "  0.95807177  0.9807117   0.95789427  0.98801142  0.99323422  0.97725552\n",
      "  0.98746818  0.97516429  0.9977501   0.97134483  0.84984165  0.99900001\n",
      "  0.98708344  0.9736709   0.93888253  0.91606283  0.99750197  0.98268992\n",
      "  0.96321201  0.97520196  0.98236853  0.99574208  0.9794113   0.99650997\n",
      "  0.99181706  0.95249474  0.93796945  0.99400252  0.98802948  0.98337007\n",
      "  0.97108096  0.99724334  0.96368742  0.99625802  0.92903179  0.7828815\n",
      "  0.99699354]\n",
      "Minibatch loss at epoch 148 and iter 199799: 0.000000 and the learning rate: 0.037735\n",
      "Minibatch train and validation accuracy: 100.000%, 96.258%\n",
      "Time interval: 669.6656 seconds, estimated run time for 200 epochs: 41.7803 hours\n",
      "[ 0.9405067   0.88356119  0.83500093  0.96130687  0.95984375  0.94335938\n",
      "  0.9776023   0.97101051  0.95556635  0.98802346  0.99372911  0.98251617\n",
      "  0.98719507  0.97381091  0.99799854  0.97393376  0.85998815  0.99900001\n",
      "  0.98832244  0.97228926  0.93981552  0.91283375  0.99750328  0.9831928\n",
      "  0.97148681  0.97595495  0.98701251  0.99724746  0.97394645  0.99601346\n",
      "  0.99131685  0.95023876  0.92396533  0.99374795  0.9880175   0.98289919\n",
      "  0.96941704  0.9967438   0.9636687   0.99600947  0.93687654  0.79573494\n",
      "  0.99446356]\n",
      "Minibatch loss at epoch 149 and iter 201149: 0.000039 and the learning rate: 0.035849\n",
      "Minibatch train and validation accuracy: 100.000%, 96.340%\n",
      "Time interval: 670.7888 seconds, estimated run time for 200 epochs: 41.7500 hours\n",
      "[ 0.94226605  0.8844533   0.8391484   0.96428519  0.96254539  0.94219613\n",
      "  0.97785383  0.97098219  0.95576972  0.98655999  0.99347669  0.98159462\n",
      "  0.98545593  0.9741506   0.99775118  0.97725552  0.85706085  0.9992497\n",
      "  0.98806512  0.97251225  0.94126856  0.91078514  0.99750197  0.98222172\n",
      "  0.96850759  0.97489172  0.98527533  0.99699801  0.97653913  0.99651176\n",
      "  0.99206305  0.94950891  0.94156414  0.99424809  0.98751825  0.98315114\n",
      "  0.96988779  0.99699199  0.96284777  0.99650651  0.93189919  0.81433952\n",
      "  0.99522686]\n",
      "Minibatch loss at epoch 150 and iter 202499: 0.000025 and the learning rate: 0.035849\n",
      "Minibatch train and validation accuracy: 100.000%, 96.716%\n",
      "Time interval: 669.6676 seconds, estimated run time for 200 epochs: 41.7197 hours\n",
      "[ 0.95187891  0.89491838  0.83989751  0.96265912  0.96664149  0.94069386\n",
      "  0.97162378  0.964899    0.95180982  0.98899406  0.99249578  0.98013192\n",
      "  0.98870152  0.97960168  0.99749827  0.98910302  0.92037743  0.99900001\n",
      "  0.99225146  0.98087251  0.93561959  0.91927379  0.99849951  0.97454673\n",
      "  0.96294332  0.97332948  0.98625296  0.99724883  0.97847307  0.99675685\n",
      "  0.98714733  0.95725626  0.95145124  0.99374795  0.98681217  0.98388249\n",
      "  0.96800727  0.99624485  0.96332341  0.99675518  0.9438706   0.85792708\n",
      "  0.99875051]\n",
      "Minibatch loss at epoch 151 and iter 203849: 0.000000 and the learning rate: 0.035849\n",
      "Minibatch train and validation accuracy: 100.000%, 96.239%\n",
      "Time interval: 670.8878 seconds, estimated run time for 200 epochs: 41.6903 hours\n",
      "[ 0.93493587  0.87298989  0.8475998   0.96543342  0.96001905  0.94498968\n",
      "  0.97216749  0.97934043  0.95514065  0.98585212  0.99299252  0.97726667\n",
      "  0.98539734  0.97631001  0.99750078  0.97727782  0.84942484  0.99775463\n",
      "  0.98780131  0.97059488  0.94563466  0.90365577  0.99675357  0.96391338\n",
      "  0.95317769  0.97064728  0.96983021  0.99399048  0.98984349  0.99825084\n",
      "  0.99205905  0.95723951  0.95032036  0.99299252  0.98574603  0.98411077\n",
      "  0.97393376  0.99674219  0.96300054  0.99725294  0.93525499  0.81140929\n",
      "  0.99699652]\n",
      "Minibatch loss at epoch 152 and iter 205199: 0.000005 and the learning rate: 0.035849\n",
      "Minibatch train and validation accuracy: 100.000%, 96.211%\n",
      "Time interval: 671.6358 seconds, estimated run time for 200 epochs: 41.6615 hours\n",
      "[ 0.94137222  0.88034147  0.84740943  0.96428525  0.95747226  0.94200391\n",
      "  0.95838302  0.97380614  0.95456791  0.98705125  0.99299604  0.98134464\n",
      "  0.98439026  0.97648501  0.99750197  0.97508502  0.8405205   0.99825168\n",
      "  0.98754936  0.97347236  0.94865727  0.90913898  0.99725294  0.98052698\n",
      "  0.9637301   0.97280765  0.97726095  0.99524355  0.9869228   0.9970085\n",
      "  0.98838025  0.94951868  0.94023484  0.99425381  0.98596442  0.98261255\n",
      "  0.97749466  0.99699354  0.96370101  0.99750197  0.94598639  0.77740335\n",
      "  0.99749702]\n",
      "Minibatch loss at epoch 153 and iter 206549: 0.000000 and the learning rate: 0.035849\n",
      "Minibatch train and validation accuracy: 100.000%, 96.172%\n",
      "Time interval: 670.9063 seconds, estimated run time for 200 epochs: 41.6328 hours\n",
      "[ 0.94910353  0.88865215  0.83986318  0.96101969  0.96347094  0.9377709\n",
      "  0.94477314  0.96843076  0.95153916  0.98751825  0.99199152  0.98111308\n",
      "  0.98514932  0.97878742  0.99749947  0.98039168  0.84851921  0.998501\n",
      "  0.98879153  0.97489589  0.94579685  0.91451353  0.99700254  0.97926903\n",
      "  0.96750855  0.97379756  0.98018771  0.99549502  0.98400939  0.99600953\n",
      "  0.98618597  0.95582861  0.9319343   0.99251074  0.98728454  0.9831177\n",
      "  0.97844148  0.99674386  0.96139944  0.99700403  0.94909227  0.75228858\n",
      "  0.99775225]\n",
      "Minibatch loss at epoch 154 and iter 207899: 0.000000 and the learning rate: 0.035849\n",
      "Minibatch train and validation accuracy: 100.000%, 96.077%\n",
      "Time interval: 671.1702 seconds, estimated run time for 200 epochs: 41.6046 hours\n",
      "[ 0.95048028  0.8905955   0.82535976  0.95165473  0.96099412  0.93250012\n",
      "  0.95288152  0.97478533  0.95235646  0.98634166  0.99122095  0.98326725\n",
      "  0.9851343   0.97877675  0.99725157  0.97821254  0.82501417  0.998999\n",
      "  0.98123413  0.97180307  0.94923151  0.90874583  0.99700552  0.97783202\n",
      "  0.95810521  0.97564644  0.97321165  0.99090862  0.98546392  0.99725705\n",
      "  0.99255538  0.94974709  0.94095463  0.99301004  0.98775876  0.98211569\n",
      "  0.97846258  0.99724472  0.96090484  0.99625605  0.95257068  0.76659483\n",
      "  0.99724746]\n",
      "Minibatch loss at epoch 155 and iter 209249: 0.000010 and the learning rate: 0.035849\n",
      "Minibatch train and validation accuracy: 100.000%, 96.147%\n",
      "Time interval: 669.4236 seconds, estimated run time for 200 epochs: 41.5761 hours\n",
      "[ 0.95039493  0.89106768  0.82434338  0.95739537  0.96428525  0.92957699\n",
      "  0.91856933  0.97056633  0.9509182   0.98780131  0.99248451  0.98039168\n",
      "  0.98587948  0.9782933   0.99774897  0.98255903  0.85950369  0.9987511\n",
      "  0.98781961  0.97606206  0.94843698  0.92471921  0.99750197  0.98026586\n",
      "  0.96236652  0.97386402  0.97800791  0.99524117  0.98472857  0.9967584\n",
      "  0.99009848  0.95844424  0.9447065   0.99275857  0.98752445  0.9823246\n",
      "  0.97725552  0.99699509  0.96115208  0.9955129   0.95185506  0.74628329\n",
      "  0.99649423]\n",
      "Minibatch loss at epoch 156 and iter 210599: 0.000000 and the learning rate: 0.034056\n",
      "Minibatch train and validation accuracy: 100.000%, 95.801%\n",
      "Time interval: 670.8720 seconds, estimated run time for 200 epochs: 41.5485 hours\n",
      "[ 0.95664978  0.89693111  0.82695031  0.95550191  0.95311695  0.93170917\n",
      "  0.96394825  0.96910679  0.94632363  0.9872908   0.99324107  0.98037243\n",
      "  0.98466128  0.97729522  0.99725157  0.97274894  0.76785666  0.998999\n",
      "  0.9836629   0.97059494  0.94692761  0.91709101  0.99725294  0.98242968\n",
      "  0.96157789  0.97309601  0.97538114  0.99346024  0.98473608  0.9970085\n",
      "  0.99058896  0.95389766  0.90760452  0.99349636  0.9877587   0.98238599\n",
      "  0.97795159  0.99699354  0.96533966  0.99600947  0.95173407  0.71355093\n",
      "  0.99572927]\n",
      "Minibatch loss at epoch 157 and iter 211949: 0.000000 and the learning rate: 0.034056\n",
      "Minibatch train and validation accuracy: 100.000%, 95.913%\n",
      "Time interval: 671.1019 seconds, estimated run time for 200 epochs: 41.5213 hours\n",
      "[ 0.95356745  0.89522249  0.82505727  0.95461011  0.95496321  0.93326908\n",
      "  0.96695769  0.96742779  0.94710147  0.9875555   0.99273318  0.98135382\n",
      "  0.9856599   0.97726071  0.99725157  0.97464603  0.79264569  0.99924898\n",
      "  0.98535573  0.96849203  0.94560617  0.91726857  0.99750197  0.98292458\n",
      "  0.96292406  0.97205234  0.97607839  0.99523169  0.98424375  0.99650997\n",
      "  0.98887461  0.9559744   0.91261643  0.99301004  0.98800552  0.98187184\n",
      "  0.97724444  0.99699509  0.96541071  0.9957611   0.95151466  0.73254669\n",
      "  0.99573356]\n",
      "Minibatch loss at epoch 158 and iter 213299: 0.000000 and the learning rate: 0.034056\n",
      "Minibatch train and validation accuracy: 100.000%, 95.944%\n",
      "Time interval: 669.7838 seconds, estimated run time for 200 epochs: 41.4940 hours\n",
      "[ 0.95182717  0.89409858  0.8340956   0.95986485  0.95863694  0.93772495\n",
      "  0.96789837  0.96982926  0.95194465  0.98779535  0.99248457  0.98039168\n",
      "  0.98517168  0.97594279  0.99725157  0.97774476  0.78813511  0.99949926\n",
      "  0.98707062  0.96827275  0.94272155  0.91983968  0.99750197  0.98411858\n",
      "  0.96908754  0.9725883   0.97798622  0.99549502  0.98158556  0.99551517\n",
      "  0.98911381  0.9576574   0.90566844  0.9939965   0.98699301  0.98216891\n",
      "  0.97748363  0.99674058  0.96440417  0.99526727  0.95067894  0.72244555\n",
      "  0.99598551]\n",
      "Minibatch loss at epoch 159 and iter 214649: 0.000001 and the learning rate: 0.034056\n",
      "Minibatch train and validation accuracy: 100.000%, 95.739%\n",
      "Time interval: 670.8841 seconds, estimated run time for 200 epochs: 41.4675 hours\n",
      "[ 0.95883727  0.89420283  0.83727509  0.96103847  0.96661705  0.93840182\n",
      "  0.94809479  0.9633022   0.94993597  0.98896641  0.99351895  0.96944666\n",
      "  0.98511928  0.97751909  0.99700403  0.97846252  0.74702525  0.99924934\n",
      "  0.9877587   0.97726667  0.93950504  0.93133336  0.99800152  0.98682529\n",
      "  0.96794003  0.97122437  0.98017794  0.99574208  0.9794113   0.99501699\n",
      "  0.98741001  0.96190196  0.90063184  0.99151224  0.98697352  0.98068303\n",
      "  0.97893137  0.99674386  0.9640283   0.9957611   0.94563794  0.67366868\n",
      "  0.99573779]\n",
      "Minibatch loss at epoch 160 and iter 215999: 0.000001 and the learning rate: 0.034056\n",
      "Minibatch train and validation accuracy: 100.000%, 95.780%\n",
      "Time interval: 670.9985 seconds, estimated run time for 200 epochs: 41.4413 hours\n",
      "[ 0.95178658  0.88813686  0.83480704  0.956438    0.96707565  0.94223255\n",
      "  0.95627058  0.9667713   0.95141649  0.99025202  0.99373543  0.97134483\n",
      "  0.9859221   0.9777323   0.99700099  0.9794113   0.76237577  0.99900001\n",
      "  0.98703843  0.9758119   0.93913001  0.93119705  0.99799955  0.98558599\n",
      "  0.96764201  0.97152972  0.97872293  0.99499452  0.9779731   0.99403536\n",
      "  0.98862463  0.96348536  0.89948237  0.99077034  0.98849374  0.98088807\n",
      "  0.97607368  0.99699354  0.96349567  0.9957611   0.94105637  0.68902683\n",
      "  0.99623352]\n",
      "Minibatch loss at epoch 161 and iter 217349: 0.000000 and the learning rate: 0.034056\n",
      "Minibatch train and validation accuracy: 100.000%, 95.860%\n",
      "Time interval: 671.3467 seconds, estimated run time for 200 epochs: 41.4156 hours\n",
      "[ 0.94993961  0.88917881  0.83071607  0.95326608  0.96877259  0.93849832\n",
      "  0.96013486  0.96606833  0.94814014  0.98876357  0.99225152  0.97108096\n",
      "  0.98689473  0.97953981  0.99725294  0.98207664  0.75497466  0.99900055\n",
      "  0.98974699  0.97725552  0.93817371  0.9299258   0.99750328  0.98074973\n",
      "  0.96198559  0.97073001  0.98043054  0.99524117  0.97821254  0.99502188\n",
      "  0.98789179  0.96433765  0.92353839  0.99127352  0.98899949  0.9818809\n",
      "  0.97512144  0.99724472  0.96113211  0.99600947  0.93878537  0.7244705\n",
      "  0.99749327]\n",
      "Minibatch loss at epoch 162 and iter 218699: 0.000014 and the learning rate: 0.034056\n",
      "Minibatch train and validation accuracy: 100.000%, 95.870%\n",
      "Time interval: 670.2157 seconds, estimated run time for 200 epochs: 41.3897 hours\n",
      "[ 0.94644082  0.89087516  0.82930988  0.95349348  0.96750319  0.94006258\n",
      "  0.9450388   0.97482234  0.95373088  0.98925757  0.99224371  0.97535932\n",
      "  0.98636311  0.97801322  0.99725294  0.98350924  0.78530169  0.99900001\n",
      "  0.98925763  0.97846258  0.93879646  0.93055141  0.99775225  0.98293298\n",
      "  0.96464461  0.97305495  0.98285669  0.9962467   0.97653913  0.99477178\n",
      "  0.98936385  0.96445912  0.90739852  0.99002445  0.98851103  0.98142135\n",
      "  0.97510934  0.99699354  0.961092    0.99501944  0.94623065  0.69647586\n",
      "  0.99699193]\n",
      "Minibatch loss at epoch 163 and iter 220049: 0.000001 and the learning rate: 0.032353\n",
      "Minibatch train and validation accuracy: 100.000%, 96.192%\n",
      "Time interval: 670.4695 seconds, estimated run time for 200 epochs: 41.3643 hours\n",
      "[ 0.94481403  0.89088458  0.83012319  0.95206243  0.9652276   0.93812132\n",
      "  0.9462412   0.97408265  0.95040667  0.98728448  0.98999453  0.98038208\n",
      "  0.9864043   0.97770977  0.99750197  0.9859497   0.81936198  0.99825084\n",
      "  0.99199951  0.97749466  0.93972695  0.92722893  0.99749953  0.97593272\n",
      "  0.96004105  0.9741767   0.98285669  0.9962467   0.97967136  0.9955197\n",
      "  0.98887461  0.96581984  0.95009452  0.99201548  0.98876357  0.98333699\n",
      "  0.9758355   0.99724472  0.96220058  0.99526489  0.95043987  0.76933914\n",
      "  0.99674058]\n",
      "Minibatch loss at epoch 164 and iter 221399: 0.000010 and the learning rate: 0.032353\n",
      "Minibatch train and validation accuracy: 100.000%, 96.191%\n",
      "Time interval: 669.6238 seconds, estimated run time for 200 epochs: 41.3390 hours\n",
      "[ 0.94644082  0.8878352   0.8374995   0.95351565  0.96817124  0.93754512\n",
      "  0.96617138  0.97146988  0.95025927  0.9882701   0.99174327  0.98472112\n",
      "  0.98590082  0.97696739  0.99750197  0.98303366  0.80868745  0.99900055\n",
      "  0.99000949  0.97822315  0.93944132  0.92511904  0.99775118  0.97929972\n",
      "  0.96229291  0.97429389  0.9855212   0.99674541  0.97821254  0.99427956\n",
      "  0.98886913  0.96102589  0.94264764  0.99078864  0.98798752  0.98237723\n",
      "  0.97273564  0.99749202  0.95952517  0.9957611   0.94036996  0.77795738\n",
      "  0.99699056]\n",
      "Minibatch loss at epoch 165 and iter 222749: 0.000000 and the learning rate: 0.032353\n",
      "Minibatch train and validation accuracy: 100.000%, 96.235%\n",
      "Time interval: 670.8860 seconds, estimated run time for 200 epochs: 41.3143 hours\n",
      "[ 0.94611299  0.89094716  0.84013557  0.95806324  0.96728122  0.93980533\n",
      "  0.96265709  0.96935749  0.94998711  0.98828173  0.99175572  0.98158556\n",
      "  0.98665947  0.97722626  0.99749827  0.98375136  0.81351864  0.99900001\n",
      "  0.9897725   0.97749466  0.93940943  0.92588615  0.99775118  0.97905838\n",
      "  0.96357477  0.97400904  0.98554289  0.99674869  0.97918153  0.9952696\n",
      "  0.98984849  0.96073633  0.9451791   0.99128222  0.98798752  0.98236853\n",
      "  0.97294617  0.99724334  0.9601025   0.99551523  0.94281334  0.77896655\n",
      "  0.99749202]\n",
      "Minibatch loss at epoch 166 and iter 224099: 0.000000 and the learning rate: 0.032353\n",
      "Minibatch train and validation accuracy: 100.000%, 96.229%\n",
      "Time interval: 671.6381 seconds, estimated run time for 200 epochs: 41.2902 hours\n",
      "[ 0.94603586  0.88982779  0.83732831  0.95873278  0.96448642  0.94017869\n",
      "  0.96477973  0.9698292   0.95301962  0.98753071  0.99124736  0.9837513\n",
      "  0.98614907  0.97747356  0.99750078  0.9823091   0.80821878  0.99900055\n",
      "  0.98902696  0.97653908  0.93975222  0.9258076   0.99775118  0.98026592\n",
      "  0.96498406  0.97347766  0.98554289  0.99649602  0.97919172  0.99502188\n",
      "  0.98789775  0.96168721  0.94250655  0.99152076  0.98898298  0.9835816\n",
      "  0.97822315  0.99724197  0.96385491  0.9955129   0.94191873  0.77380347\n",
      "  0.99799252]\n",
      "Minibatch loss at epoch 167 and iter 225449: 0.000000 and the learning rate: 0.032353\n",
      "Minibatch train and validation accuracy: 100.000%, 96.189%\n",
      "Time interval: 670.5795 seconds, estimated run time for 200 epochs: 41.2660 hours\n",
      "[ 0.94207346  0.88870966  0.85026544  0.96800727  0.96173483  0.94180626\n",
      "  0.97536898  0.97195756  0.95604348  0.98774648  0.99126482  0.98133552\n",
      "  0.98538262  0.97536141  0.9977501   0.97943145  0.81198049  0.99874985\n",
      "  0.98805332  0.983962    0.93761468  0.93025649  0.99775237  0.97355485\n",
      "  0.97028643  0.9730134   0.98456126  0.99599558  0.98061299  0.99551302\n",
      "  0.98716635  0.96868837  0.91819811  0.99126482  0.98749322  0.98003405\n",
      "  0.96966702  0.99699199  0.96135962  0.99477166  0.94648689  0.75532377\n",
      "  0.99824554]\n",
      "Minibatch loss at epoch 168 and iter 226799: 0.000000 and the learning rate: 0.032353\n",
      "Minibatch train and validation accuracy: 100.000%, 96.194%\n",
      "Time interval: 670.7190 seconds, estimated run time for 200 epochs: 41.2422 hours\n",
      "[ 0.93579674  0.88643056  0.8541432   0.9736709   0.95939654  0.94201422\n",
      "  0.98336178  0.98126185  0.9620564   0.98700607  0.99126041  0.97967136\n",
      "  0.98490143  0.97485346  0.99775118  0.98039168  0.80274916  0.99850029\n",
      "  0.98630774  0.98203254  0.93624818  0.93019563  0.99825174  0.97239143\n",
      "  0.96916705  0.97197634  0.9835816   0.99450231  0.97990149  0.9955197\n",
      "  0.99033409  0.96908689  0.9182356   0.99300653  0.98675287  0.97980249\n",
      "  0.96523362  0.99724334  0.9586131   0.99600947  0.9477663   0.75963509\n",
      "  0.998748  ]\n",
      "Minibatch loss at epoch 169 and iter 228149: 0.000000 and the learning rate: 0.032353\n",
      "Minibatch train and validation accuracy: 100.000%, 96.030%\n",
      "Time interval: 669.6769 seconds, estimated run time for 200 epochs: 41.2183 hours\n",
      "[ 0.93646228  0.88470668  0.84394318  0.97106689  0.96126634  0.94057679\n",
      "  0.98092598  0.97815913  0.95973784  0.98878592  0.99298894  0.98158556\n",
      "  0.98567432  0.97356331  0.99774897  0.97917128  0.77990824  0.99899948\n",
      "  0.98780131  0.97252566  0.94086683  0.90953231  0.99800152  0.97950065\n",
      "  0.96915114  0.97526455  0.98384243  0.99550182  0.97918153  0.99527198\n",
      "  0.99378526  0.95194566  0.91651326  0.99201947  0.98649275  0.9807688\n",
      "  0.96919668  0.99724048  0.95782614  0.9957611   0.94893032  0.74890631\n",
      "  0.99874735]\n",
      "Minibatch loss at epoch 170 and iter 229499: 0.000000 and the learning rate: 0.032353\n",
      "Minibatch train and validation accuracy: 100.000%, 96.198%\n",
      "Time interval: 672.7427 seconds, estimated run time for 200 epochs: 41.1957 hours\n",
      "[ 0.94468242  0.88577425  0.84587157  0.9696523   0.96173483  0.94038093\n",
      "  0.98122483  0.9771663   0.9592756   0.98773414  0.99224371  0.97966141\n",
      "  0.98744929  0.97686195  0.99775118  0.97823381  0.78321624  0.99900001\n",
      "  0.98828179  0.97632366  0.93932182  0.92760491  0.99725437  0.9836548\n",
      "  0.96757537  0.97452664  0.98213351  0.99475086  0.98015141  0.99576324\n",
      "  0.99279815  0.96139795  0.91270518  0.9932546   0.9915334   0.98511857\n",
      "  0.98302531  0.99724329  0.97254652  0.99675685  0.95108372  0.74063683\n",
      "  0.99949926]\n",
      "Minibatch loss at epoch 171 and iter 230849: 0.000002 and the learning rate: 0.030736\n",
      "Minibatch train and validation accuracy: 100.000%, 96.173%\n",
      "Time interval: 670.4112 seconds, estimated run time for 200 epochs: 41.1726 hours\n",
      "[ 0.94190425  0.88411516  0.84355605  0.97198492  0.95747221  0.93961304\n",
      "  0.96596938  0.97858679  0.96019977  0.98677266  0.99248827  0.9779731\n",
      "  0.98770958  0.97794628  0.99749947  0.98135382  0.80119711  0.99874985\n",
      "  0.98753691  0.97274888  0.94018847  0.92250288  0.99825084  0.98242098\n",
      "  0.96542776  0.97473425  0.98137522  0.99425668  0.9818266   0.99601543\n",
      "  0.99255162  0.9590497   0.91886872  0.99400252  0.9915418   0.98511118\n",
      "  0.98398572  0.99724054  0.97174805  0.99700403  0.95020074  0.73926407\n",
      "  0.99899858]\n",
      "Minibatch loss at epoch 172 and iter 232199: 0.000000 and the learning rate: 0.030736\n",
      "Minibatch train and validation accuracy: 100.000%, 96.071%\n",
      "Time interval: 670.3596 seconds, estimated run time for 200 epochs: 41.1497 hours\n",
      "[ 0.93835896  0.88120335  0.83982885  0.97083086  0.9584443   0.94246125\n",
      "  0.9552449   0.97693771  0.96055871  0.98653316  0.99200344  0.97965139\n",
      "  0.98795742  0.9771685   0.99749947  0.98134464  0.80537266  0.99874985\n",
      "  0.98828173  0.97248554  0.93994188  0.9208551   0.9980005   0.98099184\n",
      "  0.96546346  0.974747    0.98213351  0.99500698  0.98062247  0.99601543\n",
      "  0.99327809  0.9594754   0.91403705  0.9932512   0.98925221  0.98194361\n",
      "  0.98351735  0.99724054  0.97074485  0.99626166  0.94933146  0.72499353\n",
      "  0.99724329]\n",
      "Minibatch loss at epoch 173 and iter 233549: 0.000000 and the learning rate: 0.030736\n",
      "Minibatch train and validation accuracy: 100.000%, 96.144%\n",
      "Time interval: 671.2191 seconds, estimated run time for 200 epochs: 41.1274 hours\n",
      "[ 0.94991487  0.89513749  0.84240317  0.97483456  0.95574325  0.9335559\n",
      "  0.92731899  0.97031581  0.95654297  0.98845333  0.992522    0.97870207\n",
      "  0.98693424  0.97622609  0.99750197  0.98570681  0.82982409  0.99899948\n",
      "  0.98753697  0.98642266  0.93932188  0.93089712  0.99800056  0.9843784\n",
      "  0.96583563  0.97373694  0.98114091  0.99549729  0.98015141  0.99527198\n",
      "  0.9910754   0.95906949  0.9262861   0.99276215  0.98899406  0.98167366\n",
      "  0.98400146  0.99698895  0.96852744  0.99650824  0.95240444  0.71156693\n",
      "  0.9982447 ]\n",
      "Minibatch loss at epoch 174 and iter 234899: 0.000000 and the learning rate: 0.030736\n",
      "Minibatch train and validation accuracy: 100.000%, 96.213%\n",
      "Time interval: 669.6383 seconds, estimated run time for 200 epochs: 41.1049 hours\n",
      "[ 0.94802654  0.89490229  0.84541285  0.97202581  0.9569003   0.93743938\n",
      "  0.94304645  0.97172064  0.95837456  0.98772186  0.99225146  0.97749466\n",
      "  0.98694074  0.97669661  0.99750197  0.98351735  0.82918209  0.99900055\n",
      "  0.98703843  0.98422825  0.93802476  0.93076062  0.99775118  0.98414224\n",
      "  0.9678576   0.97425491  0.98042083  0.99500203  0.97967136  0.99477696\n",
      "  0.99180895  0.960446    0.92400044  0.99325454  0.98897743  0.98193473\n",
      "  0.98326725  0.99724197  0.96975809  0.9965083   0.95066988  0.73116648\n",
      "  0.9979955 ]\n",
      "Minibatch loss at epoch 175 and iter 236249: 0.000000 and the learning rate: 0.030736\n",
      "Minibatch train and validation accuracy: 100.000%, 96.317%\n",
      "Time interval: 671.6129 seconds, estimated run time for 200 epochs: 41.0832 hours\n",
      "[ 0.94947016  0.89597005  0.84550041  0.97130299  0.95784837  0.93761951\n",
      "  0.92843729  0.97218108  0.95673871  0.98971087  0.99201548  0.9758355\n",
      "  0.98643851  0.97796863  0.99675518  0.98789775  0.88236892  0.9987511\n",
      "  0.98652643  0.98495638  0.93707347  0.93291193  0.99824822  0.98436284\n",
      "  0.96254152  0.97324538  0.97899634  0.99376667  0.97894174  0.99476653\n",
      "  0.98959321  0.96134162  0.92872024  0.99300653  0.98899406  0.98284817\n",
      "  0.97630048  0.99724197  0.96831387  0.99625802  0.94964343  0.74276733\n",
      "  0.99874866]\n",
      "Minibatch loss at epoch 176 and iter 237599: 0.000732 and the learning rate: 0.030736\n",
      "Minibatch train and validation accuracy: 100.000%, 96.289%\n",
      "Time interval: 670.8192 seconds, estimated run time for 200 epochs: 41.0615 hours\n",
      "[ 0.94734275  0.89542782  0.84771526  0.97034472  0.96038836  0.9422282\n",
      "  0.95021498  0.97218108  0.95855266  0.98924148  0.99251449  0.98062247\n",
      "  0.98491663  0.97799098  0.99749827  0.98667282  0.85460746  0.99849951\n",
      "  0.986799    0.98181772  0.93700743  0.92758936  0.99750197  0.98194361\n",
      "  0.966829    0.97394335  0.98286521  0.99352217  0.97917128  0.9942767\n",
      "  0.99082977  0.95974731  0.9199627   0.9935028   0.98951524  0.98242092\n",
      "  0.9741711   0.99724472  0.9677909   0.99600947  0.94739473  0.74736792\n",
      "  0.99724054]\n",
      "Minibatch loss at epoch 177 and iter 238949: 0.000000 and the learning rate: 0.030736\n",
      "Minibatch train and validation accuracy: 100.000%, 96.194%\n",
      "Time interval: 672.7054 seconds, estimated run time for 200 epochs: 41.0407 hours\n",
      "[ 0.94621044  0.89017594  0.83968115  0.97010893  0.95734322  0.9390797\n",
      "  0.9271704   0.9733817   0.96110368  0.98802346  0.9917475   0.97655052\n",
      "  0.98486334  0.97669661  0.99725026  0.98862463  0.85958368  0.99850029\n",
      "  0.98778921  0.97846258  0.93951249  0.92753577  0.99774671  0.98003405\n",
      "  0.96492994  0.97312331  0.98310095  0.990807    0.98230046  0.99575907\n",
      "  0.99083424  0.96348536  0.9293347   0.99274772  0.98951     0.98313445\n",
      "  0.97390836  0.99699652  0.96909273  0.9960115   0.94755459  0.73260212\n",
      "  0.99699044]\n",
      "Minibatch loss at epoch 178 and iter 240299: 0.000000 and the learning rate: 0.029199\n",
      "Minibatch train and validation accuracy: 100.000%, 96.392%\n",
      "Time interval: 669.8994 seconds, estimated run time for 200 epochs: 41.0192 hours\n",
      "[ 0.94128788  0.89175618  0.86128545  0.97464603  0.96225905  0.94922805\n",
      "  0.94621563  0.97102457  0.95845801  0.98607612  0.99049002  0.98279202\n",
      "  0.98334968  0.97526455  0.99749702  0.98861903  0.85885328  0.99900001\n",
      "  0.989016    0.97393376  0.93596792  0.91342288  0.99800056  0.9790687\n",
      "  0.96516085  0.97385073  0.98599952  0.99376976  0.9825505   0.99502188\n",
      "  0.98984849  0.95087421  0.94964325  0.99322754  0.99002445  0.98337835\n",
      "  0.97390836  0.99749321  0.96991277  0.99650472  0.94488144  0.78299075\n",
      "  0.99749702]\n",
      "Minibatch loss at epoch 179 and iter 241649: 0.000000 and the learning rate: 0.029199\n",
      "Minibatch train and validation accuracy: 100.000%, 96.208%\n",
      "Time interval: 671.4979 seconds, estimated run time for 200 epochs: 40.9984 hours\n",
      "[ 0.94142807  0.89204794  0.85997748  0.96850729  0.96007735  0.94859648\n",
      "  0.92515057  0.97574079  0.95808333  0.98581696  0.98999953  0.98039168\n",
      "  0.98359782  0.97656792  0.99774784  0.98838598  0.84359592  0.99899954\n",
      "  0.98926294  0.97442096  0.93889278  0.91210216  0.99749947  0.97932011\n",
      "  0.9613083   0.97372359  0.9840315   0.99326801  0.98350924  0.99625975\n",
      "  0.99157113  0.95052785  0.94584966  0.99299949  0.98900497  0.98289067\n",
      "  0.97822315  0.99749452  0.96886122  0.9957633   0.94862008  0.74573714\n",
      "  0.99548829]\n",
      "Minibatch loss at epoch 180 and iter 242999: 0.000000 and the learning rate: 0.029199\n",
      "Minibatch train and validation accuracy: 100.000%, 96.264%\n",
      "Time interval: 671.0053 seconds, estimated run time for 200 epochs: 40.9778 hours\n",
      "[ 0.94014204  0.89041048  0.8596583   0.97155309  0.96180928  0.94925326\n",
      "  0.92104608  0.97266912  0.95621669  0.98654664  0.99025685  0.97991133\n",
      "  0.98411852  0.97680235  0.99774444  0.98886365  0.8579573   0.99899954\n",
      "  0.98902148  0.97607368  0.93756509  0.92271113  0.99749827  0.97908938\n",
      "  0.96024895  0.97293144  0.98378599  0.992773    0.98304206  0.99626166\n",
      "  0.99132109  0.95885718  0.94649571  0.99275136  0.98976231  0.98336178\n",
      "  0.9758355   0.99699652  0.96907699  0.99551082  0.94680804  0.74924731\n",
      "  0.99548376]\n",
      "Minibatch loss at epoch 181 and iter 244349: 0.000000 and the learning rate: 0.029199\n",
      "Minibatch train and validation accuracy: 100.000%, 96.294%\n",
      "Time interval: 672.5937 seconds, estimated run time for 200 epochs: 40.9578 hours\n",
      "[ 0.93960965  0.88836187  0.85918152  0.97060925  0.95945573  0.94930363\n",
      "  0.93577933  0.97525072  0.95921898  0.98581696  0.99050903  0.9818266\n",
      "  0.98387051  0.97682571  0.99775118  0.98739135  0.84393018  0.99899858\n",
      "  0.98902696  0.97463363  0.93910712  0.92108005  0.99775118  0.98027563\n",
      "  0.96373016  0.97424197  0.98502946  0.99401748  0.98304206  0.99601346\n",
      "  0.99155867  0.95723557  0.94462806  0.99250323  0.98900497  0.98262978\n",
      "  0.97726667  0.99749571  0.96882933  0.9960075   0.94600713  0.75917721\n",
      "  0.99598753]\n",
      "Minibatch loss at epoch 182 and iter 245699: 0.000000 and the learning rate: 0.029199\n",
      "Minibatch train and validation accuracy: 100.000%, 96.256%\n",
      "Time interval: 670.5305 seconds, estimated run time for 200 epochs: 40.9375 hours\n",
      "[ 0.93919188  0.88806903  0.85809082  0.96852249  0.96038836  0.94916892\n",
      "  0.91603363  0.9750362   0.95656466  0.98630768  0.99124736  0.98159462\n",
      "  0.98514181  0.97679067  0.99775118  0.98716635  0.86346823  0.99874985\n",
      "  0.98853964  0.97368371  0.94055986  0.92372835  0.9977501   0.98049814\n",
      "  0.95862561  0.975227    0.98502201  0.99178857  0.98350924  0.99601144\n",
      "  0.99254793  0.95932162  0.94627172  0.99150378  0.98975724  0.98479885\n",
      "  0.97631204  0.99824739  0.9675436   0.99501199  0.94410521  0.74829537\n",
      "  0.99473238]\n",
      "Minibatch loss at epoch 183 and iter 247049: 0.000001 and the learning rate: 0.029199\n",
      "Minibatch train and validation accuracy: 100.000%, 96.184%\n",
      "Time interval: 671.8292 seconds, estimated run time for 200 epochs: 40.9177 hours\n",
      "[ 0.94210482  0.88737512  0.85935289  0.97105277  0.9569211   0.9486984\n",
      "  0.91050184  0.97265583  0.95584494  0.98973155  0.99103093  0.98400939\n",
      "  0.98514932  0.97957075  0.99749827  0.98765385  0.85032988  0.99899948\n",
      "  0.98779535  0.97368371  0.93963212  0.92103821  0.9980005   0.98294139\n",
      "  0.96460807  0.97429389  0.9845382   0.99450773  0.98400152  0.99502188\n",
      "  0.99034369  0.95480728  0.94361824  0.99101752  0.99052316  0.98454589\n",
      "  0.98013192  0.99824822  0.96889293  0.9955129   0.94282746  0.72630465\n",
      "  0.99397248]\n",
      "Minibatch loss at epoch 184 and iter 248399: 0.000000 and the learning rate: 0.029199\n",
      "Minibatch train and validation accuracy: 100.000%, 96.176%\n",
      "Time interval: 670.0928 seconds, estimated run time for 200 epochs: 40.8977 hours\n",
      "[ 0.94703853  0.89218706  0.86014909  0.96847671  0.95599562  0.94677413\n",
      "  0.89376915  0.97738397  0.95699954  0.98971093  0.99028587  0.98157656\n",
      "  0.98492414  0.97956049  0.99750078  0.98763555  0.86524773  0.99899948\n",
      "  0.98729086  0.97678912  0.94065309  0.92446285  0.99774897  0.98610377\n",
      "  0.96271312  0.97559696  0.98456126  0.99400854  0.98449379  0.99576324\n",
      "  0.99230528  0.95270061  0.94334227  0.99151647  0.98999953  0.98354071\n",
      "  0.97917128  0.99799454  0.97014499  0.99576539  0.94288576  0.70778835\n",
      "  0.99346364]\n",
      "Minibatch loss at epoch 185 and iter 249749: 0.000000 and the learning rate: 0.029199\n",
      "Minibatch train and validation accuracy: 100.000%, 96.271%\n",
      "Time interval: 671.2868 seconds, estimated run time for 200 epochs: 40.8782 hours\n",
      "[ 0.94570625  0.89056754  0.85998845  0.96896172  0.95990229  0.94783413\n",
      "  0.90364951  0.97595638  0.95673865  0.99023241  0.99052787  0.98110384\n",
      "  0.98543406  0.97953981  0.99749947  0.98764777  0.87235796  0.99900001\n",
      "  0.98877484  0.97652763  0.93997329  0.92319822  0.99774897  0.98511857\n",
      "  0.96348041  0.97447515  0.98430842  0.99451327  0.98400152  0.99527198\n",
      "  0.9910754   0.95453405  0.94604778  0.99151647  0.99024707  0.98381025\n",
      "  0.97894174  0.9977411   0.96986669  0.9957633   0.94339579  0.73174477\n",
      "  0.99347013]\n",
      "Minibatch loss at epoch 186 and iter 251099: 0.000000 and the learning rate: 0.027739\n",
      "Minibatch train and validation accuracy: 100.000%, 96.092%\n",
      "Time interval: 671.7023 seconds, estimated run time for 200 epochs: 40.8590 hours\n",
      "[ 0.94293958  0.88546783  0.85143453  0.97038782  0.94630826  0.94434947\n",
      "  0.87565857  0.97117686  0.95456767  0.98874104  0.99029076  0.97439599\n",
      "  0.98444504  0.97876596  0.99675196  0.98764777  0.89544779  0.9987511\n",
      "  0.98878592  0.97726667  0.9428044   0.92826957  0.99725014  0.98659337\n",
      "  0.95864713  0.97424191  0.98235977  0.99253315  0.98569971  0.99576753\n",
      "  0.99082977  0.95582861  0.95009452  0.99126047  0.99026173  0.98503691\n",
      "  0.97818047  0.99849653  0.96989751  0.9960115   0.93257511  0.70735645\n",
      "  0.99166411]\n",
      "Minibatch loss at epoch 187 and iter 252449: 0.000000 and the learning rate: 0.027739\n",
      "Minibatch train and validation accuracy: 100.000%, 95.977%\n",
      "Time interval: 671.4263 seconds, estimated run time for 200 epochs: 40.8400 hours\n",
      "[ 0.94155318  0.89168584  0.85816729  0.97628891  0.9310745   0.94781059\n",
      "  0.94435191  0.95823288  0.94102448  0.98974687  0.99201149  0.98037243\n",
      "  0.98337483  0.97494256  0.99774897  0.98135382  0.81457299  0.99900055\n",
      "  0.98630774  0.97370934  0.94231731  0.91485935  0.9977501   0.9875741\n",
      "  0.96325004  0.97070664  0.98061585  0.9915418   0.98886919  0.99626356\n",
      "  0.99057961  0.94601011  0.92742825  0.99125606  0.98875791  0.98210686\n",
      "  0.98278356  0.99799854  0.97170484  0.99451876  0.9427554   0.73391342\n",
      "  0.99497437]\n",
      "Minibatch loss at epoch 188 and iter 253799: 0.000000 and the learning rate: 0.027739\n",
      "Minibatch train and validation accuracy: 100.000%, 96.204%\n",
      "Time interval: 670.9381 seconds, estimated run time for 200 epochs: 40.8210 hours\n",
      "[ 0.94108868  0.89321363  0.85824132  0.97605032  0.92925924  0.94762796\n",
      "  0.93455267  0.96323127  0.94543552  0.98878038  0.99225914  0.98110378\n",
      "  0.98311865  0.97626209  0.9977501   0.98521394  0.85681576  0.99900001\n",
      "  0.98805922  0.97606206  0.94489378  0.90758944  0.99824995  0.98514068\n",
      "  0.96213645  0.97245342  0.9810847   0.99350929  0.98960352  0.9967584\n",
      "  0.99058425  0.93673235  0.95235783  0.99100405  0.98826414  0.98283106\n",
      "  0.98179984  0.99824643  0.96820462  0.99600554  0.9435094   0.77507925\n",
      "  0.99547917]\n",
      "Minibatch loss at epoch 189 and iter 255149: 0.000000 and the learning rate: 0.027739\n",
      "Minibatch train and validation accuracy: 100.000%, 96.377%\n",
      "Time interval: 671.5353 seconds, estimated run time for 200 epochs: 40.8024 hours\n",
      "[ 0.94873601  0.89419746  0.85729951  0.97273564  0.95709044  0.94702917\n",
      "  0.94153804  0.96652061  0.948385    0.98829335  0.99251074  0.98063201\n",
      "  0.98335803  0.97578162  0.99775118  0.9844861   0.86708093  0.99899948\n",
      "  0.98804134  0.97775555  0.94354373  0.9138155   0.99824995  0.98466057\n",
      "  0.95964545  0.97171676  0.98063505  0.99178445  0.98838025  0.99650997\n",
      "  0.99082977  0.94148386  0.9560014   0.99150801  0.98824662  0.9835816\n",
      "  0.97820181  0.99849951  0.96658045  0.99625802  0.94167876  0.79156399\n",
      "  0.99649072]\n",
      "Minibatch loss at epoch 190 and iter 256499: 0.000005 and the learning rate: 0.027739\n",
      "Minibatch train and validation accuracy: 100.000%, 96.225%\n",
      "Time interval: 672.6730 seconds, estimated run time for 200 epochs: 40.7844 hours\n",
      "[ 0.9484778   0.88842279  0.85753459  0.97038788  0.95795816  0.94875568\n",
      "  0.94385165  0.95610416  0.94099408  0.98976743  0.99176806  0.97656202\n",
      "  0.98311865  0.97653246  0.99725157  0.98278362  0.84893698  0.99900055\n",
      "  0.98751825  0.97608542  0.94015706  0.90841669  0.99850029  0.98416579\n",
      "  0.96132839  0.96943623  0.98013854  0.99401146  0.98764777  0.9952696\n",
      "  0.98911381  0.93902683  0.95990348  0.99200755  0.98728448  0.9845919\n",
      "  0.98060352  0.99874735  0.96553451  0.99625605  0.93173659  0.78834528\n",
      "  0.99724609]\n",
      "Minibatch loss at epoch 191 and iter 257849: 0.000000 and the learning rate: 0.027739\n",
      "Minibatch train and validation accuracy: 100.000%, 96.297%\n",
      "Time interval: 671.3221 seconds, estimated run time for 200 epochs: 40.7661 hours\n",
      "[ 0.95128345  0.89138919  0.85635459  0.96686774  0.96046805  0.94718522\n",
      "  0.93458343  0.95562434  0.94376236  0.99025202  0.99126482  0.97653913\n",
      "  0.98388672  0.97729522  0.99700099  0.98449379  0.86779618  0.9987511\n",
      "  0.9882583   0.97870207  0.94126844  0.91743553  0.99874985  0.98441702\n",
      "  0.96186721  0.97023159  0.98011881  0.99550396  0.98617917  0.99501944\n",
      "  0.98837447  0.94568032  0.95873278  0.9915123   0.98728448  0.9840712\n",
      "  0.97989166  0.99824995  0.96558762  0.99600947  0.93278974  0.78417748\n",
      "  0.99749827]\n",
      "Minibatch loss at epoch 192 and iter 259199: 0.000001 and the learning rate: 0.027739\n",
      "Minibatch train and validation accuracy: 100.000%, 96.377%\n",
      "Time interval: 670.5602 seconds, estimated run time for 200 epochs: 40.7478 hours\n",
      "[ 0.95231169  0.89167929  0.85603929  0.96292681  0.96036905  0.94804502\n",
      "  0.95541656  0.96981448  0.95175165  0.99073792  0.99127352  0.98183554\n",
      "  0.98415846  0.978562    0.99725157  0.9818266   0.8545242   0.998999\n",
      "  0.986799    0.97798383  0.94089794  0.91440678  0.99824822  0.98344409\n",
      "  0.96589094  0.97224975  0.9813475   0.9952507   0.98497117  0.99452686\n",
      "  0.99058425  0.94308114  0.94716847  0.99101299  0.98849374  0.98534113\n",
      "  0.98038203  0.9987492   0.96634936  0.99650472  0.93838334  0.78817207\n",
      "  0.99899751]\n",
      "Minibatch loss at epoch 193 and iter 260549: 0.000000 and the learning rate: 0.026352\n",
      "Minibatch train and validation accuracy: 100.000%, 96.006%\n",
      "Time interval: 671.5544 seconds, estimated run time for 200 epochs: 40.7300 hours\n",
      "[ 0.94933921  0.89011514  0.85531038  0.96267712  0.95803976  0.94819492\n",
      "  0.91505927  0.97474819  0.95750517  0.98947328  0.99201947  0.98303366\n",
      "  0.98388672  0.97883016  0.99700403  0.9823091   0.81877166  0.99900001\n",
      "  0.98801756  0.97989166  0.94281167  0.91848648  0.99799955  0.98536295\n",
      "  0.96725911  0.97404838  0.97822809  0.99549502  0.9852066   0.99502444\n",
      "  0.99082977  0.94235301  0.92782503  0.99250329  0.9880175   0.98608303\n",
      "  0.98642266  0.99849653  0.96643561  0.99650824  0.94283509  0.68762529\n",
      "  0.99799651]\n",
      "Minibatch loss at epoch 194 and iter 261899: 0.000000 and the learning rate: 0.026352\n",
      "Minibatch train and validation accuracy: 100.000%, 96.000%\n",
      "Time interval: 669.1819 seconds, estimated run time for 200 epochs: 40.7117 hours\n",
      "[ 0.94668853  0.88836187  0.85170633  0.9594233   0.96007735  0.94573975\n",
      "  0.91678107  0.97812682  0.95791537  0.98922533  0.99127787  0.9825505\n",
      "  0.9828797   0.97909796  0.99700099  0.98351735  0.81446314  0.99900055\n",
      "  0.98802948  0.97966135  0.94262463  0.91757756  0.99824911  0.9848668\n",
      "  0.96349937  0.97382945  0.97870189  0.99574852  0.98472857  0.99502444\n",
      "  0.99132544  0.94305414  0.93258643  0.9922592   0.98851681  0.98606217\n",
      "  0.98569268  0.99849802  0.96719581  0.99650651  0.94197738  0.69778949\n",
      "  0.99724334]\n",
      "Minibatch loss at epoch 195 and iter 263249: 0.000000 and the learning rate: 0.026352\n",
      "Minibatch train and validation accuracy: 100.000%, 96.144%\n",
      "Time interval: 671.2659 seconds, estimated run time for 200 epochs: 40.6942 hours\n",
      "[ 0.9426595   0.88432097  0.85840905  0.96730393  0.9568584   0.95042092\n",
      "  0.93050325  0.97716624  0.95831192  0.9882701   0.99102199  0.98110384\n",
      "  0.98412657  0.97990912  0.996503    0.98569971  0.82546157  0.99849802\n",
      "  0.98751825  0.97750562  0.94231731  0.92546695  0.99824822  0.98366296\n",
      "  0.96374887  0.97185886  0.97724974  0.99499953  0.98545682  0.9952696\n",
      "  0.99157113  0.95270222  0.931315    0.99224371  0.98978275  0.98754311\n",
      "  0.98593587  0.99824822  0.96795642  0.99625802  0.94010568  0.71972275\n",
      "  0.99774557]\n",
      "Minibatch loss at epoch 196 and iter 264599: 0.000001 and the learning rate: 0.026352\n",
      "Minibatch train and validation accuracy: 100.000%, 96.161%\n",
      "Time interval: 669.7814 seconds, estimated run time for 200 epochs: 40.6764 hours\n",
      "[ 0.93623006  0.87906802  0.85809457  0.97062349  0.95254105  0.95202535\n",
      "  0.95133537  0.97284031  0.95700502  0.98876357  0.99300307  0.9837513\n",
      "  0.98440593  0.97886217  0.99700403  0.98327547  0.83406192  0.99874985\n",
      "  0.98728448  0.97226232  0.94105214  0.92356473  0.99774897  0.98367101\n",
      "  0.96910357  0.97333956  0.97991514  0.99327803  0.98642933  0.9952696\n",
      "  0.99304128  0.95528114  0.91554087  0.99199957  0.98904884  0.98632133\n",
      "  0.98373538  0.99824822  0.96664912  0.99600947  0.93936288  0.73136866\n",
      "  0.99774444]\n",
      "Minibatch loss at epoch 197 and iter 265949: 0.000000 and the learning rate: 0.026352\n",
      "Minibatch train and validation accuracy: 100.000%, 96.090%\n",
      "Time interval: 672.7628 seconds, estimated run time for 200 epochs: 40.6596 hours\n",
      "[ 0.93817794  0.87980855  0.85372585  0.96011484  0.96058351  0.94807404\n",
      "  0.9529267   0.9764123   0.95945555  0.98778921  0.99199152  0.98109454\n",
      "  0.98415047  0.97756439  0.99725437  0.98327547  0.82158607  0.99874985\n",
      "  0.98604834  0.97227579  0.94133079  0.92078632  0.99799955  0.98242962\n",
      "  0.96829033  0.97326958  0.98161906  0.99524361  0.98424375  0.99502188\n",
      "  0.9955197   0.95327508  0.92300534  0.9914825   0.98701251  0.98268992\n",
      "  0.97554964  0.99724746  0.95805234  0.99625802  0.93882656  0.74056101\n",
      "  0.99724609]\n",
      "Minibatch loss at epoch 198 and iter 267299: 0.000000 and the learning rate: 0.026352\n",
      "Minibatch train and validation accuracy: 100.000%, 96.069%\n",
      "Time interval: 671.6896 seconds, estimated run time for 200 epochs: 40.6427 hours\n",
      "[ 0.94028389  0.8811667   0.84804016  0.95969248  0.95893025  0.94791359\n",
      "  0.9456439   0.9714281   0.95535892  0.98679245  0.99175572  0.98255903\n",
      "  0.98388672  0.97857279  0.99675357  0.98303366  0.82653314  0.99899906\n",
      "  0.986799    0.97323555  0.94225675  0.91979706  0.99775118  0.98315948\n",
      "  0.96780789  0.97467989  0.98113155  0.99525779  0.98349297  0.99502444\n",
      "  0.99477428  0.95322996  0.9258911   0.9920035   0.98751199  0.98338658\n",
      "  0.9758355   0.99774784  0.9587971   0.99600947  0.94028676  0.73527211\n",
      "  0.99774677]\n",
      "Minibatch loss at epoch 199 and iter 268649: 0.000002 and the learning rate: 0.026352\n",
      "Minibatch train and validation accuracy: 100.000%, 96.076%\n",
      "Time interval: 671.2378 seconds, estimated run time for 200 epochs: 40.6259 hours\n",
      "[ 0.94967449  0.88835806  0.83927518  0.95647973  0.96220386  0.93843859\n",
      "  0.93370759  0.96929777  0.95453352  0.98975724  0.9922592   0.98156744\n",
      "  0.98414248  0.97806859  0.99650478  0.98521394  0.85107559  0.99850023\n",
      "  0.98558599  0.97846252  0.94311875  0.92393565  0.99774897  0.97904807\n",
      "  0.96540999  0.97278357  0.98136604  0.9952507   0.98280048  0.99403232\n",
      "  0.99353188  0.95532435  0.92400044  0.99126482  0.98673958  0.98196149\n",
      "  0.9758355   0.99674714  0.96043396  0.99625605  0.93898338  0.7323584\n",
      "  0.99623352]\n",
      "Minibatch loss at epoch 200 and iter 269999: 0.000000 and the learning rate: 0.025034\n",
      "Minibatch train and validation accuracy: 100.000%, 96.028%\n",
      "Time interval: 671.6824 seconds, estimated run time for 200 epochs: 40.6093 hours\n",
      "[ 0.94825059  0.88564563  0.83825147  0.95463181  0.9635781   0.93980533\n",
      "  0.93879426  0.9719165   0.95259541  0.98827595  0.99150372  0.98375136\n",
      "  0.98465359  0.97887272  0.99650651  0.98449379  0.83749229  0.99900001\n",
      "  0.98583108  0.97322249  0.94416732  0.91747004  0.9977501   0.98120624\n",
      "  0.96265507  0.97398651  0.9801681   0.99449956  0.98231781  0.9942767\n",
      "  0.9952696   0.95274788  0.92123395  0.99126917  0.9879995   0.98262119\n",
      "  0.97653908  0.99749446  0.96041346  0.9957633   0.94371146  0.7308833\n",
      "  0.99573356]\n",
      "Final Test accuracy: 98.1%\n",
      "INFO:tensorflow:Restoring parameters from saved-salexnet-aug-eq-n/best-model-session\n",
      "Test accuracy with the best model: 98.184%\n",
      "f1-scores of classes:\n",
      "[ 0.99173504  0.99232328  0.97774822  0.98312658  0.98772955  0.9678452\n",
      "  0.96907169  0.99445009  0.99777728  0.99687779  0.99847972  0.99879616\n",
      "  0.97048181  0.99860877  0.99999952  0.98591501  0.99667728  0.98873192\n",
      "  0.9369123   0.96610123  0.95744628  0.76470536  0.99585015  0.90634394\n",
      "  0.9777773   0.9842267   0.97547632  0.86956471  0.98675448  0.98901051\n",
      "  0.84732777  0.98892939  0.99173504  0.98122019  0.99585015  0.99871582\n",
      "  0.97165948  0.99999952  0.99638414  0.9944129   0.96739089  0.99159616\n",
      "  0.9944129 ]\n",
      "Total run time 2437.3621 minutes\n"
     ]
    }
   ],
   "source": [
    "trainer.run(salexnet, 'saved-salexnet-aug-eq-n', n_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5f0733df28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot f1 scores\n",
    "path = './saved-salexnet-aug-eq-n/best-test-f1-scores.pkl'\n",
    "with open(path, mode='rb') as f:\n",
    "    score_list = pickle.load(f)\n",
    "    classes = np.arange(43)\n",
    "    plt.plot(classes, score_list, marker='v', color='red')\n",
    "    plt.title('F1-Score of Modified AlexNet for The Test Set')\n",
    "    plt.ylabel('f1-score')\n",
    "    plt.xlabel('classes')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
